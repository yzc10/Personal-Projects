{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6411c4d7-2162-4a76-b4cc-6113a14d87b1",
   "metadata": {},
   "source": [
    "# Predicting Stock Returns [PyTorch - LSTM]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2d0666a-8bca-453b-835f-0660ad724b70",
   "metadata": {},
   "source": [
    "## 0. One-Off Data Processing [Temp]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "90d02b4b-7eed-4f5f-8c33-5321575a5b20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime as dt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from functools import partial\n",
    "from tqdm import tqdm\n",
    "\n",
    "path = path = r'C:\\YZC\\NUS\\Semester 1\\DSA5105_Principles of Machine Learning\\Principles of ML_Project'\n",
    "os.chdir(path)\n",
    "tqdm = partial(tqdm,position=0,leave=True)\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d40f9444-b934-43db-b251-de33d2f7528c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sp500 = pd.read_csv('processed_df_v1.csv')\n",
    "sp500 = sp500.drop(['Year_x','Year_y','grouper1'],axis=1)\n",
    "sp500['Date'] = pd.to_datetime(sp500['Date'])\n",
    "sp500['Target'] = sp500.groupby('Stock')['Target'].shift(-1)\n",
    "sp500['Target_Return'] = sp500.groupby('Stock')['Return'].shift(-1)\n",
    "sp500['Target_Close'] = sp500.groupby('Stock')['Close'].shift(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9bd8e6fe-d4ca-4d3f-994e-8151ac285b28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test done\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "inf_cols = ['Stochastic_5','Stochastic_15','RS_5','RS_15']\n",
    "null_mean_cols = ['SMA_Volume_ratio','Stochastic_5','Stochastic_15','Stochastic_%D_5','Stochastic_%D_15','Stochastic_Ratio',\n",
    "'+DM_5','-DM_5','+DM_15','-DM_15','RS_5','RS_15','RSI_5','RSI_ratio']\n",
    "null_adjfill_cols = ['Return','Target','Target_Return','Target_Close']\n",
    "\n",
    "def impute(df,inf_cols,null_mean_cols,null_adjfill_cols,groupby_col):\n",
    "    for c in inf_cols:\n",
    "        df[c] = df[c].replace([-np.inf,np.inf],np.nan)\n",
    "    for c in null_mean_cols:\n",
    "        result = df.groupby(groupby_col)[c].apply(lambda x:x.fillna(x.mean()))\n",
    "        df[c] = result.droplevel(0)\n",
    "    for c in null_adjfill_cols:\n",
    "        df[c] = df.groupby(groupby_col)[c].ffill().bfill()\n",
    "    return df\n",
    "\n",
    "def NA_test(df,cols):\n",
    "    for c in cols:\n",
    "        if df[c].isnull().values.any():\n",
    "            print('null',c)\n",
    "        if np.isinf(df[c].values).any():\n",
    "            print('inf',c)\n",
    "    print('test done')\n",
    "\n",
    "sp500_1 = impute(sp500,inf_cols,null_mean_cols,null_adjfill_cols,'Stock')\n",
    "NA_test(sp500_1,[c for c in sp500_1.columns if c not in ['Date','Stock','Year']])\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2229a6c3-2d91-4223-9940-218eecc41563",
   "metadata": {},
   "outputs": [],
   "source": [
    "sp500_1.to_csv('processed_df_v2.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a928ba7-6d80-41a0-8419-e9545e3e89f0",
   "metadata": {},
   "source": [
    "## 1. Data Pre-Processing\n",
    "#### (Start from here)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a4b3accc-477c-4b96-98b4-cf5b5a1148cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime as dt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "import time\n",
    "import os\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "from functools import partial\n",
    "\n",
    "path = path = r'C:\\YZC\\NUS\\Semester 1\\DSA5105_Principles of Machine Learning\\Principles of ML_Project'\n",
    "os.chdir(path)\n",
    "# tqdm = partial(tqdm,position=0,leave=True)\n",
    "# tqdm._instances.clear()\n",
    "# while len(tqdm._instances) > 0:\n",
    "#     tqdm._instances.pop().close()\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f99dd3ac-272b-4c90-af7b-116d2471a2cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Dividends</th>\n",
       "      <th>Stock Splits</th>\n",
       "      <th>Stock</th>\n",
       "      <th>Return</th>\n",
       "      <th>...</th>\n",
       "      <th>United States_CA</th>\n",
       "      <th>United States_CP_end</th>\n",
       "      <th>United States_CP_avg</th>\n",
       "      <th>United States_Gov_NetDebt</th>\n",
       "      <th>United States_GDP</th>\n",
       "      <th>United States_UR</th>\n",
       "      <th>Fed_Rate</th>\n",
       "      <th>Target</th>\n",
       "      <th>Target_Return</th>\n",
       "      <th>Target_Close</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2000-01-03</td>\n",
       "      <td>1.153400</td>\n",
       "      <td>1.206028</td>\n",
       "      <td>1.023149</td>\n",
       "      <td>1.201642</td>\n",
       "      <td>7226398</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>ATVI</td>\n",
       "      <td>-0.030293</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.921</td>\n",
       "      <td>3.427</td>\n",
       "      <td>3.367</td>\n",
       "      <td>-0.537</td>\n",
       "      <td>4.077</td>\n",
       "      <td>3.967</td>\n",
       "      <td>5.45</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.030293</td>\n",
       "      <td>1.165241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2000-01-04</td>\n",
       "      <td>1.175329</td>\n",
       "      <td>1.187609</td>\n",
       "      <td>1.041570</td>\n",
       "      <td>1.165241</td>\n",
       "      <td>4262390</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>ATVI</td>\n",
       "      <td>-0.030293</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.921</td>\n",
       "      <td>3.427</td>\n",
       "      <td>3.367</td>\n",
       "      <td>-0.537</td>\n",
       "      <td>4.077</td>\n",
       "      <td>3.967</td>\n",
       "      <td>5.45</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.003765</td>\n",
       "      <td>1.169628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2000-01-05</td>\n",
       "      <td>1.153401</td>\n",
       "      <td>1.196818</td>\n",
       "      <td>1.151208</td>\n",
       "      <td>1.169628</td>\n",
       "      <td>3389998</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>ATVI</td>\n",
       "      <td>0.003765</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.921</td>\n",
       "      <td>3.427</td>\n",
       "      <td>3.367</td>\n",
       "      <td>-0.537</td>\n",
       "      <td>4.077</td>\n",
       "      <td>3.967</td>\n",
       "      <td>5.45</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.019498</td>\n",
       "      <td>1.146823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2000-01-06</td>\n",
       "      <td>1.162173</td>\n",
       "      <td>1.169628</td>\n",
       "      <td>1.137612</td>\n",
       "      <td>1.146823</td>\n",
       "      <td>2429998</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>ATVI</td>\n",
       "      <td>-0.019498</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.921</td>\n",
       "      <td>3.427</td>\n",
       "      <td>3.367</td>\n",
       "      <td>-0.537</td>\n",
       "      <td>4.077</td>\n",
       "      <td>3.967</td>\n",
       "      <td>5.45</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.027915</td>\n",
       "      <td>1.178837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2000-01-07</td>\n",
       "      <td>1.162172</td>\n",
       "      <td>1.187609</td>\n",
       "      <td>1.133228</td>\n",
       "      <td>1.178837</td>\n",
       "      <td>15549590</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>ATVI</td>\n",
       "      <td>0.027915</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.921</td>\n",
       "      <td>3.427</td>\n",
       "      <td>3.367</td>\n",
       "      <td>-0.537</td>\n",
       "      <td>4.077</td>\n",
       "      <td>3.967</td>\n",
       "      <td>5.45</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.050223</td>\n",
       "      <td>1.238042</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 93 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date      Open      High       Low     Close    Volume  Dividends  \\\n",
       "0  2000-01-03  1.153400  1.206028  1.023149  1.201642   7226398        0.0   \n",
       "1  2000-01-04  1.175329  1.187609  1.041570  1.165241   4262390        0.0   \n",
       "2  2000-01-05  1.153401  1.196818  1.151208  1.169628   3389998        0.0   \n",
       "3  2000-01-06  1.162173  1.169628  1.137612  1.146823   2429998        0.0   \n",
       "4  2000-01-07  1.162172  1.187609  1.133228  1.178837  15549590        0.0   \n",
       "\n",
       "   Stock Splits Stock    Return  ...  United States_CA  United States_CP_end  \\\n",
       "0           0.0  ATVI -0.030293  ...            -3.921                 3.427   \n",
       "1           0.0  ATVI -0.030293  ...            -3.921                 3.427   \n",
       "2           0.0  ATVI  0.003765  ...            -3.921                 3.427   \n",
       "3           0.0  ATVI -0.019498  ...            -3.921                 3.427   \n",
       "4           0.0  ATVI  0.027915  ...            -3.921                 3.427   \n",
       "\n",
       "   United States_CP_avg  United States_Gov_NetDebt  United States_GDP  \\\n",
       "0                 3.367                     -0.537              4.077   \n",
       "1                 3.367                     -0.537              4.077   \n",
       "2                 3.367                     -0.537              4.077   \n",
       "3                 3.367                     -0.537              4.077   \n",
       "4                 3.367                     -0.537              4.077   \n",
       "\n",
       "   United States_UR  Fed_Rate  Target  Target_Return  Target_Close  \n",
       "0             3.967      5.45     0.0      -0.030293      1.165241  \n",
       "1             3.967      5.45     1.0       0.003765      1.169628  \n",
       "2             3.967      5.45     0.0      -0.019498      1.146823  \n",
       "3             3.967      5.45     1.0       0.027915      1.178837  \n",
       "4             3.967      5.45     1.0       0.050223      1.238042  \n",
       "\n",
       "[5 rows x 93 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Essentials\n",
    "sp500 = pd.read_csv('processed_df_v2.csv')\n",
    "sp500_var = sp500.copy().drop(['Date','Return','Stock','Target','Target_Return','Target_Close'],axis=1)\n",
    "sp500.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3f3297f0-c129-4a55-93a0-8872d7975c59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sampling\n",
    "sampled_stocks = ['AAPL','CCI', 'USB', 'ADI', 'PNW', 'QCOM']\n",
    "sp500_sampled = sp500.loc[sp500['Stock'].isin(sampled_stocks)].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e0a8371d-dc48-4e5f-91b7-bb1088d84f4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataFrameSelector(BaseEstimator,TransformerMixin):\n",
    "    def __init__(self,attribute_names):\n",
    "        self.attribute_names = attribute_names\n",
    "    def fit(self,X):\n",
    "        return self\n",
    "    def transform(self,X):\n",
    "        return X[self.attribute_names].to_numpy()\n",
    "\n",
    "class ArrayTransformer(BaseEstimator,TransformerMixin): \n",
    "    # Restructure into: samples x timesteps x features\n",
    "    def __init__(self):\n",
    "        return None\n",
    "    def fit(self,X):\n",
    "        return self\n",
    "    def transform(self,X):\n",
    "        X = X.toarray()\n",
    "        X1_cols = list(range(30))\n",
    "        X1_cols.extend(sampled_stocks)    \n",
    "        X1_df = pd.DataFrame(X,columns=X1_cols)\n",
    "        X1 = []\n",
    "        for s in sampled_stocks:\n",
    "            X1.append(X1_df.loc[X1_df[s]==1].to_numpy())\n",
    "        X1 = np.asarray(X1)\n",
    "        return X1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "29fb14cf-550c-4e19-a458-ad6fb6232e43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "# Pipeline for X\n",
    "cat_vars = ['Stock']\n",
    "num_vars = list(set(sp500_var.columns) - set(cat_vars))\n",
    "\n",
    "num_pipeline = Pipeline([\n",
    "    ('selector',DataFrameSelector(num_vars)),\n",
    "    ('scaler',StandardScaler()),\n",
    "    ('pca',PCA(n_components=30)),\n",
    "])\n",
    "cat_pipeline = Pipeline([\n",
    "    ('selector',DataFrameSelector(cat_vars)),\n",
    "    ('ohe',OneHotEncoder(categories=[sampled_stocks])), #Note: categories should be a list of list(s)\n",
    "])\n",
    "concat_pipeline = FeatureUnion(transformer_list=[\n",
    "    ('num_pipeline',num_pipeline),\n",
    "    ('cat_pipeline',cat_pipeline),\n",
    "])\n",
    "final_pipeline = Pipeline([\n",
    "    ('combined_pipeline',concat_pipeline),\n",
    "    ('to_array',ArrayTransformer()),\n",
    "])\n",
    "X1 = final_pipeline.fit_transform(sp500_sampled)\n",
    "\n",
    "# Transform Y:\n",
    "y1 = []\n",
    "for s in sampled_stocks:\n",
    "    y1.append(sp500_sampled.loc[sp500_sampled['Stock']==s,'Target'].to_numpy())\n",
    "y1 = np.asarray(y1)\n",
    "y1 = y1.astype(int)\n",
    "\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f93d3e05-ab47-49b9-83e7-47d5d2f1fe39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Verifying order of labels: ['AAPL','CCI', 'USB', 'ADI', 'PNW', 'QCOM']\n",
    "# idx = {}\n",
    "# for s in sampled_stocks:\n",
    "#     idx[s] = sp500_sampled.index[sp500_sampled['Stock']==s].tolist()[0]\n",
    "# print(idx)\n",
    "# for i in idx:\n",
    "#     print(i,X1[idx[i],30:]) # Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0f729957-6a65-4e36-a929-db2968d2a2c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n",
      "(6, 5995) (6, 5995, 36)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as data\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(device)\n",
    "print(y1.shape,X1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "94b410f8-8f8d-49aa-9729-9b28747466e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM_Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.lstm = nn.LSTM(input_size=36, hidden_size=50,num_layers=1,batch_first=True)\n",
    "        self.linear = nn.Linear(50,1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "    def forward(self,x):\n",
    "        x, _ = self.lstm(x)\n",
    "        x = self.linear(x)\n",
    "        x = self.sigmoid(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "90d51d2a-de30-4744-904c-082823adeaa0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([6, 4796, 36]) torch.Size([6, 4796, 1]) torch.Size([6, 1199, 36]) torch.Size([6, 1199, 1])\n"
     ]
    }
   ],
   "source": [
    "def time_series_split(X,split_pct):\n",
    "    time_series = X.shape[1]\n",
    "    train_size = int(time_series*split_pct)\n",
    "    test_size = time_series - train_size\n",
    "    X_train, X_test = X[:,:train_size],X[:,train_size:time_series]\n",
    "    return X_train, X_test\n",
    "\n",
    "def convert_tensor(X,unsqueeze=False):\n",
    "    X = torch.from_numpy(X)\n",
    "    X = X.type(torch.FloatTensor)\n",
    "    if unsqueeze==True:\n",
    "        X = torch.unsqueeze(X,dim=-1)\n",
    "    return X\n",
    "\n",
    "split_pct = 0.8\n",
    "X_train, X_test = time_series_split(X1,split_pct)\n",
    "y_train, y_test = time_series_split(y1,split_pct)\n",
    "X_train, X_test = convert_tensor(X_train), convert_tensor(X_test)\n",
    "y_train, y_test = convert_tensor(y_train,unsqueeze=True), convert_tensor(y_test,unsqueeze=True)\n",
    "print(X_train.shape,y_train.shape,X_test.shape,y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "97848e63-df1a-4fcb-a85d-ce87844ae475",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LSTM_Model()\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "loader = data.DataLoader(data.TensorDataset(X_train,y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4fd9fa99-b0e9-462a-97ed-1a65b26e0098",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5525b5b0fc6b40d1802ee77da14ec549",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch0: accuracy=0.5137614678899083, precision=0.520895031260283,recall=0.843816631130064\n",
      "Epoch1: accuracy=0.5157075340561579, precision=0.5217673814165043,recall=0.8560767590618337\n",
      "Epoch2: accuracy=0.5151515151515151, precision=0.5216962524654832,recall=0.8459488272921108\n",
      "Epoch3: accuracy=0.517931609674729, precision=0.5239541160593792,recall=0.8278251599147122\n",
      "Epoch4: accuracy=0.513900472616069, precision=0.5223566543924251,recall=0.7939765458422174\n",
      "Epoch5: accuracy=0.5127884348067834, precision=0.522264287001983,recall=0.7721215351812367\n",
      "Epoch6: accuracy=0.5116763969974979, precision=0.5219871205151794,recall=0.7561300639658849\n",
      "Epoch7: accuracy=0.509869335557409, precision=0.5210742260350616,recall=0.7446695095948828\n",
      "Epoch8: accuracy=0.5108423686405338, precision=0.5219108519842016,recall=0.7396055437100213\n",
      "Epoch9: accuracy=0.5095913261050876, precision=0.5211960635881908,recall=0.7340085287846482\n",
      "Epoch10: accuracy=0.5093133166527662, precision=0.5211509146341463,recall=0.7289445628997868\n",
      "Epoch11: accuracy=0.5076452599388379, precision=0.5203409531189461,recall=0.7158848614072495\n",
      "Epoch12: accuracy=0.505838198498749, precision=0.5193099392276024,recall=0.7060234541577826\n",
      "Epoch13: accuracy=0.5041701417848207, precision=0.5186755501716132,recall=0.6847014925373134\n",
      "Epoch14: accuracy=0.5041701417848207, precision=0.5187741018875583,recall=0.6812366737739872\n",
      "Epoch15: accuracy=0.5026410897970531, precision=0.518185618729097,recall=0.6607142857142857\n",
      "Epoch16: accuracy=0.5011120378092855, precision=0.5171038824763904,recall=0.6567164179104478\n",
      "Epoch17: accuracy=0.5023630803447318, precision=0.5179092044981258,recall=0.6628464818763327\n",
      "Epoch18: accuracy=0.5033361134278566, precision=0.5185800290637326,recall=0.6657782515991472\n",
      "Epoch19: accuracy=0.5038921323324993, precision=0.51863923405989,recall=0.6785714285714286\n",
      "Epoch20: accuracy=0.5030581039755352, precision=0.5189304812834225,recall=0.646588486140725\n",
      "Epoch21: accuracy=0.5015290519877675, precision=0.5172844648063307,recall=0.662046908315565\n",
      "Epoch22: accuracy=0.5054211843202668, precision=0.5196595054722335,recall=0.6833688699360341\n",
      "Epoch23: accuracy=0.5069502363080345, precision=0.5206528309490228,recall=0.6886993603411514\n",
      "Epoch24: accuracy=0.50806227411732, precision=0.5215194988886643,recall=0.6878997867803838\n",
      "Epoch25: accuracy=0.5072282457603559, precision=0.520964148268179,recall=0.685501066098081\n",
      "Epoch26: accuracy=0.5107033639143731, precision=0.5227629513343799,recall=0.7100213219616205\n",
      "Epoch27: accuracy=0.5073672504865165, precision=0.5210696920583469,recall=0.685501066098081\n",
      "Epoch28: accuracy=0.5097303308312483, precision=0.5223524736737533,recall=0.7006929637526652\n",
      "Epoch29: accuracy=0.5087572977481234, precision=0.5214990138067062,recall=0.7046908315565032\n",
      "Epoch30: accuracy=0.510286349735891, precision=0.5225349340680968,recall=0.7076226012793176\n",
      "Epoch31: accuracy=0.5101473450097304, precision=0.5223179326546593,recall=0.7110874200426439\n",
      "Epoch32: accuracy=0.5101473450097304, precision=0.5221187427240978,recall=0.7172174840085288\n",
      "Epoch33: accuracy=0.5112593828190158, precision=0.5225880551301685,recall=0.7276119402985075\n",
      "Epoch34: accuracy=0.5094523213789269, precision=0.5218071582241346,recall=0.7110874200426439\n",
      "Epoch35: accuracy=0.5107033639143731, precision=0.521969696969697,recall=0.7345415778251599\n",
      "Epoch36: accuracy=0.5090353072004448, precision=0.5215432824128476,recall=0.7097547974413646\n",
      "Epoch37: accuracy=0.509869335557409, precision=0.5217642526964561,recall=0.7220149253731343\n",
      "Epoch38: accuracy=0.5093133166527662, precision=0.5217391304347826,recall=0.7100213219616205\n",
      "Epoch39: accuracy=0.5097303308312483, precision=0.5214981845977451,recall=0.7273454157782516\n",
      "Epoch40: accuracy=0.509869335557409, precision=0.521789433089086,recall=0.7212153518123667\n",
      "Epoch41: accuracy=0.5108423686405338, precision=0.5224167789109101,recall=0.7236140724946695\n",
      "Epoch42: accuracy=0.5112593828190158, precision=0.5224933282500953,recall=0.730543710021322\n",
      "Epoch43: accuracy=0.5122324159021406, precision=0.5229202037351444,recall=0.7388059701492538\n",
      "Epoch44: accuracy=0.510286349735891, precision=0.5219643199693075,recall=0.7252132196162047\n",
      "Epoch45: accuracy=0.5095913261050876, precision=0.5218664584146817,recall=0.7124200426439232\n",
      "Epoch46: accuracy=0.5100083402835697, precision=0.5221636399140793,recall=0.7126865671641791\n",
      "Epoch47: accuracy=0.509869335557409, precision=0.5218907400232468,recall=0.7180170575692963\n",
      "Epoch48: accuracy=0.50806227411732, precision=0.5210017747978702,recall=0.7041577825159915\n",
      "Epoch49: accuracy=0.5105643591882124, precision=0.5226603884638023,recall=0.7100213219616205\n",
      "Epoch50: accuracy=0.5100083402835697, precision=0.5223645320197045,recall=0.7065565031982942\n",
      "Epoch51: accuracy=0.5072282457603559, precision=0.5204021289178001,recall=0.7036247334754797\n",
      "Epoch52: accuracy=0.5068112315818738, precision=0.5201820340324496,recall=0.7006929637526652\n",
      "Epoch53: accuracy=0.5041701417848207, precision=0.5184152896675294,recall=0.6940298507462687\n",
      "Epoch54: accuracy=0.5062552126772311, precision=0.5196618167518678,recall=0.7044243070362474\n",
      "Epoch55: accuracy=0.5079232693911593, precision=0.5209320695102686,recall=0.7030916844349681\n",
      "Epoch56: accuracy=0.5079232693911593, precision=0.5210400952759031,recall=0.6996268656716418\n",
      "Epoch57: accuracy=0.5065332221295524, precision=0.5199211045364891,recall=0.7025586353944563\n",
      "Epoch58: accuracy=0.5087572977481234, precision=0.5215927099841522,recall=0.7017590618336887\n",
      "Epoch59: accuracy=0.5062552126772311, precision=0.5195848021934979,recall=0.707089552238806\n",
      "Epoch60: accuracy=0.5062552126772311, precision=0.5196772924045652,recall=0.7038912579957356\n",
      "Epoch61: accuracy=0.5082012788434807, precision=0.5211295418641391,recall=0.7033582089552238\n",
      "Epoch62: accuracy=0.5070892410341952, precision=0.520460866110449,recall=0.6982942430703625\n",
      "Epoch63: accuracy=0.5065332221295524, precision=0.5200875099443119,recall=0.6969616204690832\n",
      "Epoch64: accuracy=0.5079232693911593, precision=0.520990099009901,recall=0.701226012793177\n",
      "Epoch65: accuracy=0.5068112315818738, precision=0.5200787401574803,recall=0.7041577825159915\n",
      "Epoch66: accuracy=0.5054211843202668, precision=0.5194155324259407,recall=0.6916311300639659\n",
      "Epoch67: accuracy=0.5054211843202668, precision=0.5191246056782335,recall=0.7017590618336887\n",
      "Epoch68: accuracy=0.5048651654156241, precision=0.5190993164455167,recall=0.6881663113006397\n",
      "Epoch69: accuracy=0.5048651654156241, precision=0.5191146881287726,recall=0.6876332622601279\n",
      "Epoch70: accuracy=0.5062552126772311, precision=0.5197706603400554,recall=0.7006929637526652\n",
      "Epoch71: accuracy=0.5048651654156241, precision=0.5194991789819376,recall=0.6745735607675906\n",
      "Epoch72: accuracy=0.5048651654156241, precision=0.5192932575142161,recall=0.6815031982942431\n",
      "Epoch73: accuracy=0.504448151237142, precision=0.5192347253651513,recall=0.6727078891257996\n",
      "Epoch74: accuracy=0.5048651654156241, precision=0.5189848121502798,recall=0.6921641791044776\n",
      "Epoch75: accuracy=0.5037531276063386, precision=0.5185185185185185,recall=0.6791044776119403\n",
      "Epoch76: accuracy=0.5056991937725883, precision=0.5197183098591549,recall=0.6884328358208955\n",
      "Epoch77: accuracy=0.5050041701417848, precision=0.5192191587844637,recall=0.6876332622601279\n",
      "Epoch78: accuracy=0.5051431748679455, precision=0.5194410692588093,recall=0.68363539445629\n",
      "Epoch79: accuracy=0.5056991937725883, precision=0.5199349064279902,recall=0.6812366737739872\n",
      "Epoch80: accuracy=0.5050041701417848, precision=0.5194382251170364,recall=0.6801705756929638\n",
      "Epoch81: accuracy=0.505838198498749, precision=0.5199837695272875,recall=0.6831023454157783\n",
      "Epoch82: accuracy=0.5056991937725883, precision=0.519959266802444,recall=0.6804371002132196\n",
      "Epoch83: accuracy=0.5029190992493745, precision=0.5183946488294314,recall=0.6609808102345416\n",
      "Epoch84: accuracy=0.5052821795941062, precision=0.519933897954968,recall=0.6708422174840085\n",
      "Epoch85: accuracy=0.5070892410341952, precision=0.5208249090173878,recall=0.6865671641791045\n",
      "Epoch86: accuracy=0.5069502363080345, precision=0.5211645674168903,recall=0.6727078891257996\n",
      "Epoch87: accuracy=0.5077842646649986, precision=0.52173017507724,recall=0.6751066098081023\n",
      "Epoch88: accuracy=0.508479288295802, precision=0.52217659137577,recall=0.677771855010661\n",
      "Epoch89: accuracy=0.5082012788434807, precision=0.5221074380165289,recall=0.6735074626865671\n",
      "Epoch90: accuracy=0.5075062552126772, precision=0.5216490573855397,recall=0.6711087420042644\n",
      "Epoch91: accuracy=0.50806227411732, precision=0.5219271155033972,recall=0.6756396588486141\n",
      "Epoch92: accuracy=0.5079232693911593, precision=0.5216414863209473,recall=0.6809701492537313\n",
      "Epoch93: accuracy=0.5083402835696413, precision=0.5221695194885544,recall=0.6748400852878464\n",
      "Epoch94: accuracy=0.5063942174033917, precision=0.5205143906919779,recall=0.679637526652452\n",
      "Epoch95: accuracy=0.5073672504865165, precision=0.521010101010101,recall=0.6873667377398721\n",
      "Epoch96: accuracy=0.5063942174033917, precision=0.5205647636586863,recall=0.6780383795309168\n",
      "Epoch97: accuracy=0.5069502363080345, precision=0.5208375686115064,recall=0.6828358208955224\n",
      "Epoch98: accuracy=0.5061162079510704, precision=0.5206303130831432,recall=0.6692430703624733\n",
      "Epoch99: accuracy=0.5054211843202668, precision=0.5200496072757338,recall=0.6705756929637526\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 100\n",
    "results = pd.DataFrame(columns=['epoch','accuracy','precision','recall'])\n",
    "for epoch in tqdm(range(n_epochs)):\n",
    "    model.train()\n",
    "    for X_batch, y_batch in loader:\n",
    "        y_pred = model(X_batch)\n",
    "        loss = loss_fn(y_pred,y_batch)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        model.eval()\n",
    "    with torch.no_grad():\n",
    "        y_pred = model(X_test)\n",
    "        y_pred = torch.squeeze(y_pred,dim=-1)\n",
    "        y_test1 = torch.squeeze(y_test,dim=-1)\n",
    "        y_pred, y_test1 = y_pred.numpy(), y_test1.numpy()\n",
    "        y_pred = (y_pred>0.5).astype(float).flatten()\n",
    "        y_test1 = y_test1.flatten()\n",
    "        # print(y_pred,y_test1)\n",
    "        accuracy = metrics.accuracy_score(y_test1,y_pred)\n",
    "        precision = metrics.precision_score(y_test1,y_pred)\n",
    "        recall = metrics.recall_score(y_test1,y_pred)\n",
    "        tqdm.write(f\"Epoch{epoch}: accuracy={accuracy}, precision={precision},recall={recall}\") \n",
    "        results.loc[len(results)] = [epoch,accuracy,precision,recall]\n",
    "results.to_csv('pytorch_lstm_results_v0.csv',index=False)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "91494be0-4009-4480-b481-5679069ce805",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross validation\n",
    "# Hyperparam Tuning"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch-env",
   "language": "python",
   "name": "my-conda-env-kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
