{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "639d24cf",
   "metadata": {},
   "source": [
    "## 0. Init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "id": "3387e486",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     C:\\Users\\yongz\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "from gensim.models import Word2Vec, Doc2Vec, FastText\n",
    "from gensim.models.doc2vec import TaggedDocument\n",
    "from skorch import NeuralNetClassifier\n",
    "from sklearn import utils\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegressionCV, LogisticRegression\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import classification_report, precision_recall_fscore_support, balanced_accuracy_score, accuracy_score, recall_score\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch import utils\n",
    "from tqdm.auto import tqdm\n",
    "import re\n",
    "import time\n",
    "import warnings\n",
    "import copy\n",
    "\n",
    "import nltk\n",
    "nltk.download('vader_lexicon')\n",
    "# nltk.download('words')\n",
    "# nltk.download('wordnet')\n",
    "# nltk.download('averaged_perceptron_tagger')\n",
    "# nltk.download('maxent_ne_chunker')\n",
    "from nltk.util import bigrams\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import MWETokenizer,word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "\n",
    "warnings.filterwarnings(action='ignore')\n",
    "path = r\"{PATH}\"\n",
    "os.chdir(path)\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7fb51c9",
   "metadata": {},
   "source": [
    "## 1. Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e2e811e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence_id</th>\n",
       "      <th>Text</th>\n",
       "      <th>Verdict</th>\n",
       "      <th>Text_lower</th>\n",
       "      <th>Tokens</th>\n",
       "      <th>Tokens_lem</th>\n",
       "      <th>Tokens_no_stop</th>\n",
       "      <th>Tokens_lem_no_stop</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>I think we've seen a deterioration of values.</td>\n",
       "      <td>-1</td>\n",
       "      <td>i think we've seen a deterioration of values.</td>\n",
       "      <td>[i, think, we, 've, seen, a, deterioration, of...</td>\n",
       "      <td>[i, think, we, 've, seen, a, deterioration, of...</td>\n",
       "      <td>[think, 've, seen, deterioration, values, .]</td>\n",
       "      <td>[think, 've, seen, deterioration, value, .]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>I think for a while as a nation we condoned th...</td>\n",
       "      <td>-1</td>\n",
       "      <td>i think for a while as a nation we condoned th...</td>\n",
       "      <td>[i, think, for, a, while, as, a, nation, we, c...</td>\n",
       "      <td>[i, think, for, a, while, a, a, nation, we, co...</td>\n",
       "      <td>[think, nation, condoned, things, condemned, .]</td>\n",
       "      <td>[think, nation, condoned, thing, condemned, .]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>For a while, as I recall, it even seems to me ...</td>\n",
       "      <td>-1</td>\n",
       "      <td>for a while, as i recall, it even seems to me ...</td>\n",
       "      <td>[for, a, while, ,, as, i, recall, ,, it, even,...</td>\n",
       "      <td>[for, a, while, ,, a, i, recall, ,, it, even, ...</td>\n",
       "      <td>[,, recall, ,, even, seems, talk, legalizing, ...</td>\n",
       "      <td>[,, recall, ,, even, seems, wa, talk, legalizi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>So we've seen a deterioration in values, and o...</td>\n",
       "      <td>-1</td>\n",
       "      <td>so we've seen a deterioration in values, and o...</td>\n",
       "      <td>[so, we, 've, seen, a, deterioration, in, valu...</td>\n",
       "      <td>[so, we, 've, seen, a, deterioration, in, valu...</td>\n",
       "      <td>['ve, seen, deterioration, values, ,, one, thi...</td>\n",
       "      <td>['ve, seen, deterioration, value, ,, one, thin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>We got away, we got into this feeling that val...</td>\n",
       "      <td>-1</td>\n",
       "      <td>we got away, we got into this feeling that val...</td>\n",
       "      <td>[we, got, away, ,, we, got, into, this, feelin...</td>\n",
       "      <td>[we, got, away, ,, we, got, into, this, feelin...</td>\n",
       "      <td>[got, away, ,, got, feeling, value-, free, edu...</td>\n",
       "      <td>[got, away, ,, got, feeling, value-, free, edu...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Sentence_id                                               Text  Verdict  \\\n",
       "0            1      I think we've seen a deterioration of values.       -1   \n",
       "1            2  I think for a while as a nation we condoned th...       -1   \n",
       "2            3  For a while, as I recall, it even seems to me ...       -1   \n",
       "3            4  So we've seen a deterioration in values, and o...       -1   \n",
       "4            5  We got away, we got into this feeling that val...       -1   \n",
       "\n",
       "                                          Text_lower  \\\n",
       "0      i think we've seen a deterioration of values.   \n",
       "1  i think for a while as a nation we condoned th...   \n",
       "2  for a while, as i recall, it even seems to me ...   \n",
       "3  so we've seen a deterioration in values, and o...   \n",
       "4  we got away, we got into this feeling that val...   \n",
       "\n",
       "                                              Tokens  \\\n",
       "0  [i, think, we, 've, seen, a, deterioration, of...   \n",
       "1  [i, think, for, a, while, as, a, nation, we, c...   \n",
       "2  [for, a, while, ,, as, i, recall, ,, it, even,...   \n",
       "3  [so, we, 've, seen, a, deterioration, in, valu...   \n",
       "4  [we, got, away, ,, we, got, into, this, feelin...   \n",
       "\n",
       "                                          Tokens_lem  \\\n",
       "0  [i, think, we, 've, seen, a, deterioration, of...   \n",
       "1  [i, think, for, a, while, a, a, nation, we, co...   \n",
       "2  [for, a, while, ,, a, i, recall, ,, it, even, ...   \n",
       "3  [so, we, 've, seen, a, deterioration, in, valu...   \n",
       "4  [we, got, away, ,, we, got, into, this, feelin...   \n",
       "\n",
       "                                      Tokens_no_stop  \\\n",
       "0       [think, 've, seen, deterioration, values, .]   \n",
       "1    [think, nation, condoned, things, condemned, .]   \n",
       "2  [,, recall, ,, even, seems, talk, legalizing, ...   \n",
       "3  ['ve, seen, deterioration, values, ,, one, thi...   \n",
       "4  [got, away, ,, got, feeling, value-, free, edu...   \n",
       "\n",
       "                                  Tokens_lem_no_stop  \n",
       "0        [think, 've, seen, deterioration, value, .]  \n",
       "1     [think, nation, condoned, thing, condemned, .]  \n",
       "2  [,, recall, ,, even, seems, wa, talk, legalizi...  \n",
       "3  ['ve, seen, deterioration, value, ,, one, thin...  \n",
       "4  [got, away, ,, got, feeling, value-, free, edu...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('train.csv',\n",
    "                   dtype={'Sentence_id':int,'Text':str,'Verdict':int})\n",
    "stop_words = set(stopwords.words('english'))\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "data['Text_lower'] = data['Text'].apply(lambda x:x.lower())\n",
    "data['Tokens'] = data['Text_lower'].apply(word_tokenize)\n",
    "data['Tokens_lem'] = data['Tokens'].apply(lambda x:[lemmatizer.lemmatize(i) for i in x])\n",
    "data['Tokens_no_stop'] = data['Tokens'].map(lambda x: [w for w in x if not w.lower() in stop_words])\n",
    "data['Tokens_lem_no_stop'] = data['Tokens_lem'].map(lambda x: [w for w in x if not w.lower() in stop_words])\n",
    "data['Tokens_2'] = data['Tokens'].apply(generate_bigram_list)\n",
    "data['POS_tags'] = data['Tokens'].apply(generate_pos_list)\n",
    "data.head() # 5 seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "6a182ff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To try:\n",
    "    # Vary list of stop words excluded\n",
    "    # Further experiments with tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "id": "394e9744",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_bigram_list(word_list):\n",
    "    bg_list = list(bigrams(word_list))\n",
    "    bg_list = [' '.join(bigram) for bigram in bg_list]\n",
    "    return bg_list\n",
    "\n",
    "def generate_pos_list(token_list):\n",
    "    pos_list = nltk.pos_tag(token_list)\n",
    "    pos_list = [tup[1] for tup in pos_list]\n",
    "    return pos_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5028a8a5",
   "metadata": {},
   "source": [
    "## 2. Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "id": "880cdafb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train-Val Split\n",
    "train_idx, val_idx = train_test_split(np.arange(len(data)),random_state=1)\n",
    "train_df = data.loc[train_idx].reset_index(drop=True)\n",
    "val_df = data.loc[val_idx].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aff4fb39",
   "metadata": {},
   "source": [
    "### 2.1 Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 471,
   "id": "582fecd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NaiveBayes:\n",
    "    def __init__(self,train_data,token_col,k=1,nb_type='unigram'):\n",
    "        self.train_data = train_data\n",
    "        self.token_col = token_col\n",
    "        self.k = k\n",
    "        self.nb_type = nb_type\n",
    "        \n",
    "        # Generate corpus\n",
    "        corpus = []\n",
    "        for i in range(len(self.train_data)):\n",
    "            corpus.extend(self.train_data.at[i,token_col])\n",
    "        self.corpus = set(corpus)\n",
    "        self.V = len(self.corpus)\n",
    "        \n",
    "        # Generate aggregate likelihood df\n",
    "        prob_df = train_data['Verdict'].value_counts().reset_index()\n",
    "        prob_df['prob'] = prob_df['count']/len(train_data)\n",
    "        prob_df = prob_df.set_index('Verdict')\n",
    "        self.prob_df = prob_df\n",
    "        \n",
    "    def generate_prob(self):\n",
    "        df = self.train_data\n",
    "        token_col = self.token_col\n",
    "        V = self.V\n",
    "        k = self.k\n",
    "        corpus = self.corpus\n",
    "        \n",
    "        words_df = pd.DataFrame(columns=['word','count_impt','count_unimpt','count_false'])\n",
    "        if self.nb_type == 'unigram':\n",
    "            col_to_count = 'Tokens'\n",
    "        elif self.nb_type == 'bigram':\n",
    "            col_to_count = 'Tokens_2'\n",
    "        elif self.nb_type == 'pos':\n",
    "            col_to_count = 'POS_tags'\n",
    "        data_impt = df.loc[df['Verdict'] == 1,col_to_count].tolist()\n",
    "        data_unimpt = df.loc[df['Verdict'] == 0,col_to_count].tolist()\n",
    "        data_false = df.loc[df['Verdict'] == -1,col_to_count].tolist()\n",
    "        for word in tqdm(corpus):\n",
    "            count_impt = sum(word in text for text in data_impt)\n",
    "            count_unimpt = sum(word in text for text in data_unimpt)\n",
    "            count_false = sum(word in text for text in data_false)\n",
    "            words_df.loc[len(words_df)] = [word, count_impt, count_unimpt, count_false]\n",
    "        N_impt = words_df['count_impt'].sum()\n",
    "        N_unimpt = words_df['count_unimpt'].sum()\n",
    "        N_false = words_df['count_false'].sum()\n",
    "        self.N_impt = N_impt\n",
    "        self.N_unimpt = N_unimpt\n",
    "        self.N_false = N_false\n",
    "        words_df['prob_impt'] = (words_df['count_impt'] + k)/(N_impt + (k*V))\n",
    "        words_df['prob_unimpt'] = (words_df['count_unimpt'] + k)/(N_unimpt + (k*V))\n",
    "        words_df['prob_false'] = (words_df['count_false'] + k)/(N_false + (k*V))\n",
    "        words_df = words_df.set_index('word')\n",
    "        self.words_df = words_df\n",
    "        \n",
    "    def get_pred(self,val_data1):\n",
    "        val_data = val_data1.copy()\n",
    "        prob_df = self.prob_df\n",
    "        words_df = self.words_df\n",
    "        token_col = self.token_col\n",
    "        k = self.k\n",
    "        V = self.V\n",
    "        N_impt = self.N_impt\n",
    "        N_unimpt = self.N_unimpt\n",
    "        N_false = self.N_false\n",
    "        val_data['Prediction'] = None\n",
    "\n",
    "        for i in tqdm(range(len(val_data))):\n",
    "            prob_impt = prob_df.at[1,'prob']\n",
    "            prob_unimpt = prob_df.at[0,'prob']\n",
    "            prob_false = prob_df.at[-1,'prob']\n",
    "            for n in range(len(val_data.at[i,token_col])):\n",
    "                try:\n",
    "                    prob_impt += math.log(words_df.at[val_data.at[i,token_col][n],'prob_impt'])\n",
    "                    prob_unimpt += math.log(words_df.at[val_data.at[i,token_col][n],'prob_unimpt'])\n",
    "                    prob_false += math.log(words_df.at[val_data.at[i,token_col][n],'prob_false'])\n",
    "                except:\n",
    "                    prob_impt += math.log(k/(N_impt + (k*V)))\n",
    "                    prob_unimpt += math.log(k/(N_unimpt + (k*V)))\n",
    "                    prob_false += math.log(k/(N_false + (k*V)))\n",
    "            rank = pd.DataFrame.from_dict({'type':[1,0,-1],'prob':[prob_impt,prob_unimpt,prob_false]})\n",
    "            rank = rank.sort_values(by='prob',ascending=False).reset_index(drop=True)\n",
    "            val_data.loc[i,'prob_impt'] = prob_impt\n",
    "            val_data.loc[i,'prob_unimpt'] = prob_unimpt\n",
    "            val_data.loc[i,'prob_false'] = prob_false\n",
    "            val_data.loc[i,'Prediction'] = rank.at[0,'type']\n",
    "        \n",
    "        return val_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be30b88c",
   "metadata": {},
   "source": [
    "#### 2.1.1 Train and evaluate base unigram model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 453,
   "id": "abdaa990",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f572f695f1a40d3ad93d247af50a6fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/11105 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "899da84d05d2479d9d572b1639051c46",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5626 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Note: required for subsequent feature generation\n",
    "nb1 = NaiveBayes(train_df,'Tokens')\n",
    "nb1.generate_prob()\n",
    "val_df_nb1 = nb1.get_pred(val_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 454,
   "id": "24ae4f2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:0.7644863135442588\n",
      "Balanced accuracy:0.6083724747464544\n",
      "\n",
      "Classification metrics:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.84      0.88      0.86      3727\n",
      "           0       0.40      0.32      0.35       565\n",
      "           1       0.67      0.63      0.65      1334\n",
      "\n",
      "    accuracy                           0.76      5626\n",
      "   macro avg       0.63      0.61      0.62      5626\n",
      "weighted avg       0.75      0.76      0.76      5626\n",
      "\n"
     ]
    }
   ],
   "source": [
    "nb_control_balanced_acc = balanced_accuracy_score(val_df_nb1['Verdict'].tolist(),val_df_nb1['Prediction'].tolist())\n",
    "nb_control_acc = accuracy_score(val_df_nb1['Verdict'].tolist(),val_df_nb1['Prediction'].tolist())\n",
    "print(f'Accuracy:{nb_control_acc}')\n",
    "print(f'Balanced accuracy:{nb_control_balanced_acc}')\n",
    "print('\\nClassification metrics:\\n',classification_report(val_df_nb1['Verdict'].tolist(),val_df_nb1['Prediction'].tolist(),target_names = ['-1','0','1']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcc95e0a",
   "metadata": {},
   "source": [
    "#### 2.1.2 Train and evaluate bigram model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "id": "4e55f418",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "acfa830ede1e4491a1d37dc1a15c39ef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/93059 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b151237e168f4d2bafe754f3d5c3dfb2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5626 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "nb2 = NaiveBayes(train_df,'Tokens_2',nb_type='bigram')\n",
    "nb2.generate_prob()\n",
    "train_df_nb2 = nb2.get_pred(train_df)\n",
    "val_df_nb2 = nb2.get_pred(val_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 436,
   "id": "185262d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:0.6837895485247067\n",
      "Balanced accuracy:0.5799854171800247\n",
      "\n",
      "Classification metrics:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.84      0.76      0.80      3727\n",
      "           0       0.28      0.39      0.32       565\n",
      "           1       0.55      0.59      0.57      1334\n",
      "\n",
      "    accuracy                           0.68      5626\n",
      "   macro avg       0.55      0.58      0.56      5626\n",
      "weighted avg       0.71      0.68      0.70      5626\n",
      "\n"
     ]
    }
   ],
   "source": [
    "nb2_control_balanced_acc = balanced_accuracy_score(val_df_nb2['Verdict'].tolist(),val_df_nb2['Prediction'].tolist())\n",
    "nb2_control_acc = accuracy_score(val_df_nb2['Verdict'].tolist(),val_df_nb2['Prediction'].tolist())\n",
    "print(f'Accuracy:{nb2_control_acc}')\n",
    "print(f'Balanced accuracy:{nb2_control_balanced_acc}')\n",
    "print('\\nClassification metrics:\\n',classification_report(val_df_nb2['Verdict'].tolist(),val_df_nb2['Prediction'].tolist(),target_names = ['-1','0','1']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "675d8348",
   "metadata": {},
   "source": [
    "#### 2.1.3 Ablation Study for Naive Bayes\n",
    "Impact analysis for the following variables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e45c819e",
   "metadata": {},
   "source": [
    "**Lemmatization**\n",
    "\n",
    "Lemmatize individual tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 514,
   "id": "d9619228",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c8054f16deec4bf195b9f62005a291f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9912 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "55efb76c33bb416bac55250532c581b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5626 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "nb1_lem = NaiveBayes(train_df,'Tokens_lem')\n",
    "nb1_lem.generate_prob()\n",
    "val_df_nb1_lem = nb1_lem.get_pred(val_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 515,
   "id": "fc65190b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:0.6133605123896734\n",
      "Balanced accuracy comparison:\n",
      "control:0.6083724747464544, treatment:0.6133605123896734\n",
      "\n",
      "Classification metrics:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.85      0.85      0.85      3727\n",
      "           0       0.34      0.34      0.34       565\n",
      "           1       0.64      0.65      0.64      1334\n",
      "\n",
      "    accuracy                           0.75      5626\n",
      "   macro avg       0.61      0.61      0.61      5626\n",
      "weighted avg       0.75      0.75      0.75      5626\n",
      "\n"
     ]
    }
   ],
   "source": [
    "nb_lem_acc = accuracy_score(val_df_nb1_lem['Verdict'].tolist(),val_df_nb1_lem['Prediction'].tolist())\n",
    "nb_lem_balanced_acc = balanced_accuracy_score(val_df_nb1_lem['Verdict'].tolist(),val_df_nb1_lem['Prediction'].tolist())\n",
    "print(f'Accuracy:{nb_lem_balanced_acc}')\n",
    "print(f'Balanced accuracy comparison:\\ncontrol:{nb_control_balanced_acc}, treatment:{nb_lem_balanced_acc}')\n",
    "print('\\nClassification metrics:\\n',classification_report(val_df_nb1_lem['Verdict'].tolist(),val_df_nb1_lem['Prediction'].tolist(),target_names = ['-1','0','1']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83dc9cb7",
   "metadata": {},
   "source": [
    "**Stop Words**\n",
    "\n",
    "Remove stop words from text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 516,
   "id": "549d8c7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f48319424d094629bff15ef26d544495",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10976 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e43ce784f2e543429071a663d9380277",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5626 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "nb1_sw = NaiveBayes(train_df,'Tokens_no_stop')\n",
    "nb1_sw.generate_prob()\n",
    "val_df_nb1_sw = nb1_sw.get_pred(val_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 517,
   "id": "22dec2ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:0.7488446498400284\n",
      "Balanced accuracy comparison:\n",
      "control:0.6083724747464544, treatment:0.5956504110565249\n",
      "\n",
      "Classification metrics:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.83      0.86      0.85      3727\n",
      "           0       0.37      0.31      0.34       565\n",
      "           1       0.64      0.61      0.62      1334\n",
      "\n",
      "    accuracy                           0.75      5626\n",
      "   macro avg       0.61      0.60      0.60      5626\n",
      "weighted avg       0.74      0.75      0.74      5626\n",
      "\n"
     ]
    }
   ],
   "source": [
    "nb_sw_acc = accuracy_score(val_df_nb1_sw['Verdict'].tolist(),val_df_nb1_sw['Prediction'].tolist())\n",
    "nb_sw_balanced_acc = balanced_accuracy_score(val_df_nb1_sw['Verdict'].tolist(),val_df_nb1_sw['Prediction'].tolist())\n",
    "print(f'Accuracy:{nb_sw_acc}')\n",
    "print(f'Balanced accuracy comparison:\\ncontrol:{nb_control_balanced_acc}, treatment:{nb_sw_balanced_acc}')\n",
    "print('\\nClassification metrics:\\n',classification_report(val_df_nb1_sw['Verdict'].tolist(),val_df_nb1_sw['Prediction'].tolist(),target_names = ['-1','0','1']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a76842e1",
   "metadata": {},
   "source": [
    "**Case**\n",
    "\n",
    "Preserve Uppercase letters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e059bbae",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['Tokens_case'] = train_df['Text'].apply(word_tokenize)\n",
    "nb1_case = NaiveBayes(train_df,'Tokens_case')\n",
    "nb1_case.generate_prob()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 521,
   "id": "bc8b849f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "10bb2c579edd416a9c963fd9fe8829c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5626 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "val_df['Tokens_case'] = val_df['Text'].apply(word_tokenize)\n",
    "val_df_nb1_case = nb1_case.get_pred(val_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 522,
   "id": "a663e023",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy comparison:0.654639175257732\n",
      "Balanced accuracy comparison:\n",
      "control:0.6083724747464544, treatment:0.6311573992821279\n",
      "\n",
      "Classification metrics:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.89      0.68      0.77      3727\n",
      "           0       0.24      0.60      0.34       565\n",
      "           1       0.60      0.61      0.61      1334\n",
      "\n",
      "    accuracy                           0.65      5626\n",
      "   macro avg       0.58      0.63      0.57      5626\n",
      "weighted avg       0.76      0.65      0.69      5626\n",
      "\n"
     ]
    }
   ],
   "source": [
    "nb_case_acc = accuracy_score(val_df_nb1_case['Verdict'].tolist(),val_df_nb1_case['Prediction'].tolist())\n",
    "nb_case_balanced_acc = balanced_accuracy_score(val_df_nb1_case['Verdict'].tolist(),val_df_nb1_case['Prediction'].tolist())\n",
    "print(f'Accuracy comparison:{nb_case_acc}')\n",
    "print(f'Balanced accuracy comparison:\\ncontrol:{nb_control_balanced_acc}, treatment:{nb_case_balanced_acc}')\n",
    "print('\\nClassification metrics:\\n',classification_report(val_df_nb1_case['Verdict'].tolist(),val_df_nb1_case['Prediction'].tolist(),target_names = ['-1','0','1']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2c86c2b",
   "metadata": {},
   "source": [
    "### 2.2 Logistic Regression\n",
    "#### 2.2.1 Feature Engineering\n",
    "*Note that the features engineered here are also applicable to the Neural Network models\n",
    "\n",
    "**Sandbox Utils**\n",
    "\n",
    "Experimental code has been removed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b08ed664",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_dist(verdict_df):\n",
    "    total = float(len(verdict_df))\n",
    "    try:\n",
    "        impt = float(verdict_df.value_counts()[1])\n",
    "    except: impt = 0\n",
    "    try:\n",
    "        not_impt = float(verdict_df.value_counts()[0])\n",
    "    except:\n",
    "        not_impt = 0\n",
    "    try:\n",
    "        false = float(verdict_df.value_counts()[-1])\n",
    "    except:\n",
    "        false = 0\n",
    "    print('important %:',impt/total,'not important %:',not_impt/total,'false %:',false/total)\n",
    "\n",
    "def feature_test(substr):\n",
    "    if data['Text'].str.contains(substr).any():\n",
    "        test_0 = data.loc[data['Text'].str.contains(substr),'Text'].to_list()\n",
    "        verdict_df = data.loc[data['Text'].str.contains(substr),'Verdict']\n",
    "        test_1 = verdict_df.to_list()\n",
    "        test = list(zip(test_0,test_1))\n",
    "        eval_dist(verdict_df)\n",
    "        return test\n",
    "    else:\n",
    "        print('substring not found')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "843956b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "list(data.loc[data['Verdict']==-1,'Text'].to_numpy()[np.random.choice(10000,20)]) # False examples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db11df69",
   "metadata": {},
   "source": [
    "**Feature Generation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 455,
   "id": "b1f00c6c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f84048f88172461085482d041aa95a99",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16875 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "19bde28c4b474f45b758bde5e8a6194b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5626 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Generate bayesian probabilities for datasets\n",
    "\n",
    "train_df_likelihood = nb1.get_pred(train_df)\n",
    "val_df_likelihood = nb1.get_pred(val_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "id": "301f5a84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# *Getting top words per category:\n",
    "def get_top_tokens(nb_obj):\n",
    "    words_df = nb_obj.words_df\n",
    "    total_word_count = nb_obj.N_impt + nb_obj.N_unimpt + nb_obj.N_false\n",
    "    texts_impt_count = train_df['Verdict'].value_counts()[1]\n",
    "    texts_unimpt_count = train_df['Verdict'].value_counts()[0]\n",
    "    texts_false_count = train_df['Verdict'].value_counts()[-1]\n",
    "    total_text_count = len(train_df)\n",
    "    impt_prior = texts_impt_count/total_text_count\n",
    "    unimpt_prior = texts_unimpt_count/total_text_count\n",
    "    false_prior = texts_false_count/total_text_count\n",
    "\n",
    "    words_df['prob_post_impt'] = words_df.apply(lambda r: r.prob_impt*impt_prior/((r.count_impt+r.count_unimpt+r.count_false)/total_word_count),axis=1)\n",
    "    words_df['prob_post_unimpt'] = words_df.apply(lambda r: r.prob_unimpt*unimpt_prior/((r.count_impt+r.count_unimpt+r.count_false)/total_word_count),axis=1)\n",
    "    words_df['prob_post_false'] = words_df.apply(lambda r: r.prob_false*false_prior/((r.count_impt+r.count_unimpt+r.count_false)/total_word_count),axis=1)\n",
    "\n",
    "    top_impt = words_df.sort_values('prob_post_impt',ascending=False).head(2000).index.tolist()\n",
    "    top_unimpt = words_df.sort_values('prob_post_unimpt',ascending=False).head(2000).index.tolist()\n",
    "    top_false = words_df.sort_values('prob_post_false',ascending=False).head(2000).index.tolist()\n",
    "    \n",
    "    return top_impt, top_unimpt, top_false\n",
    "\n",
    "top_impt, top_unimpt, top_false = get_top_tokens(nb1) # unigrams\n",
    "top_impt_bg, top_unimpt_bg, top_false_bg = get_top_tokens(nb2) # bigrams\n",
    "        \n",
    "def count_top_tokens(token_list,target_list):\n",
    "    count = 0\n",
    "    for w in token_list:\n",
    "        if w in target_list:\n",
    "            count += token_list.count(w)\n",
    "    return count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "77ef3c60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# *Named entity recognition\n",
    "\n",
    "def identify_names(text):\n",
    "    result = 0\n",
    "    for chunk in nltk.ne_chunk(nltk.pos_tag(word_tokenize(text))):\n",
    "        if hasattr(chunk,'label'):\n",
    "            result += 1\n",
    "            break\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f4c06088",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "259df999447542f0bd5d8c0f735c7afb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16875 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f144b603e0164eff8c19470de983fd77",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5626 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# *Average of word vectors\n",
    "\n",
    "ft_size = 100\n",
    "corpus = train_df['Tokens'].tolist()\n",
    "ft = FastText(corpus,vector_size=ft_size,epochs=10)\n",
    "\n",
    "def generate_ft_avg(token_list,ft_size,model):\n",
    "    vector = np.zeros(ft_size)\n",
    "    for token in token_list:\n",
    "        vector += model.wv[token]\n",
    "    vector /= len(token_list)\n",
    "    return vector\n",
    "        \n",
    "def generate_ft_emb(df,model):\n",
    "    emb = []\n",
    "    for i in tqdm(range(len(df))):\n",
    "        emb.append(generate_ft_avg(df.at[i,'Tokens'],model))\n",
    "    return np.array(emb)\n",
    "\n",
    "X_train_ft = generate_ft_emb(train_df,ft)\n",
    "X_val_ft = generate_ft_emb(val_df,ft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ee0a96c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# *Sentiment of text\n",
    "\n",
    "sentiment_analyzer = SentimentIntensityAnalyzer()\n",
    "def generate_sentiment(text,analyzer,sentiment_type):\n",
    "    '''\n",
    "    type: pos | neg | neu | compound \n",
    "    '''\n",
    "    scores = analyzer.polarity_scores(text)\n",
    "    return scores[sentiment_type]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "bac6f04b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# *Frequency of stopwords\n",
    "\n",
    "def generate_stopword_count(token_list,stop_words):\n",
    "    count = 0\n",
    "    for token in token_list:\n",
    "        if token in stop_words:count += 1\n",
    "    return count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 477,
   "id": "25cbc5f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e64ee532d8b940f9ac2cc2532d1b0c85",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/45 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "809111fac76a47b2bed29f824bbd5935",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16875 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a30969ed394d4613981a83b441ef67ff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5626 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# *POS tags\n",
    "nb_pos = NaiveBayes(train_df,'POS_tags',nb_type='pos')\n",
    "nb_pos.generate_prob()\n",
    "train_df_nb_pos = nb_pos.get_pred(train_df)\n",
    "val_df_nb_pos = nb_pos.get_pred(val_df)\n",
    "\n",
    "# Marginal impact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 457,
   "id": "6af4a3ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_logreg_features(df,df_likelihood,bg_likelihood,pos_likelihood):\n",
    "    '''\n",
    "    Brainstorm:\n",
    "    Me pronouns - I, You, me\n",
    "    Collective pronouns - they,\n",
    "    Presence of numbers (numeric or spelt)\n",
    "    Filler words - uh or uhh\n",
    "    ' - ' or '--'\n",
    "    No. of words with highest bayesian likelihoods per class ** (didn't work)\n",
    "    Acronyms\n",
    "    Mr(s) and Senator\n",
    "    Identify names (NER)\n",
    "    \n",
    "    Sentiment scores?\n",
    "    '''\n",
    "    df_log = df.copy()\n",
    "    \n",
    "    # Features: Hard-coded\n",
    "    df_log['_1'] = df_log['Text'].str.contains('!').astype(int)\n",
    "    df_log['_2'] = df_log['Text'].str.contains('\\?').astype(int)\n",
    "    df_log['_3'] = df_log['Text'].map(len) # Try len of token list\n",
    "    df_log['_4'] = df_log['Text'].str.count('I |me |[Yy]ou ')\n",
    "    df_log['_5'] = df_log['Text'].str.count('[Ww]e |[Tt]hey |us[. ]')\n",
    "    df_log['_6'] = df_log['Text'].str.contains('[Uu][h]+ ').astype(int)\n",
    "    df_log['_7'] = df_log['Text'].str.contains(' [-]+ ').astype(int)\n",
    "    df_log['_8'] = df_log['Text'].str.contains(num_pattern).astype(int)\n",
    "    df_log['_9'] = df_log['Text'].str.contains('[A-Z]{2,}').astype(int)\n",
    "    df_log['_10'] = df_log['Text'].str.contains('Mr[s]?|Senator').astype(int)\n",
    "    df_log['_11'] = df_log['Text'].map(identify_names)\n",
    "    df_log['_12'] = df_log['Text'].apply(lambda x: generate_sentiment(x,sentiment_analyzer,'pos'))\n",
    "    df_log['_13'] = df_log['Text'].apply(lambda x: generate_sentiment(x,sentiment_analyzer,'neu'))\n",
    "    df_log['_14'] = df_log['Text'].apply(lambda x: generate_sentiment(x,sentiment_analyzer,'neg'))\n",
    "    df_log['_15'] = df_log['Tokens'].map(lambda x: generate_stopword_count(x,stop_words))\n",
    "    \n",
    "#     df_log['_16'] = df_log['Tokens_2'].apply(lambda x:count_top_words(x,top_impt))\n",
    "#     df_log['_17'] = df_log['Tokens_2'].apply(lambda x:count_top_words(x,top_unimpt))\n",
    "#     df_log['_18'] = df_log['Tokens_2'].apply(lambda x:count_top_words(x,top_false))\n",
    "\n",
    "    # Features: Bayesian likelihood\n",
    "    temp_cols = ['impt','unimpt','false'] \n",
    "    temp = list(zip(['_BL1','_BL2','_BL3'],temp_cols))\n",
    "    for feature,col in temp:\n",
    "        df_log[feature] = df_likelihood[f'prob_{col}']\n",
    "        \n",
    "    temp_bg = list(zip(['_BG1','_BG2','_BG3'],temp_cols))\n",
    "    for feature,col in temp_bg:\n",
    "        df_log[feature] = bg_likelihood[f'prob_{col}']\n",
    "        \n",
    "    temp_pos = list(zip(['_POS1','_POS2','_POS3'],temp_cols))\n",
    "    for feature,col in temp_pos:\n",
    "        df_log[feature] = pos_likelihood[f'prob_{col}']\n",
    "\n",
    "    return df_log\n",
    "\n",
    "def select_cols(end_col_num=None,col_list=None,Bayesian=True,Bigram=True,POS=True):\n",
    "    '''\n",
    "    col_list: e.g. [1,6,8,...]\n",
    "    '''\n",
    "    col_list0 = []\n",
    "    if col_list == None:\n",
    "        for i in range(end_col_num):\n",
    "            col_list0.append(f'_{i+1}')\n",
    "    else:\n",
    "        for i in col_list:\n",
    "            col_list0.append(f'_{i}')\n",
    "    if Bayesian == True:\n",
    "        col_list0.extend(['_BL1','_BL2','_BL3'])\n",
    "    if Bigram == True:\n",
    "        col_list0.extend(['_BG1','_BG2','_BG3'])\n",
    "    if POS == True:\n",
    "        col_list0.extend(['_POS1','_POS2','_POS3'])\n",
    "    return col_list0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 458,
   "id": "c9b33388",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To re-run this cell after every feature update\n",
    "train_df_log = generate_logreg_features(train_df,train_df_likelihood,train_df_nb2,train_df_nb_pos)\n",
    "val_df_log = generate_logreg_features(val_df,val_df_likelihood,val_df_nb2,val_df_nb_pos)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c58fc263",
   "metadata": {},
   "source": [
    "#### 2.2.2 Train and Evaluate Base Model\n",
    "Features only, without embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 492,
   "id": "79811f58",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train_0 = train_df_log[select_cols(end_col_num=15,Bigram=False)].to_numpy() # all features\n",
    "X_train_0 = scaler.fit_transform(X_train_0)\n",
    "y_train = train_df_log['Verdict'].to_numpy()\n",
    "X_val_0 = val_df_log[select_cols(end_col_num=15,Bigram=False)].to_numpy() # all features\n",
    "X_val_0 = scaler.fit_transform(X_val_0)\n",
    "y_val = val_df_log['Verdict'].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 494,
   "id": "83c0d0fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7808389619623178\n",
      "0.5663351825966391\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.81      0.94      0.87      3727\n",
      "           0       0.55      0.16      0.25       565\n",
      "           1       0.72      0.60      0.65      1334\n",
      "\n",
      "    accuracy                           0.78      5626\n",
      "   macro avg       0.69      0.57      0.59      5626\n",
      "weighted avg       0.76      0.78      0.75      5626\n",
      "\n"
     ]
    }
   ],
   "source": [
    "logreg_clf1 = LogisticRegression(max_iter=500)\n",
    "logreg_clf1.fit(X_train_0,y_train)\n",
    "y_pred1 = logreg_clf1.predict(X_val_0)\n",
    "print(accuracy_score(y_val,y_pred1))\n",
    "print(balanced_accuracy_score(y_val,y_pred1))\n",
    "print(classification_report(y_val,y_pred1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "id": "2557634d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5511084706156364"
      ]
     },
     "execution_count": 353,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "balanced_accuracy_score(y_val,y_pred1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bd222b2",
   "metadata": {},
   "source": [
    "#### 2.2.3 Ablation Study"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccbb1286",
   "metadata": {},
   "source": [
    "Features + Doc Embeddings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7255b0a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2d2860457de04bbc83e9f2a273abd96c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Features: Document embeddings\n",
    "def generate_taggeddocs(df):\n",
    "    base_df = df[['Tokens','Verdict']]\n",
    "    d2v_df_temp = base_df.apply(lambda r: TaggedDocument(words=r['Tokens'],\n",
    "                                        tags=[r.Verdict]),axis=1)\n",
    "    d2v_values = d2v_df_temp.tolist()\n",
    "    return d2v_values\n",
    "\n",
    "d2v_train_values = generate_taggeddocs(train_df_log)\n",
    "d2v = Doc2Vec(vector_size=300, epochs=40) # Tune\n",
    "d2v.build_vocab(d2v_train_values)\n",
    "for epoch in tqdm(range(50)):\n",
    "    d2v.train(utils.shuffle(d2v_train_values),total_examples=len(d2v_train_values),epochs=1)\n",
    "    d2v.alpha -= 0.002 # can tune\n",
    "    d2v.min_alpha = d2v.alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "id": "dcc8c83b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_d2v = np.array([d2v.infer_vector(doc.words) for doc in d2v_train_values]) # Embeddings only\n",
    "X_train = np.concatenate((X_train_0,X_train_d2v),axis=1) # all features + emb\n",
    "d2v_val_values = generate_taggeddocs(val_df_log)\n",
    "X_val_d2v = np.array([d2v.infer_vector(doc.words) for doc in d2v_val_values]) # Embeddings only\n",
    "X_val = np.concatenate((X_val_0,X_val_d2v),axis=1) # all features + emb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 491,
   "id": "3675cc3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7579097049413438\n",
      "0.5506263748057397\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.80      0.91      0.85      3727\n",
      "           0       0.46      0.16      0.24       565\n",
      "           1       0.65      0.58      0.61      1334\n",
      "\n",
      "    accuracy                           0.76      5626\n",
      "   macro avg       0.64      0.55      0.57      5626\n",
      "weighted avg       0.73      0.76      0.73      5626\n",
      "\n"
     ]
    }
   ],
   "source": [
    "logreg_clf2 = LogisticRegression(max_iter=1000)\n",
    "logreg_clf2.fit(X_train,y_train)\n",
    "y_pred2 = logreg_clf2.predict(X_val)\n",
    "print(accuracy_score(y_val,y_pred2))\n",
    "print(balanced_accuracy_score(y_val,y_pred2))\n",
    "print(classification_report(y_val,y_pred2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9768bca",
   "metadata": {},
   "source": [
    "Just Doc Embeddings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "id": "2b17bfd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.68      0.98      0.80      3727\n",
      "           0       0.00      0.00      0.00       565\n",
      "           1       0.55      0.09      0.16      1334\n",
      "\n",
      "    accuracy                           0.67      5626\n",
      "   macro avg       0.41      0.36      0.32      5626\n",
      "weighted avg       0.58      0.67      0.57      5626\n",
      "\n"
     ]
    }
   ],
   "source": [
    "logreg_clf3 = LogisticRegression(max_iter=500)\n",
    "logreg_clf3.fit(X_train_d2v,y_train)\n",
    "y_pred3 = logreg_clf3.predict(X_val_d2v)\n",
    "print(classification_report(y_val,y_pred3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "440d6efd",
   "metadata": {},
   "source": [
    "Just Word Embeddings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "id": "7b1952f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.79      0.92      0.85      3727\n",
      "           0       0.45      0.13      0.20       565\n",
      "           1       0.65      0.54      0.59      1334\n",
      "\n",
      "    accuracy                           0.75      5626\n",
      "   macro avg       0.63      0.53      0.55      5626\n",
      "weighted avg       0.72      0.75      0.72      5626\n",
      "\n"
     ]
    }
   ],
   "source": [
    "logreg_clf4 = LogisticRegression(max_iter=500)\n",
    "logreg_clf4.fit(X_train_ft,y_train)\n",
    "y_pred4 = logreg_clf4.predict(X_val_ft)\n",
    "print(classification_report(y_val,y_pred4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9352334",
   "metadata": {},
   "source": [
    "Word Embeddings + Features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 432,
   "id": "75b54076",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7619978670458585\n",
      "0.5562256077144367\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.80      0.92      0.86      3727\n",
      "           0       0.48      0.18      0.26       565\n",
      "           1       0.67      0.57      0.62      1334\n",
      "\n",
      "    accuracy                           0.76      5626\n",
      "   macro avg       0.65      0.56      0.58      5626\n",
      "weighted avg       0.74      0.76      0.74      5626\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X_train_ft1 = np.concatenate((X_train_0,X_train_ft),axis=1) # all features + FT emb\n",
    "X_val_ft1 = np.concatenate((X_val_0,X_val_ft),axis=1) # all features + FT emb\n",
    "logreg_clf5 = LogisticRegression()\n",
    "logreg_clf5.fit(X_train_ft1,y_train)\n",
    "y_pred5 = logreg_clf5.predict(X_val_ft1)\n",
    "print(accuracy_score(y_val,y_pred5) )\n",
    "print(balanced_accuracy_score(y_val,y_pred5))\n",
    "print(classification_report(y_val,y_pred5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45a56466",
   "metadata": {},
   "source": [
    "Test different feature combinations to get best val results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 499,
   "id": "1c272e6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7842161393530039\n",
      "0.5941908865394395\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.82      0.93      0.87      3727\n",
      "           0       0.52      0.24      0.32       565\n",
      "           1       0.71      0.62      0.66      1334\n",
      "\n",
      "    accuracy                           0.78      5626\n",
      "   macro avg       0.68      0.59      0.62      5626\n",
      "weighted avg       0.76      0.78      0.77      5626\n",
      "\n"
     ]
    }
   ],
   "source": [
    "temp_col_list = [1,2,3,4,5,6,7,8,9,10,11,12,13,14,15]\n",
    "X_train_2 = train_df_log[select_cols(col_list=temp_col_list,Bigram=False)].to_numpy()\n",
    "# X_train_2 = train_df_log[select_cols(end_col_num=15,Bigram=False)].to_numpy()\n",
    "X_train_2 = scaler.fit_transform(X_train_2)\n",
    "X_val_2 = val_df_log[select_cols(col_list=temp_col_list,Bigram=False)].to_numpy()\n",
    "# X_val_2 = val_df_log[select_cols(end_col_num=15,Bigram=False)].to_numpy()\n",
    "X_val_2 = scaler.fit_transform(X_val_2)\n",
    "X_train_ft2 = np.concatenate((X_train_2,X_train_ft),axis=1) # all features + FT emb\n",
    "X_val_ft2 = np.concatenate((X_val_2,X_val_ft),axis=1) # all features + FT emb\n",
    "logreg_clf6 = LogisticRegression()\n",
    "logreg_clf6.fit(X_train_ft2,y_train)\n",
    "y_pred6 = logreg_clf6.predict(X_val_ft2)\n",
    "print(accuracy_score(y_val,y_pred6))\n",
    "print(balanced_accuracy_score(y_val,y_pred6))\n",
    "print(classification_report(y_val,y_pred6))\n",
    "\n",
    "# 0.7842161393530039\n",
    "# 0.5941908865394395"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 513,
   "id": "2310eebd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.25792505, -0.25041781,  0.56375018,  0.02001205,  0.04213407,\n",
       "        0.78444148, -0.21239551,  0.1095592 ,  0.12627011, -0.14101416,\n",
       "        0.49108066, -0.25837697, -0.46287509,  0.03085525,  0.30895309,\n",
       "        0.49858017,  0.14578567,  0.20938721,  0.08791701,  0.41204225,\n",
       "        0.25806333,  0.19489786, -0.37420876,  0.25441852, -0.20194479,\n",
       "       -0.34077031,  0.55715071,  0.09016396,  0.58312911,  0.07695484,\n",
       "        0.11397774,  0.20077722,  0.19239341,  0.10101745,  0.22540026,\n",
       "        0.52902543, -0.89207404, -0.49265925,  0.10659941, -0.12813442,\n",
       "       -0.05903449, -0.069048  , -0.14622801,  0.62300087, -0.05370399,\n",
       "       -0.2370373 , -0.37053659,  0.05917016, -0.16815537, -0.14304047,\n",
       "       -0.89829032, -0.55927079,  0.2026039 , -0.21964684,  0.19578068,\n",
       "        0.50884602, -0.00353546, -0.06262991, -0.80183266,  0.34847094,\n",
       "       -0.23624475,  0.0373517 , -0.38931693,  0.32732837,  0.00699078,\n",
       "       -0.69703807, -0.46258959,  0.1837601 , -0.34539193, -0.16589576,\n",
       "       -0.05977418,  0.13713212,  0.37079181, -0.16906475,  0.27036558,\n",
       "       -0.52711247,  0.59217543,  0.10054491, -0.04919842,  0.54692302,\n",
       "       -0.0277036 ,  0.0035564 ,  0.31933785, -0.88767902, -0.13991503,\n",
       "       -0.66004267,  0.01168042,  0.17271503,  0.09214592, -1.28524459,\n",
       "        0.4756735 , -0.28637788, -0.04413738,  0.85564081, -0.47981742,\n",
       "        0.48384013,  0.00809255,  0.93848352,  0.75598677])"
      ]
     },
     "execution_count": 513,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(logreg_clf6.coef_)[1,22:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0863a7a",
   "metadata": {},
   "source": [
    "### Artificial Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42b1144f",
   "metadata": {},
   "source": [
    "#### Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "id": "1b3a7add",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_tensor(X,dtype):\n",
    "    X = torch.from_numpy(X)\n",
    "    if dtype =='float':\n",
    "        X = X.type(torch.FloatTensor)\n",
    "    elif dtype == 'long':\n",
    "        X = X.type(torch.LongTensor)\n",
    "    return X\n",
    "\n",
    "def convert_y(y):\n",
    "    y_nn = np.zeros([y.shape[0],3])\n",
    "    for i in range(len(y)):\n",
    "        if y[i] == -1:\n",
    "            y_nn[i,0] = 1\n",
    "        elif y[i] == 0:\n",
    "            y_nn[i,1] = 1\n",
    "        elif y[i] == 1: \n",
    "            y_nn[i,2] = 1\n",
    "    return y_nn\n",
    "\n",
    "# Troubleshooting\n",
    "def check_dist(arr):\n",
    "    unique, counts = np.unique(arr,return_counts=True)\n",
    "    print(list(zip(unique,counts)))\n",
    "\n",
    "y_train_nn = convert_tensor(convert_y(y_train),'float')\n",
    "y_val_nn = convert_tensor(convert_y(y_val),'float')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bad2c1ab",
   "metadata": {},
   "source": [
    "#### Basic Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "be3ded4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Init\n",
    "\n",
    "class ANN(nn.Module):\n",
    "    def __init__(self,input_size,\n",
    "                 num_units1,num_units2,\n",
    "#                  num_units3,\n",
    "                 act1,act2,\n",
    "#                  act3\n",
    "                ):\n",
    "        super().__init__()\n",
    "        self.hidden1 = nn.Linear(input_size,num_units1)\n",
    "        self.act1 = act1\n",
    "#         self.dropout1 = nn.Dropout(0.1)\n",
    "#         self.hidden2 = nn.Linear(num_units1,num_units2) # tune\n",
    "#         self.act2 = act2 # tune\n",
    "#         self.dropout2 = nn.Dropout(0.1)\n",
    "#         self.hidden3 = nn.Linear(num_units2,num_units3) # tune\n",
    "#         self.act3 = act3 # tune        \n",
    "        self.output = nn.Linear(num_units1,3) # tune\n",
    "        self.softmax = nn.Softmax(dim=1) # tune\n",
    "    def forward(self,x):\n",
    "        x = self.hidden1(x)\n",
    "        x = self.act1(x)\n",
    "#         x = self.dropout1(x)\n",
    "#         x = self.hidden2(x)\n",
    "#         x = self.act2(x)\n",
    "#         x = self.dropout2(x)\n",
    "#         x = self.hidden3(x)\n",
    "#         x = self.act3(x)\n",
    "        x = self.output(x)\n",
    "        x = self.softmax(x)\n",
    "        return x\n",
    "\n",
    "# Set up datasets\n",
    "# # Choose datasets based on feature choice\n",
    "X_train_base = scaler.fit_transform(train_df_log[select_cols(end_col_num=11)].to_numpy()) # selected features\n",
    "X_val_base = scaler.fit_transform(val_df_log[select_cols(end_col_num=11)].to_numpy())\n",
    "X_train_chosen = X_train_ft\n",
    "X_val_chosen = X_val_ft\n",
    "# X_train_chosen = X_train_base\n",
    "# X_val_chosen = X_val_base\n",
    "# X_train_chosen = np.concatenate((X_train_base,X_train_d2v),axis=1)\n",
    "# X_val_chosen = np.concatenate((X_val_base,X_val_d2v),axis=1)\n",
    "# X_train_chosen = X_train_d2v\n",
    "# X_val_chosen = X_val_d2v\n",
    "\n",
    "# # Process datasets\n",
    "input_size = X_train_chosen.shape[1]\n",
    "X_train_nn = convert_tensor(X_train_chosen,'float')\n",
    "X_val_nn = convert_tensor(X_val_chosen,'float')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "id": "abf588e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train model\n",
    "def train_ann_model(model,file_name,loss_fn,optimizer,loader,cat=False,**kwargs):\n",
    "    \n",
    "    X_val_text_nn, X_val_ftr_nn = kwargs.get('X_val_text_nn', None),kwargs.get('X_val_ftr_nn', None)\n",
    "    n_epochs = 40\n",
    "    results_df = pd.DataFrame(columns=['epoch','bal_accuracy','precision','recall','fscore','support'])\n",
    "    epoch_loss = []\n",
    "    best_loss = float('inf')\n",
    "    \n",
    "    for epoch in tqdm(range(n_epochs)):\n",
    "        model.train()\n",
    "        if cat==False:\n",
    "            for X_batch, y_batch in loader:\n",
    "                y_pred_batch = model(X_batch)\n",
    "                loss = loss_fn(y_pred_batch,y_batch)\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "        elif cat==True:\n",
    "            for X_text_batch,X_ftr_batch,y_batch in loader:\n",
    "                y_pred_batch = model(X_text_batch,X_ftr_batch)\n",
    "                loss = loss_fn(y_pred_batch,y_batch)\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "        model.eval()\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            if cat==False:\n",
    "                y_pred_nn = model(X_val_nn)\n",
    "            elif cat==True:\n",
    "                y_pred_nn = model(X_val_text_nn,X_val_ftr_nn)\n",
    "                        \n",
    "            y_pred = torch.argmax(y_pred_nn,1)\n",
    "            y_pred = y_pred.numpy()\n",
    "            y_pred[y_pred==0] = -1\n",
    "            y_pred[y_pred==1] = 0\n",
    "            y_pred[y_pred==2] = 1\n",
    "            check_dist(y_pred)\n",
    "            bal_accuracy = balanced_accuracy_score(y_val,y_pred)\n",
    "            epoch_loss.append(loss)\n",
    "            precision, recall, fscore, support = precision_recall_fscore_support(y_val,y_pred,average='weighted')\n",
    "            results_df.loc[len(results_df)] = [epoch+1,bal_accuracy, precision,recall,fscore,support]\n",
    "            val_loss = loss_fn(y_pred_nn,y_val_nn)\n",
    "            tqdm.write(f\"Epoch{epoch+1}: val loss={val_loss}, balanced accuracy={bal_accuracy}, precision={precision}, recall={recall}, fscore={fscore}\")\n",
    "            \n",
    "            # Early Stopping\n",
    "            if val_loss < best_loss:\n",
    "                best_loss = val_loss\n",
    "                best_model_weights = copy.deepcopy(model.state_dict())\n",
    "                patience = 10\n",
    "            else:\n",
    "                patience -= 1\n",
    "                if patience == 0:\n",
    "                    break\n",
    "    \n",
    "    torch.save(best_model_weights,file_name)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d132e6b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Init\n",
    "# # Parameter experimentation (pre-tuning)\n",
    "num_units1 = 80\n",
    "num_units2 = 60\n",
    "num_units3 = 5\n",
    "act1 = nn.ELU()\n",
    "act2 = nn.Sigmoid()\n",
    "act3 = nn.Sigmoid()\n",
    "\n",
    "# # Core Init\n",
    "ann0 = ANN(input_size,\n",
    "           num_units1,num_units2,\n",
    "#            num_units3,\n",
    "           act1,act2\n",
    "#            ,act3\n",
    "          )\n",
    "optimizer = optim.Adam(ann0.parameters(),lr=0.004) # tune\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "loader = utils.data.DataLoader(utils.data.TensorDataset(X_train_nn,y_train_nn),batch_size=2)\n",
    "ann0 = train_ann_model(ann0,'ann1.pt',loss_fn,optimizer,loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d26d730a",
   "metadata": {},
   "source": [
    "#### Neural Network with Concat Structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 540,
   "id": "6b28888d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Init\n",
    "\n",
    "class ANN_Cat(nn.Module):\n",
    "    def __init__(self,\n",
    "                 input_size_text,input_size_ftr,\n",
    "                 num_units_text1,num_units_text2,num_units_ftr1,num_units_ftr2,num_units_comb1,num_units_comb2,\n",
    "                 act_text1,act_ftr1,act_comb1 \n",
    "                ):\n",
    "        super().__init__()\n",
    "        self.hidden_text1 = nn.Linear(input_size_text,num_units_text1)\n",
    "        self.act_text1 = act_text1\n",
    "# #         self.dropout1 = nn.Dropout(0.1)\n",
    "#         self.hidden_text2 = nn.Linear(num_units_text1,num_units_text2)\n",
    "#         self.act_text2 = act_text2\n",
    "        \n",
    "        self.hidden_ftr1 = nn.Linear(input_size_ftr,num_units_ftr1)\n",
    "        self.act_ftr1 = act_ftr1\n",
    "#         self.dropout2 = nn.Dropout(0.1)\n",
    "        self.hidden_ftr2 = nn.Linear(num_units_ftr1,num_units_ftr2)\n",
    "        self.act_ftr2 = act_ftr2\n",
    "        \n",
    "        self.hidden_comb1 = nn.Linear(num_units_text1 + num_units_ftr2,num_units_comb1) # To update based on layer_num\n",
    "        self.act_comb1 = act_comb1\n",
    "        self.dropout3 = nn.Dropout(0.2)\n",
    "#         self.hidden_comb2 = nn.Linear(num_units_comb1,num_units_comb2)\n",
    "#         self.act_comb2 = act_comb2        \n",
    "        self.output = nn.Linear(num_units_comb1,3) # To update based on layer_num\n",
    "        self.softmax = nn.Softmax(dim=1) # tune\n",
    "    \n",
    "    def forward(self,x,y):\n",
    "        '''\n",
    "        x: text input\n",
    "        y: feature input\n",
    "        '''\n",
    "        x = self.hidden_text1(x)\n",
    "        x = self.act_text1(x)\n",
    "#         x = self.dropout1(x)\n",
    "#         x = self.hidden_text2(x)\n",
    "#         x = self.act_text2(x)\n",
    "        \n",
    "        y = self.hidden_ftr1(y)\n",
    "        y = self.act_ftr1(y)\n",
    "#         y = self.dropout2(y)\n",
    "        y = self.hidden_ftr2(y)\n",
    "        y = self.act_ftr2(y)\n",
    "        \n",
    "        z = torch.cat((x,y),1)\n",
    "        z = self.hidden_comb1(z)\n",
    "        z = self.act_comb1(z)\n",
    "        z = self.dropout3(z)\n",
    "#         z = self.hidden_comb2(z)\n",
    "#         z = self.act_comb2(z)\n",
    "        z = self.output(z)\n",
    "        z = self.softmax(z)\n",
    "        return z\n",
    "\n",
    "# Set up datasets\n",
    "# *KIV: scale embeddnigs\n",
    "X_train_text_chosen = X_train_ft\n",
    "X_val_text_chosen = X_val_ft\n",
    "\n",
    "# # Choose datasets based on feature choice\n",
    "X_train_ftr = scaler.fit_transform(train_df_log[select_cols(end_col_num=15)].to_numpy()) # selected features\n",
    "X_val_ftr = scaler.fit_transform(val_df_log[select_cols(end_col_num=15)].to_numpy())\n",
    "X_train_ftr_chosen = X_train_ftr\n",
    "X_val_ftr_chosen = X_val_ftr\n",
    "\n",
    "# # Process datasets\n",
    "input_size_text = X_train_text_chosen.shape[1]\n",
    "input_size_ftr = X_train_ftr_chosen.shape[1]\n",
    "\n",
    "X_train_text_nn = convert_tensor(X_train_text_chosen,'float')\n",
    "X_val_text_nn = convert_tensor(X_val_text_chosen,'float')\n",
    "X_train_ftr_nn = convert_tensor(X_train_ftr_chosen,'float')\n",
    "X_val_ftr_nn = convert_tensor(X_val_ftr_chosen,'float')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 541,
   "id": "b7424f83",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e378b558a58c43cdaefb451c305638dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/40 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(-1, 4503), (0, 8), (1, 1115)]\n",
      "Epoch1: val loss=0.7959750890731812, balanced accuracy=0.49462233677261347, precision=0.7175107396212932, recall=0.7500888730892286, fscore=0.7035676057240886\n",
      "[(-1, 3847), (0, 1092), (1, 687)]\n",
      "Epoch2: val loss=0.8455769419670105, balanced accuracy=0.5489628916104146, precision=0.734346930489069, recall=0.6919658727337362, fscore=0.6966929476449822\n",
      "[(-1, 3669), (0, 1471), (1, 486)]\n",
      "Epoch3: val loss=0.8752524852752686, balanced accuracy=0.5406623922213809, precision=0.7476417431953283, recall=0.6615712762175613, fscore=0.6715190987623922\n",
      "[(-1, 3489), (0, 1636), (1, 501)]\n",
      "Epoch4: val loss=0.8942480683326721, balanced accuracy=0.5468919335526835, precision=0.7374648499171755, recall=0.6450408816210451, fscore=0.6592340033745832\n",
      "[(-1, 3780), (0, 1524), (1, 322)]\n",
      "Epoch5: val loss=0.8841254711151123, balanced accuracy=0.5267929563501453, precision=0.7634600894700937, recall=0.6564166370423036, fscore=0.6564542105597174\n",
      "[(-1, 3180), (0, 1950), (1, 496)]\n",
      "Epoch6: val loss=0.9340406060218811, balanced accuracy=0.5332648614989811, precision=0.7520318050901267, recall=0.6070031994312123, fscore=0.6402334516982253\n",
      "[(-1, 3521), (0, 1700), (1, 405)]\n",
      "Epoch7: val loss=0.9151960611343384, balanced accuracy=0.5165488311119152, precision=0.7551994028099673, recall=0.6265552790615002, fscore=0.6458971675129638\n",
      "[(-1, 3601), (0, 1501), (1, 524)]\n",
      "Epoch8: val loss=0.8856375217437744, balanced accuracy=0.5404658585201251, precision=0.7482631197622768, recall=0.6549946676146463, fscore=0.6706191696057939\n",
      "[(-1, 3671), (0, 1450), (1, 505)]\n",
      "Epoch9: val loss=0.8839949369430542, balanced accuracy=0.5340946529900186, precision=0.7419756103351574, recall=0.6573053679345894, fscore=0.6684800613947347\n",
      "[(-1, 3731), (0, 1379), (1, 516)]\n",
      "Epoch10: val loss=0.8836648464202881, balanced accuracy=0.5315680698559567, precision=0.7381010004715444, recall=0.6594383220760753, fscore=0.6687853789079556\n",
      "[(-1, 3622), (0, 1426), (1, 578)]\n",
      "Epoch11: val loss=0.8752511739730835, balanced accuracy=0.5621394567573711, precision=0.7479539865595635, recall=0.6679701386420192, fscore=0.6810761891065031\n"
     ]
    }
   ],
   "source": [
    "# Initializing model\n",
    "# # Parameter experimentation (pre-tuning)\n",
    "num_units_text1 = 80\n",
    "num_units_text2 = 60\n",
    "\n",
    "num_units_ftr1 = 20\n",
    "num_units_ftr2 = 8\n",
    "\n",
    "num_units_comb1 = 70\n",
    "num_units_comb2 = 50\n",
    "\n",
    "act_text1 = nn.LeakyReLU()\n",
    "act_text2 = nn.LeakyReLU()\n",
    "\n",
    "act_ftr1 = nn.LeakyReLU()\n",
    "act_ftr2 = nn.LeakyReLU()\n",
    "\n",
    "act_comb1 = nn.LeakyReLU()\n",
    "act_comb2 = nn.Sigmoid()\n",
    "\n",
    "# # Initialization\n",
    "ann_cat = ANN_Cat(\n",
    "    input_size_text,input_size_ftr,\n",
    "    num_units_text1,num_units_text2,num_units_ftr1,num_units_ftr2,num_units_comb1,num_units_comb2,\n",
    "    act_text1,act_ftr1,act_comb1 \n",
    ")\n",
    "optimizer_cat = optim.Adam(ann_cat.parameters(),lr=0.0003) # tune\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "loader_cat = utils.data.DataLoader(utils.data.TensorDataset(X_train_text_nn,X_train_ftr_nn,y_train_nn),batch_size=2)\n",
    "ann_cat = train_ann_model(ann_cat,'ann_cat4.pt',loss_fn,optimizer_cat,loader_cat,cat=True,\n",
    "                          X_val_text_nn=X_val_text_nn,X_val_ftr_nn=X_val_ftr_nn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 542,
   "id": "859e3ac6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7500888730892286 0.49462233677261347\n"
     ]
    }
   ],
   "source": [
    "# Sense Check\n",
    "weights_1 = torch.load('ann_cat4.pt')\n",
    "ann_cat.load_state_dict(weights_1)\n",
    "y_pred_nn = ann_cat(X_val_text_nn,X_val_ftr_nn)\n",
    "y_pred = torch.argmax(y_pred_nn,1)\n",
    "y_pred = y_pred.numpy()\n",
    "y_pred[y_pred==0] = -1\n",
    "y_pred[y_pred==1] = 0\n",
    "y_pred[y_pred==2] = 1\n",
    "accuracy1 = accuracy_score(y_val,y_pred) # = weighted recall\n",
    "bal_accuracy1 = balanced_accuracy_score(y_val,y_pred)\n",
    "print(accuracy1,bal_accuracy1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4839d501",
   "metadata": {},
   "source": [
    "KIV: Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "067c4d9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 5120 candidates, totalling 15360 fits\n",
      "  epoch    train_loss      dur\n",
      "-------  ------------  -------\n",
      "      1        \u001b[36m0.9027\u001b[0m  23.1220\n",
      "      2        \u001b[36m0.9017\u001b[0m  22.5110\n",
      "      3        \u001b[36m0.9017\u001b[0m  21.9067\n",
      "      4        0.9017  22.2528\n",
      "      5        0.9017  22.1930\n",
      "      6        0.9017  22.9600\n",
      "      7        0.9017  22.4477\n",
      "      8        0.9017  23.0299\n",
      "      9        0.9017  22.7174\n",
      "     10        0.9017  22.1013\n",
      "  epoch    train_loss      dur\n",
      "-------  ------------  -------\n",
      "      1        \u001b[36m0.9013\u001b[0m  22.3828\n",
      "      2        \u001b[36m0.9002\u001b[0m  22.6431\n",
      "      3        \u001b[36m0.9002\u001b[0m  21.7757\n",
      "      4        0.9002  22.4238\n",
      "      5        0.9002  22.8037\n",
      "      6        0.9002  23.3393\n",
      "      7        0.9002  23.4128\n",
      "      8        0.9002  22.5803\n",
      "      9        0.9002  22.8700\n",
      "     10        0.9002  22.2768\n",
      "  epoch    train_loss      dur\n",
      "-------  ------------  -------\n",
      "      1        \u001b[36m0.9054\u001b[0m  22.6206\n",
      "      2        \u001b[36m0.9044\u001b[0m  22.3366\n",
      "      3        \u001b[36m0.9044\u001b[0m  22.5366\n",
      "      4        0.9044  23.0888\n",
      "      5        0.9044  23.0295\n",
      "      6        0.9044  22.7039\n",
      "      7        0.9044  23.0487\n",
      "      8        0.9044  22.5662\n",
      "      9        0.9044  22.6730\n",
      "     10        0.9044  22.7733\n",
      "  epoch    train_loss      dur\n",
      "-------  ------------  -------\n",
      "      1        \u001b[36m0.9050\u001b[0m  22.4794\n",
      "  epoch    train_loss      dur\n",
      "-------  ------------  -------\n",
      "      1        \u001b[36m0.9022\u001b[0m  23.3115\n",
      "      2        \u001b[36m0.9017\u001b[0m  23.1456\n",
      "      3        \u001b[36m0.9017\u001b[0m  24.4254\n",
      "      4        0.9017  23.1444\n",
      "      5        0.9017  23.1306\n",
      "      6        0.9017  23.4988\n",
      "      7        0.9017  24.6111\n",
      "      8        0.9017  23.1486\n",
      "      9        0.9017  23.5770\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[60], line 20\u001b[0m\n\u001b[0;32m     11\u001b[0m params \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m     12\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124moptimizer__lr\u001b[39m\u001b[38;5;124m'\u001b[39m:\u001b[38;5;28mlist\u001b[39m(np\u001b[38;5;241m.\u001b[39mlinspace(\u001b[38;5;241m0.001\u001b[39m,\u001b[38;5;241m0.005\u001b[39m,\u001b[38;5;241m5\u001b[39m)),\n\u001b[0;32m     13\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodule__num_units1\u001b[39m\u001b[38;5;124m'\u001b[39m:\u001b[38;5;28mlist\u001b[39m(np\u001b[38;5;241m.\u001b[39marange(\u001b[38;5;241m100\u001b[39m,\u001b[38;5;241m300\u001b[39m,\u001b[38;5;241m50\u001b[39m)),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     17\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbatch_size\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;28mint\u001b[39m(i) \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(np\u001b[38;5;241m.\u001b[39marange(\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m5\u001b[39m))]\n\u001b[0;32m     18\u001b[0m }\n\u001b[0;32m     19\u001b[0m gs \u001b[38;5;241m=\u001b[39m GridSearchCV(ann_hp,param_grid\u001b[38;5;241m=\u001b[39mparams,cv\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m,scoring\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbalanced_accuracy\u001b[39m\u001b[38;5;124m'\u001b[39m,verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m---> 20\u001b[0m \u001b[43mgs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train_nn\u001b[49m\u001b[43m,\u001b[49m\u001b[43my_train_nn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;66;03m# 7:09\u001b[39;00m\n",
      "File \u001b[1;32m~\\miniforge3\\envs\\torch-env\\Lib\\site-packages\\sklearn\\base.py:1152\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1145\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1147\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1148\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1149\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1150\u001b[0m     )\n\u001b[0;32m   1151\u001b[0m ):\n\u001b[1;32m-> 1152\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\miniforge3\\envs\\torch-env\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:898\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    892\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_results(\n\u001b[0;32m    893\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[0;32m    894\u001b[0m     )\n\u001b[0;32m    896\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[1;32m--> 898\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevaluate_candidates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    900\u001b[0m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[0;32m    901\u001b[0m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[0;32m    902\u001b[0m first_test_score \u001b[38;5;241m=\u001b[39m all_out[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_scores\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32m~\\miniforge3\\envs\\torch-env\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1422\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1420\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[0;32m   1421\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1422\u001b[0m     \u001b[43mevaluate_candidates\u001b[49m\u001b[43m(\u001b[49m\u001b[43mParameterGrid\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparam_grid\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\miniforge3\\envs\\torch-env\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:845\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[1;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[0;32m    837\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    838\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[0;32m    839\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFitting \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m folds for each of \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m candidates,\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    840\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m totalling \u001b[39m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m fits\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m    841\u001b[0m             n_splits, n_candidates, n_candidates \u001b[38;5;241m*\u001b[39m n_splits\n\u001b[0;32m    842\u001b[0m         )\n\u001b[0;32m    843\u001b[0m     )\n\u001b[1;32m--> 845\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mparallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    846\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_and_score\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    847\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase_estimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    848\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    849\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    850\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    851\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtest\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    852\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparameters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    853\u001b[0m \u001b[43m        \u001b[49m\u001b[43msplit_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_splits\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    854\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcandidate_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_candidates\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    855\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_and_score_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    856\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    857\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mproduct\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    858\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcandidate_params\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    859\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    860\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    862\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    863\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    864\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo fits were performed. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    865\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWas the CV iterator empty? \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    866\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWere there no candidates?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    867\u001b[0m     )\n",
      "File \u001b[1;32m~\\miniforge3\\envs\\torch-env\\Lib\\site-packages\\sklearn\\utils\\parallel.py:65\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     60\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[0;32m     61\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     62\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     63\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[0;32m     64\u001b[0m )\n\u001b[1;32m---> 65\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\miniforge3\\envs\\torch-env\\Lib\\site-packages\\joblib\\parallel.py:1863\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1861\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_sequential_output(iterable)\n\u001b[0;32m   1862\u001b[0m     \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[1;32m-> 1863\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(output)\n\u001b[0;32m   1865\u001b[0m \u001b[38;5;66;03m# Let's create an ID that uniquely identifies the current call. If the\u001b[39;00m\n\u001b[0;32m   1866\u001b[0m \u001b[38;5;66;03m# call is interrupted early and that the same instance is immediately\u001b[39;00m\n\u001b[0;32m   1867\u001b[0m \u001b[38;5;66;03m# re-used, this id will be used to prevent workers that were\u001b[39;00m\n\u001b[0;32m   1868\u001b[0m \u001b[38;5;66;03m# concurrently finalizing a task from the previous call to run the\u001b[39;00m\n\u001b[0;32m   1869\u001b[0m \u001b[38;5;66;03m# callback.\u001b[39;00m\n\u001b[0;32m   1870\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n",
      "File \u001b[1;32m~\\miniforge3\\envs\\torch-env\\Lib\\site-packages\\joblib\\parallel.py:1792\u001b[0m, in \u001b[0;36mParallel._get_sequential_output\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1790\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_batches \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   1791\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m-> 1792\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1793\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_completed_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   1794\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprint_progress()\n",
      "File \u001b[1;32m~\\miniforge3\\envs\\torch-env\\Lib\\site-packages\\sklearn\\utils\\parallel.py:127\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    125\u001b[0m     config \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m    126\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconfig):\n\u001b[1;32m--> 127\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\miniforge3\\envs\\torch-env\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:751\u001b[0m, in \u001b[0;36m_fit_and_score\u001b[1;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[0m\n\u001b[0;32m    748\u001b[0m result[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfit_error\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    750\u001b[0m fit_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m start_time\n\u001b[1;32m--> 751\u001b[0m test_scores \u001b[38;5;241m=\u001b[39m \u001b[43m_score\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscorer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merror_score\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    752\u001b[0m score_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m start_time \u001b[38;5;241m-\u001b[39m fit_time\n\u001b[0;32m    753\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m return_train_score:\n",
      "File \u001b[1;32m~\\miniforge3\\envs\\torch-env\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:810\u001b[0m, in \u001b[0;36m_score\u001b[1;34m(estimator, X_test, y_test, scorer, error_score)\u001b[0m\n\u001b[0;32m    808\u001b[0m         scores \u001b[38;5;241m=\u001b[39m scorer(estimator, X_test)\n\u001b[0;32m    809\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 810\u001b[0m         scores \u001b[38;5;241m=\u001b[39m \u001b[43mscorer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_test\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    811\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[0;32m    812\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(scorer, _MultimetricScorer):\n\u001b[0;32m    813\u001b[0m         \u001b[38;5;66;03m# If `_MultimetricScorer` raises exception, the `error_score`\u001b[39;00m\n\u001b[0;32m    814\u001b[0m         \u001b[38;5;66;03m# parameter is equal to \"raise\".\u001b[39;00m\n",
      "File \u001b[1;32m~\\miniforge3\\envs\\torch-env\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py:266\u001b[0m, in \u001b[0;36m_BaseScorer.__call__\u001b[1;34m(self, estimator, X, y_true, sample_weight, **kwargs)\u001b[0m\n\u001b[0;32m    263\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m sample_weight \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    264\u001b[0m     _kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msample_weight\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m sample_weight\n\u001b[1;32m--> 266\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_score\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpartial\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_cached_call\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m_kwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\miniforge3\\envs\\torch-env\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py:353\u001b[0m, in \u001b[0;36m_PredictScorer._score\u001b[1;34m(self, method_caller, estimator, X, y_true, **kwargs)\u001b[0m\n\u001b[0;32m    316\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Evaluate predicted target values for X relative to y_true.\u001b[39;00m\n\u001b[0;32m    317\u001b[0m \n\u001b[0;32m    318\u001b[0m \u001b[38;5;124;03mParameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    343\u001b[0m \u001b[38;5;124;03m    Score function applied to prediction of estimator on X.\u001b[39;00m\n\u001b[0;32m    344\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    345\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_warn_overlap(\n\u001b[0;32m    346\u001b[0m     message\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m    347\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThere is an overlap between set kwargs of this scorer instance and\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    351\u001b[0m     kwargs\u001b[38;5;241m=\u001b[39mkwargs,\n\u001b[0;32m    352\u001b[0m )\n\u001b[1;32m--> 353\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m \u001b[43mmethod_caller\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpredict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    354\u001b[0m scoring_kwargs \u001b[38;5;241m=\u001b[39m {\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_kwargs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs}\n\u001b[0;32m    355\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sign \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_score_func(y_true, y_pred, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mscoring_kwargs)\n",
      "File \u001b[1;32m~\\miniforge3\\envs\\torch-env\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py:86\u001b[0m, in \u001b[0;36m_cached_call\u001b[1;34m(cache, estimator, response_method, *args, **kwargs)\u001b[0m\n\u001b[0;32m     83\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cache \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m response_method \u001b[38;5;129;01min\u001b[39;00m cache:\n\u001b[0;32m     84\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cache[response_method]\n\u001b[1;32m---> 86\u001b[0m result, _ \u001b[38;5;241m=\u001b[39m \u001b[43m_get_response_values\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     87\u001b[0m \u001b[43m    \u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse_method\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresponse_method\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[0;32m     88\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     90\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cache \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m     91\u001b[0m     cache[response_method] \u001b[38;5;241m=\u001b[39m result\n",
      "File \u001b[1;32m~\\miniforge3\\envs\\torch-env\\Lib\\site-packages\\sklearn\\utils\\_response.py:194\u001b[0m, in \u001b[0;36m_get_response_values\u001b[1;34m(estimator, X, response_method, pos_label)\u001b[0m\n\u001b[0;32m    191\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m pos_label \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m target_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbinary\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    192\u001b[0m         pos_label \u001b[38;5;241m=\u001b[39m classes[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m--> 194\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m \u001b[43mprediction_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    196\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m prediction_method\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpredict_proba\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    197\u001b[0m     y_pred \u001b[38;5;241m=\u001b[39m _process_predict_proba(\n\u001b[0;32m    198\u001b[0m         y_pred\u001b[38;5;241m=\u001b[39my_pred,\n\u001b[0;32m    199\u001b[0m         target_type\u001b[38;5;241m=\u001b[39mtarget_type,\n\u001b[0;32m    200\u001b[0m         classes\u001b[38;5;241m=\u001b[39mclasses,\n\u001b[0;32m    201\u001b[0m         pos_label\u001b[38;5;241m=\u001b[39mpos_label,\n\u001b[0;32m    202\u001b[0m     )\n",
      "File \u001b[1;32m~\\miniforge3\\envs\\torch-env\\Lib\\site-packages\\skorch\\classifier.py:232\u001b[0m, in \u001b[0;36mNeuralNetClassifier.predict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    202\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpredict\u001b[39m(\u001b[38;5;28mself\u001b[39m, X):\n\u001b[0;32m    203\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Where applicable, return class labels for samples in X.\u001b[39;00m\n\u001b[0;32m    204\u001b[0m \n\u001b[0;32m    205\u001b[0m \u001b[38;5;124;03m    If the module's forward method returns multiple outputs as a\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    230\u001b[0m \n\u001b[0;32m    231\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 232\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict_proba\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39margmax(axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[1;32m~\\miniforge3\\envs\\torch-env\\Lib\\site-packages\\skorch\\classifier.py:200\u001b[0m, in \u001b[0;36mNeuralNetClassifier.predict_proba\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    168\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Where applicable, return probability estimates for\u001b[39;00m\n\u001b[0;32m    169\u001b[0m \u001b[38;5;124;03msamples.\u001b[39;00m\n\u001b[0;32m    170\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    196\u001b[0m \n\u001b[0;32m    197\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    198\u001b[0m \u001b[38;5;66;03m# Only the docstring changed from parent.\u001b[39;00m\n\u001b[0;32m    199\u001b[0m \u001b[38;5;66;03m# pylint: disable=useless-super-delegation\u001b[39;00m\n\u001b[1;32m--> 200\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict_proba\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\miniforge3\\envs\\torch-env\\Lib\\site-packages\\skorch\\net.py:1595\u001b[0m, in \u001b[0;36mNeuralNet.predict_proba\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m   1593\u001b[0m nonlin \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_predict_nonlinearity()\n\u001b[0;32m   1594\u001b[0m y_probas \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m-> 1595\u001b[0m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43myp\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward_iter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraining\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m   1596\u001b[0m \u001b[43m    \u001b[49m\u001b[43myp\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43myp\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43myp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43myp\u001b[49m\n\u001b[0;32m   1597\u001b[0m \u001b[43m    \u001b[49m\u001b[43myp\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mnonlin\u001b[49m\u001b[43m(\u001b[49m\u001b[43myp\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\miniforge3\\envs\\torch-env\\Lib\\site-packages\\skorch\\net.py:1440\u001b[0m, in \u001b[0;36mNeuralNet.forward_iter\u001b[1;34m(self, X, training, device)\u001b[0m\n\u001b[0;32m   1438\u001b[0m dataset \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_dataset(X)\n\u001b[0;32m   1439\u001b[0m iterator \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_iterator(dataset, training\u001b[38;5;241m=\u001b[39mtraining)\n\u001b[1;32m-> 1440\u001b[0m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43miterator\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m   1441\u001b[0m \u001b[43m    \u001b[49m\u001b[43myp\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluation_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraining\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1442\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01myield\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mto_device\u001b[49m\u001b[43m(\u001b[49m\u001b[43myp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\miniforge3\\envs\\torch-env\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:630\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    627\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    628\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    629\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 630\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    631\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    632\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    633\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[1;32m~\\miniforge3\\envs\\torch-env\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:674\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    672\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    673\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m--> 674\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m    675\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[0;32m    676\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[1;32m~\\miniforge3\\envs\\torch-env\\Lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:54\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n\u001b[1;32m---> 54\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcollate_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\miniforge3\\envs\\torch-env\\Lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py:265\u001b[0m, in \u001b[0;36mdefault_collate\u001b[1;34m(batch)\u001b[0m\n\u001b[0;32m    204\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdefault_collate\u001b[39m(batch):\n\u001b[0;32m    205\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    206\u001b[0m \u001b[38;5;124;03m        Function that takes in a batch of data and puts the elements within the batch\u001b[39;00m\n\u001b[0;32m    207\u001b[0m \u001b[38;5;124;03m        into a tensor with an additional outer dimension - batch size. The exact output type can be\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    263\u001b[0m \u001b[38;5;124;03m            >>> default_collate(batch)  # Handle `CustomType` automatically\u001b[39;00m\n\u001b[0;32m    264\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 265\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcollate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcollate_fn_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdefault_collate_fn_map\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\miniforge3\\envs\\torch-env\\Lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py:142\u001b[0m, in \u001b[0;36mcollate\u001b[1;34m(batch, collate_fn_map)\u001b[0m\n\u001b[0;32m    139\u001b[0m transposed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mbatch))  \u001b[38;5;66;03m# It may be accessed twice, so we use a list.\u001b[39;00m\n\u001b[0;32m    141\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(elem, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[1;32m--> 142\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m[\u001b[49m\u001b[43mcollate\u001b[49m\u001b[43m(\u001b[49m\u001b[43msamples\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcollate_fn_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcollate_fn_map\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43msamples\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtransposed\u001b[49m\u001b[43m]\u001b[49m  \u001b[38;5;66;03m# Backwards compatibility.\u001b[39;00m\n\u001b[0;32m    143\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    144\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32m~\\miniforge3\\envs\\torch-env\\Lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py:142\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    139\u001b[0m transposed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mbatch))  \u001b[38;5;66;03m# It may be accessed twice, so we use a list.\u001b[39;00m\n\u001b[0;32m    141\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(elem, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[1;32m--> 142\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[43mcollate\u001b[49m\u001b[43m(\u001b[49m\u001b[43msamples\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcollate_fn_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcollate_fn_map\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m samples \u001b[38;5;129;01min\u001b[39;00m transposed]  \u001b[38;5;66;03m# Backwards compatibility.\u001b[39;00m\n\u001b[0;32m    143\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    144\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32m~\\miniforge3\\envs\\torch-env\\Lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py:119\u001b[0m, in \u001b[0;36mcollate\u001b[1;34m(batch, collate_fn_map)\u001b[0m\n\u001b[0;32m    117\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m collate_fn_map \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    118\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m elem_type \u001b[38;5;129;01min\u001b[39;00m collate_fn_map:\n\u001b[1;32m--> 119\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcollate_fn_map\u001b[49m\u001b[43m[\u001b[49m\u001b[43melem_type\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcollate_fn_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcollate_fn_map\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    121\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m collate_type \u001b[38;5;129;01min\u001b[39;00m collate_fn_map:\n\u001b[0;32m    122\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(elem, collate_type):\n",
      "File \u001b[1;32m~\\miniforge3\\envs\\torch-env\\Lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py:162\u001b[0m, in \u001b[0;36mcollate_tensor_fn\u001b[1;34m(batch, collate_fn_map)\u001b[0m\n\u001b[0;32m    160\u001b[0m     storage \u001b[38;5;241m=\u001b[39m elem\u001b[38;5;241m.\u001b[39m_typed_storage()\u001b[38;5;241m.\u001b[39m_new_shared(numel, device\u001b[38;5;241m=\u001b[39melem\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[0;32m    161\u001b[0m     out \u001b[38;5;241m=\u001b[39m elem\u001b[38;5;241m.\u001b[39mnew(storage)\u001b[38;5;241m.\u001b[39mresize_(\u001b[38;5;28mlen\u001b[39m(batch), \u001b[38;5;241m*\u001b[39m\u001b[38;5;28mlist\u001b[39m(elem\u001b[38;5;241m.\u001b[39msize()))\n\u001b[1;32m--> 162\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstack\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mout\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "ann_hp = NeuralNetClassifier(\n",
    "    ANN,\n",
    "    criterion = nn.CrossEntropyLoss,\n",
    "    max_epochs = 10,\n",
    "    optimizer = optim.Adam,\n",
    "    train_split = None,\n",
    "    module__input_size = input_size\n",
    "    \n",
    ")\n",
    "params = {\n",
    "    'optimizer__lr':list(np.linspace(0.001,0.005,5)),\n",
    "    'module__num_units1':list(np.arange(100,300,50)),\n",
    "    'module__num_units2':list(np.arange(50,250,50)),\n",
    "    'module__act1':[nn.ELU(),nn.LeakyReLU(),nn.Sigmoid(),nn.Tanh()],\n",
    "    'module__act2':[nn.ELU(),nn.LeakyReLU(),nn.Sigmoid(),nn.Tanh()],\n",
    "    'batch_size': [int(i) for i in list(np.arange(1,5))]\n",
    "}\n",
    "gs = GridSearchCV(ann_hp,param_grid=params,cv=3,scoring='balanced_accuracy',verbose=1)\n",
    "gs.fit(X_train_nn,y_train_nn)\n",
    "\n",
    "# Issues:\n",
    "# # Raytune doesn't support Windows\n",
    "# # GridSearch takes too long"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac1ccd27",
   "metadata": {},
   "source": [
    "## Generate Test Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "99948b31",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_test_csv(y_pred,filename):\n",
    "    '''\n",
    "    y_pred: array\n",
    "    '''\n",
    "    test_predictions = pd.DataFrame(y_pred,columns=['Verdict'])\n",
    "    test_predictions['Sentence_id'] = test_data['Sentence_id']\n",
    "    test_predictions.to_csv(filename,index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a0a1c5e",
   "metadata": {},
   "source": [
    "### Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "id": "ffc85f9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = pd.read_csv('test.csv',\n",
    "                   dtype={'Sentence_id':int,'Text':str,'Verdict':int})\n",
    "test_data['Text_lower'] = test_data['Text'].apply(lambda x:x.lower())\n",
    "test_data['Tokens'] = test_data['Text_lower'].apply(word_tokenize)\n",
    "test_data['Tokens_lem'] = test_data['Tokens'].apply(lambda x:[lemmatizer.lemmatize(i) for i in x])\n",
    "test_data['Tokens_no_stop'] = test_data['Tokens'].map(lambda x: [w for w in x if not w.lower() in stop_words])\n",
    "test_data['Tokens_lem_no_stop'] = test_data['Tokens_lem'].map(lambda x: [w for w in x if not w.lower() in stop_words])\n",
    "test_data['Tokens_2'] = test_data['Tokens'].apply(generate_bigram_list)\n",
    "test_data['POS_tags'] = test_data['Tokens'].apply(generate_pos_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 472,
   "id": "6f4b21d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d3aba619947e45ed9cf3d8f76b8666e5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12410 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "55962b0130b1448ba985dd185aa783b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/22501 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0484ada17047422e8025706af3414e15",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1032 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "nb_all = NaiveBayes(data,'Tokens') # Try with lemmatization and including stop words\n",
    "nb_all.generate_prob()\n",
    "all_df_likelihood = nb_all.get_pred(data)\n",
    "test_df_likelihood = nb_all.get_pred(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 475,
   "id": "0d2f8ad0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b031268f08c64e23bb428da70843138a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/45 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4630b5de64ab4c67b82ac2c2e670268a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/22501 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "15c12fbdcfc64684b69b869028c04207",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1032 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "nb_pos_all = NaiveBayes(data,'POS_tags',nb_type='pos')\n",
    "nb_pos_all.generate_prob()\n",
    "df_nb_pos_all = nb_pos_all.get_pred(data)\n",
    "df_nb_pos_test = nb_pos_all.get_pred(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "id": "a79c1dc9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0fe2e6bf63f14db984ca5592f8a08a8a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/112242 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "40cee66eb62c4469a65388d1a52ff5f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/22501 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca06d724f6674553aebe75ca78df2c34",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1032 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "nb2_all = NaiveBayes(data,'Tokens_2',nb_type='bigram')\n",
    "nb2_all.generate_prob()\n",
    "df_nb2_all = nb2_all.get_pred(data)\n",
    "df_nb2_test = nb2_all.get_pred(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f27fa0c",
   "metadata": {},
   "source": [
    "Retrain on all data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 480,
   "id": "2ffa6003",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2cf7f574ad9440c1a7ce7a7a9e892f29",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/22501 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# # Prepare all_dataset (required for other models)\n",
    "features_df = generate_logreg_features(data,all_df_likelihood,df_nb2_all,df_nb_pos_all)\n",
    "corpus_all = data['Tokens'].tolist()\n",
    "ft = FastText(corpus_all,vector_size=ft_size,epochs=10)\n",
    "X_all_ft = generate_ft_emb(data,ft) # word embeddings only\n",
    "X_all_0 = features_df[select_cols(end_col_num=15)].to_numpy() # features only\n",
    "X_all_0 = scaler.fit_transform(X_all_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 523,
   "id": "cf48a4b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tokens</th>\n",
       "      <th>Tokens_lem</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[and, i, want, to, come, back, to, something, ...</td>\n",
       "      <td>[and, i, want, to, come, back, to, something, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[one, of, the, overwhelming, results, that, i,...</td>\n",
       "      <td>[one, of, the, overwhelming, result, that, i, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[i, 'm, confident, that, it, can, be, done, an...</td>\n",
       "      <td>[i, 'm, confident, that, it, can, be, done, an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[but, here, 's, the, point, he, misses, .]</td>\n",
       "      <td>[but, here, 's, the, point, he, miss, .]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[i, mean, ,, this, is, the, president, who, sa...</td>\n",
       "      <td>[i, mean, ,, this, is, the, president, who, sa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16870</th>\n",
       "      <td>[as, the, result, in, the, last, uh, -, two, y...</td>\n",
       "      <td>[a, the, result, in, the, last, uh, -, two, ye...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16871</th>\n",
       "      <td>[they, will, know, whether, we, used, those, w...</td>\n",
       "      <td>[they, will, know, whether, we, used, those, w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16872</th>\n",
       "      <td>[i, 'm, awfully, glad, you, ge-, got, that, qu...</td>\n",
       "      <td>[i, 'm, awfully, glad, you, ge-, got, that, qu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16873</th>\n",
       "      <td>[and, china, 's, a, got, a, lot, of, influence...</td>\n",
       "      <td>[and, china, 's, a, got, a, lot, of, influence...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16874</th>\n",
       "      <td>[i, believe, that, that, would, help, in, term...</td>\n",
       "      <td>[i, believe, that, that, would, help, in, term...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>16875 rows  2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  Tokens  \\\n",
       "0      [and, i, want, to, come, back, to, something, ...   \n",
       "1      [one, of, the, overwhelming, results, that, i,...   \n",
       "2      [i, 'm, confident, that, it, can, be, done, an...   \n",
       "3             [but, here, 's, the, point, he, misses, .]   \n",
       "4      [i, mean, ,, this, is, the, president, who, sa...   \n",
       "...                                                  ...   \n",
       "16870  [as, the, result, in, the, last, uh, -, two, y...   \n",
       "16871  [they, will, know, whether, we, used, those, w...   \n",
       "16872  [i, 'm, awfully, glad, you, ge-, got, that, qu...   \n",
       "16873  [and, china, 's, a, got, a, lot, of, influence...   \n",
       "16874  [i, believe, that, that, would, help, in, term...   \n",
       "\n",
       "                                              Tokens_lem  \n",
       "0      [and, i, want, to, come, back, to, something, ...  \n",
       "1      [one, of, the, overwhelming, result, that, i, ...  \n",
       "2      [i, 'm, confident, that, it, can, be, done, an...  \n",
       "3               [but, here, 's, the, point, he, miss, .]  \n",
       "4      [i, mean, ,, this, is, the, president, who, sa...  \n",
       "...                                                  ...  \n",
       "16870  [a, the, result, in, the, last, uh, -, two, ye...  \n",
       "16871  [they, will, know, whether, we, used, those, w...  \n",
       "16872  [i, 'm, awfully, glad, you, ge-, got, that, qu...  \n",
       "16873  [and, china, 's, a, got, a, lot, of, influence...  \n",
       "16874  [i, believe, that, that, would, help, in, term...  \n",
       "\n",
       "[16875 rows x 2 columns]"
      ]
     },
     "execution_count": 523,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp_df = train_df\n",
    "temp_df = temp_df[['Tokens','Tokens_lem']]\n",
    "temp_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "id": "d2363b24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb90dccd1ef74908b3747ce5fdb55c75",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/40 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(-1, 4550), (0, 68), (1, 1008)]\n",
      "Epoch1: balanced accuracy=0.5046161140765908, precision=0.7258179248346225, recall=0.7488446498400284, fscore=0.7091478627311959\n",
      "[(-1, 4360), (0, 555), (1, 711)]\n",
      "Epoch2: balanced accuracy=0.5503606971632847, precision=0.7386383058620923, recall=0.7410238179879133, fscore=0.7232824680507491\n",
      "[(-1, 4553), (0, 319), (1, 754)]\n",
      "Epoch3: balanced accuracy=0.5222296344627181, precision=0.7182486405608337, recall=0.7403128332740846, fscore=0.7110298520796047\n",
      "[(-1, 4596), (0, 81), (1, 949)]\n",
      "Epoch4: balanced accuracy=0.510236533065175, precision=0.7348399437848964, recall=0.754888019907572, fscore=0.7155310706510672\n",
      "[(-1, 5173), (0, 28), (1, 425)]\n",
      "Epoch5: balanced accuracy=0.42198913222926276, precision=0.7106565757599018, recall=0.7163170991823676, fscore=0.6436426005745558\n",
      "[(-1, 3999), (0, 39), (1, 1588)]\n",
      "Epoch6: balanced accuracy=0.5348925507328325, precision=0.7315538695818725, recall=0.7468894418769997, fscore=0.7154637438594404\n",
      "[(-1, 4295), (0, 41), (1, 1290)]\n",
      "Epoch7: balanced accuracy=0.5258609830216946, precision=0.7424120211145976, recall=0.7561322431567721, fscore=0.7198787903004984\n",
      "[(-1, 4349), (0, 25), (1, 1252)]\n",
      "Epoch8: balanced accuracy=0.5125187720160307, precision=0.730781487942341, recall=0.7507998578030572, fscore=0.7109455404497131\n",
      "[(-1, 4418), (0, 7), (1, 1201)]\n",
      "Epoch9: balanced accuracy=0.5001831247899348, precision=0.7383579090904667, recall=0.7486669036615713, fscore=0.7044957907308714\n",
      "[(-1, 4819), (0, 6), (1, 801)]\n",
      "Epoch10: balanced accuracy=0.46874557537817063, precision=0.7648378224263095, recall=0.7422680412371134, fscore=0.6871767027433531\n",
      "[(-1, 5186), (0, 4), (1, 436)]\n",
      "Epoch11: balanced accuracy=0.4154802365219465, precision=0.7060667762879519, recall=0.7143618912193388, fscore=0.638745332163505\n",
      "[(-1, 4464), (0, 4), (1, 1158)]\n",
      "Epoch12: balanced accuracy=0.4934329663384316, precision=0.7612191237604252, recall=0.7426235335940278, fscore=0.697522759018372\n",
      "[(-1, 4497), (0, 6), (1, 1123)]\n",
      "Epoch13: balanced accuracy=0.5008339047042508, precision=0.7710007141823023, recall=0.7531105581230003, fscore=0.707384588298662\n",
      "[(-1, 3803), (0, 1), (1, 1822)]\n",
      "Epoch14: balanced accuracy=0.5298381799172858, precision=0.6793349703063623, recall=0.7376466405972272, fscore=0.7047939791927894\n",
      "[(-1, 4299), (0, 4), (1, 1323)]\n",
      "Epoch15: balanced accuracy=0.5175288470270113, precision=0.7797109861402166, recall=0.7602204052612869, fscore=0.7179039342653232\n",
      "[(-1, 4524), (0, 2), (1, 1100)]\n",
      "Epoch16: balanced accuracy=0.4952993958985233, precision=0.7692964537372888, recall=0.7515108425168859, fscore=0.7041088541368625\n",
      "[(-1, 4761), (0, 10), (1, 855)]\n",
      "Epoch17: balanced accuracy=0.4703507345557664, precision=0.7306680985629528, recall=0.7419125488801991, fscore=0.6881852029088126\n",
      "[(-1, 4481), (0, 94), (1, 1051)]\n",
      "Epoch18: balanced accuracy=0.5128902065727158, precision=0.7254652186890173, recall=0.7477781727692855, fscore=0.7124162319909315\n",
      "[(-1, 4571), (0, 86), (1, 969)]\n",
      "Epoch19: balanced accuracy=0.49424845633557296, precision=0.7085938899620866, recall=0.7419125488801991, fscore=0.7014971965339931\n",
      "[(-1, 4663), (0, 58), (1, 905)]\n",
      "Epoch20: balanced accuracy=0.4806265592910002, precision=0.7080911097638078, recall=0.7381798791325986, fscore=0.6923932223301802\n",
      "[(-1, 4502), (0, 128), (1, 996)]\n",
      "Epoch21: balanced accuracy=0.5119672041619276, precision=0.716665328651083, recall=0.7500888730892286, fscore=0.7148954690168748\n",
      "[(-1, 4099), (0, 57), (1, 1470)]\n",
      "Epoch22: balanced accuracy=0.5243581963728442, precision=0.7121351681754711, recall=0.748311411304657, fscore=0.715665797092408\n",
      "[(-1, 4667), (0, 76), (1, 883)]\n",
      "Epoch23: balanced accuracy=0.49579674238710925, precision=0.7263532319086516, recall=0.7467116956985425, fscore=0.704175530497767\n",
      "[(-1, 4611), (0, 60), (1, 955)]\n",
      "Epoch24: balanced accuracy=0.4956045404761878, precision=0.7238547798268379, recall=0.7467116956985425, fscore=0.7040305270768078\n",
      "[(-1, 4809), (0, 113), (1, 704)]\n",
      "Epoch25: balanced accuracy=0.4760503363696009, precision=0.7079605821136439, recall=0.735335940277284, fscore=0.6883039008743065\n",
      "[(-1, 4513), (0, 114), (1, 999)]\n",
      "Epoch26: balanced accuracy=0.508998131463461, precision=0.715366132140705, recall=0.7492001421969428, fscore=0.7128111131874612\n",
      "[(-1, 4443), (0, 202), (1, 981)]\n",
      "Epoch27: balanced accuracy=0.5219609940441757, precision=0.7166051889014091, recall=0.7490223960184856, fscore=0.7193966401587928\n",
      "[(-1, 4391), (0, 9), (1, 1226)]\n",
      "Epoch28: balanced accuracy=0.5060204716032537, precision=0.7377853406346255, recall=0.7525773195876289, fscore=0.7092204137195258\n",
      "[(-1, 4278), (0, 6), (1, 1342)]\n",
      "Epoch29: balanced accuracy=0.5166685983212059, precision=0.7444797779065829, recall=0.7575542125844295, fscore=0.7158923354000283\n",
      "[(-1, 3814), (0, 8), (1, 1804)]\n",
      "Epoch30: balanced accuracy=0.52500424804397, precision=0.724827143594511, recall=0.7326697476004266, fscore=0.7012784121595655\n",
      "[(-1, 4305), (0, 9), (1, 1312)]\n",
      "Epoch31: balanced accuracy=0.5131679986325663, precision=0.6877370757608852, recall=0.7561322431567721, fscore=0.7136618414464028\n",
      "[(-1, 4314), (1, 1312)]\n",
      "Epoch32: balanced accuracy=0.5103107153158061, precision=0.6735712506038781, recall=0.7539992890152861, fscore=0.7107507284098824\n",
      "[(-1, 4207), (0, 1), (1, 1418)]\n",
      "Epoch33: balanced accuracy=0.5098690041802353, precision=0.768538189664268, recall=0.745111980092428, fscore=0.70468617780658\n",
      "[(-1, 4595), (1, 1031)]\n",
      "Epoch34: balanced accuracy=0.4814864502280655, precision=0.6608767865405926, recall=0.7442232492001422, fscore=0.6941543644629813\n",
      "[(-1, 4751), (1, 875)]\n",
      "Epoch35: balanced accuracy=0.46980588053169553, precision=0.6610596542513212, recall=0.7417348027017419, fscore=0.6873036882058111\n",
      "[(-1, 4366), (0, 1), (1, 1259)]\n",
      "Epoch36: balanced accuracy=0.5024602454525424, precision=0.7683372525681974, recall=0.7492001421969428, fscore=0.7051742914759169\n",
      "[(-1, 4800), (0, 2), (1, 824)]\n",
      "Epoch37: balanced accuracy=0.455064034784064, precision=0.6985955355509614, recall=0.730892285815855, fscore=0.6739449725770684\n",
      "[(-1, 4838), (0, 2), (1, 786)]\n",
      "Epoch38: balanced accuracy=0.4584238170525827, precision=0.756301427326005, recall=0.7349804479203698, fscore=0.6777173468567558\n",
      "[(-1, 4199), (0, 1), (1, 1426)]\n",
      "Epoch39: balanced accuracy=0.5132778176162862, precision=0.7709281183115181, recall=0.7474226804123711, fscore=0.7070711043229876\n",
      "[(-1, 4579), (0, 2), (1, 1045)]\n",
      "Epoch40: balanced accuracy=0.48771645541276937, precision=0.7652899955950397, recall=0.7476004265908283, fscore=0.6987431780640572\n"
     ]
    }
   ],
   "source": [
    "# # Process datasets for nn\n",
    "\n",
    "X_text_chosen = X_val_ft\n",
    "X_ftr_chosen = X_val_ftr\n",
    "input_size_text = X_text_chosen.shape[1]\n",
    "input_size_ftr = X_ftr_chosen.shape[1]\n",
    "\n",
    "X_text_nn = convert_tensor(X_text_chosen,'float')\n",
    "X_ftr_nn = convert_tensor(X_ftr_chosen,'float')\n",
    "y_chosen = y_val\n",
    "y_chosen_nn = convert_tensor(convert_y(y_chosen),'float')\n",
    "\n",
    "# # Train NN model\n",
    "loader_cat_final = utils.data.DataLoader(utils.data.TensorDataset(X_text_nn,X_ftr_nn,y_chosen_nn),batch_size=2)\n",
    "ann_cat_final = train_ann_model(ann_cat,'ann_cat_final.pt',loss_fn,optimizer_cat,loader_cat_final,cat=True,\n",
    "                          X_val_text_nn=X_val_text_nn,X_val_ftr_nn=X_val_ftr_nn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 481,
   "id": "b28866df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d4f1977d4f442f782eaca6aa0fe2120",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1032 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Prepare test dataset (required for other models)\n",
    "features_test_df = generate_logreg_features(test_data,test_df_likelihood,df_nb2_test,df_nb_pos_test)\n",
    "# ft.train(test_data['Tokens'].tolist(),total_examples=ft.corpus_count,epochs=10)\n",
    "X_test_ft = generate_ft_emb(test_data,ft) # word embeddings only\n",
    "X_test_0 = features_test_df[select_cols(end_col_num=15)].to_numpy() # features only\n",
    "X_test_0 = scaler.fit_transform(X_test_0)\n",
    "X_test_text_nn = convert_tensor(X_test_ft,'float')\n",
    "X_test_ftr_nn = convert_tensor(X_test_0,'float')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "id": "6de1a357",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_nn = ann_cat(X_test_text_nn,X_test_ftr_nn) #try without training\n",
    "y_pred = torch.argmax(y_pred_nn,1)\n",
    "y_pred = y_pred.numpy()\n",
    "y_pred[y_pred==0] = -1\n",
    "y_pred[y_pred==1] = 0\n",
    "y_pred[y_pred==2] = 1\n",
    "generate_test_csv(y_pred,'test_predictions_ann.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca906085",
   "metadata": {},
   "source": [
    "### Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 470,
   "id": "df2ed845",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c01485a39a7a4c718536826a19cfdac5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1032 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "nb_test_pred = nb_all.get_pred(test_data)\n",
    "y_pred = nb_test_pred['Prediction'].tolist()\n",
    "generate_test_csv(y_pred,'test_predictions_nb.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b80d9ee",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 482,
   "id": "216f56d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_all_01 = features_df[select_cols(end_col_num=15,Bigram=False)].to_numpy()  \n",
    "X_all_01 = scaler.fit_transform(X_all_01)\n",
    "X_all_ft1 = np.concatenate((X_all_01,X_all_ft),axis=1)\n",
    "\n",
    "X_test_01 = features_test_df[select_cols(end_col_num=15,Bigram=False)].to_numpy()\n",
    "X_test_01 = scaler.fit_transform(X_test_01)\n",
    "X_test_ft1 = np.concatenate((X_test_01,X_test_ft),axis=1)\n",
    "\n",
    "logreg_all_clf = LogisticRegression(max_iter=500)\n",
    "logreg_all_clf.fit(X_all_ft1,y_all)\n",
    "y_pred = logreg_all_clf.predict(X_test_ft1)\n",
    "generate_test_csv(y_pred,'test_predictions_LR.csv')\n",
    "\n",
    "# Best result so far: Bigram 0 POS 1 Bayesian 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch-env",
   "language": "python",
   "name": "my-conda-env-kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
