{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7dcc853b-92a8-452c-a9b9-df2d5e1787c4",
   "metadata": {},
   "source": [
    "# Sentiment Analysis with BERT [TensorFlow]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fcfa4162-cc5e-4df7-896f-40e14bf862fe",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "import datetime as dt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "import os\n",
    "import requests\n",
    "import json\n",
    "import glob\n",
    "import random\n",
    "import re\n",
    "from datetime import datetime as dt\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.preprocessing import StandardScaler,OneHotEncoder\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.model_selection import KFold,train_test_split\n",
    "from sklearn.decomposition import PCA\n",
    "# from sklearn.kernel_ridge import KernelRidge\n",
    "# from sklearn.linear_model import RidgeClassifier\n",
    "# from sklearn.svm import SVC\n",
    "# from sklearn.mixture import GaussianMixture\n",
    "# from sklearn.metrics import precision_score, recall_score, PrecisionRecallDisplay, ConfusionMatrixDisplay, confusion_matrix\n",
    "# from sklearn.metrics import silhouette_score\n",
    "# from sklearn.model_selection import GridSearchCV, TimeSeriesSplit\n",
    "# from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, BaggingClassifier\n",
    "import keras as ke\n",
    "import keras.metrics as met\n",
    "import keras.models as M\n",
    "import keras.layers as L\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras import optimizers\n",
    "# import keras_tuner as kt\n",
    "# from keras_tuner import HyperModel\n",
    "# from keras_tuner import Tuner\n",
    "# import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "from functools import partial\n",
    "# from scipy.stats import mstats\n",
    "\n",
    "# with warnings.catch_warnings():\n",
    "#     warnings.simplefilter(\"ignore\")\n",
    "#     import yfinance as yf\n",
    "#     from sklearn.cluster import KMeans\n",
    "\n",
    "path = r'{PATH}'\n",
    "os.chdir(path)\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a639942-1a8f-4d0f-9f10-92f6ae2e872d",
   "metadata": {},
   "source": [
    "## 1. Pre-Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dce5ab1f-565d-4816-8343-9255e277a640",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "    import tensorflow as tf\n",
    "    import tensorflow_hub as hub\n",
    "    import tensorflow_text as text\n",
    "    import keras_tuner as kt\n",
    "    from official.nlp import optimization\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ba61ab30-11d8-47de-9775-90457895343d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "# Check GPU availability:\n",
    "# tf.debugging.set_log_device_placement(False)\n",
    "# print(tf.test.is_built_with_cuda())\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "print(gpus)\n",
    "\n",
    "# Enable GPU memory growth:\n",
    "# try:\n",
    "#     for gpu in gpus:\n",
    "#         tf.config.experimental.set_memory_growth(gpu,True)\n",
    "# except RuntimeError as e:\n",
    "#     # Memory growth must be set before GPUs have been initialized\n",
    "#     print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "63b9e769-51d7-4f1e-96fa-127456cbd623",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "aapl_comments = pd.read_csv('reddit/kaggle_AaplOnRedditComments_2016-2021.csv')\n",
    "aapl_posts = pd.read_csv('reddit/kaggle_AaplOnRedditPosts_2016-2021.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "09be4a0e-94c2-487e-804b-ca28e55157c9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>body</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I own all 3.  Don't sell AAPL.</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I believe TSLA want to be like AAPL: part hard...</td>\n",
       "      <td>-0.2500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>**[Recent News for BABA-](https://www.reddit.c...</td>\n",
       "      <td>0.9422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>O, AAPL, NKE</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I have both. CRM has had better revenue and ea...</td>\n",
       "      <td>0.7896</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                body  sentiment\n",
       "0                     I own all 3.  Don't sell AAPL.     0.0000\n",
       "1  I believe TSLA want to be like AAPL: part hard...    -0.2500\n",
       "2  **[Recent News for BABA-](https://www.reddit.c...     0.9422\n",
       "3                                       O, AAPL, NKE        NaN\n",
       "4  I have both. CRM has had better revenue and ea...     0.7896"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aapl_comments_1 = aapl_comments.loc[:,['body','sentiment']]\n",
    "aapl_comments_1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bcd2d740-1532-4a6f-9756-663258368308",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0               Why is AAPL included in dividend ETFs?\n",
       "1                 why AAPL deserves $200+ and a 35+ PE\n",
       "2    $AAPL waiting for Buy signal on AAPL https://t...\n",
       "3                  Sell a few AAPL shares and buy CRM?\n",
       "4                     Is $AAPL able to grow much more?\n",
       "Name: title, dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aapl_posts_1 = aapl_posts.loc[:,'title']\n",
    "aapl_posts_1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8defbe9f-3eb0-4d04-bfa4-37ab4a54dcf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "body         False\n",
      "sentiment     True\n",
      "dtype: bool\n"
     ]
    }
   ],
   "source": [
    "# NA Test\n",
    "def NA_test(df):\n",
    "    na_test = pd.isnull(df)\n",
    "    print(na_test.any())\n",
    "    \n",
    "NA_test(aapl_comments_1)\n",
    "# NA_test(aapl_posts_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "97164f70-92c8-413b-a117-e2447f6d70ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "body         False\n",
      "sentiment    False\n",
      "dtype: bool\n"
     ]
    }
   ],
   "source": [
    "# NA Imputation\n",
    "def impute(df,col_remove=None):\n",
    "    if col_remove != None:\n",
    "        na_vals = pd.isnull(df[col_remove])\n",
    "        na_idx = na_vals.index[na_vals].tolist()\n",
    "        df.drop(index=na_idx)\n",
    "    df = df.fillna(value=0)\n",
    "    return df\n",
    "\n",
    "aapl_comments_1 = impute(aapl_comments_1,col_remove='body')\n",
    "NA_test(aapl_comments_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91d4a5c3-f12c-43d6-b66e-0fabd1de49e2",
   "metadata": {},
   "source": [
    "## 2. Building BERT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c484f50-fe3a-402d-b7c6-2472735b73eb",
   "metadata": {},
   "source": [
    "### 2.1 Build"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a2f226dd-0469-494d-9db9-05674f842bde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BERT model selected           : https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-2_H-128_A-2/1\n",
      "Preprocess model auto-selected: https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3\n"
     ]
    }
   ],
   "source": [
    "# bert_model_name = 'small_bert/bert_en_uncased_L-4_H-512_A-8' # Too large for laptop\n",
    "bert_model_name = 'small_bert/bert_en_uncased_L-2_H-128_A-2' \n",
    "\n",
    "map_name_to_handle = {\n",
    "    'bert_en_uncased_L-12_H-768_A-12':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/3',\n",
    "    'bert_en_cased_L-12_H-768_A-12':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_cased_L-12_H-768_A-12/3',\n",
    "    'bert_multi_cased_L-12_H-768_A-12':\n",
    "        'https://tfhub.dev/tensorflow/bert_multi_cased_L-12_H-768_A-12/3',\n",
    "    'small_bert/bert_en_uncased_L-2_H-128_A-2':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-2_H-128_A-2/1',\n",
    "    'small_bert/bert_en_uncased_L-2_H-256_A-4':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-2_H-256_A-4/1',\n",
    "    'small_bert/bert_en_uncased_L-2_H-512_A-8':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-2_H-512_A-8/1',\n",
    "    'small_bert/bert_en_uncased_L-2_H-768_A-12':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-2_H-768_A-12/1',\n",
    "    'small_bert/bert_en_uncased_L-4_H-128_A-2':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-4_H-128_A-2/1',\n",
    "    'small_bert/bert_en_uncased_L-4_H-256_A-4':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-4_H-256_A-4/1',\n",
    "    'small_bert/bert_en_uncased_L-4_H-512_A-8':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-4_H-512_A-8/1',\n",
    "    'small_bert/bert_en_uncased_L-4_H-768_A-12':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-4_H-768_A-12/1',\n",
    "    'small_bert/bert_en_uncased_L-6_H-128_A-2':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-6_H-128_A-2/1',\n",
    "    'small_bert/bert_en_uncased_L-6_H-256_A-4':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-6_H-256_A-4/1',\n",
    "    'small_bert/bert_en_uncased_L-6_H-512_A-8':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-6_H-512_A-8/1',\n",
    "    'small_bert/bert_en_uncased_L-6_H-768_A-12':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-6_H-768_A-12/1',\n",
    "    'small_bert/bert_en_uncased_L-8_H-128_A-2':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-8_H-128_A-2/1',\n",
    "    'small_bert/bert_en_uncased_L-8_H-256_A-4':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-8_H-256_A-4/1',\n",
    "    'small_bert/bert_en_uncased_L-8_H-512_A-8':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-8_H-512_A-8/1',\n",
    "    'small_bert/bert_en_uncased_L-8_H-768_A-12':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-8_H-768_A-12/1',\n",
    "    'small_bert/bert_en_uncased_L-10_H-128_A-2':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-10_H-128_A-2/1',\n",
    "    'small_bert/bert_en_uncased_L-10_H-256_A-4':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-10_H-256_A-4/1',\n",
    "    'small_bert/bert_en_uncased_L-10_H-512_A-8':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-10_H-512_A-8/1',\n",
    "    'small_bert/bert_en_uncased_L-10_H-768_A-12':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-10_H-768_A-12/1',\n",
    "    'small_bert/bert_en_uncased_L-12_H-128_A-2':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-12_H-128_A-2/1',\n",
    "    'small_bert/bert_en_uncased_L-12_H-256_A-4':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-12_H-256_A-4/1',\n",
    "    'small_bert/bert_en_uncased_L-12_H-512_A-8':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-12_H-512_A-8/1',\n",
    "    'small_bert/bert_en_uncased_L-12_H-768_A-12':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-12_H-768_A-12/1',\n",
    "    'albert_en_base':\n",
    "        'https://tfhub.dev/tensorflow/albert_en_base/2',\n",
    "    'electra_small':\n",
    "        'https://tfhub.dev/google/electra_small/2',\n",
    "    'electra_base':\n",
    "        'https://tfhub.dev/google/electra_base/2',\n",
    "    'experts_pubmed':\n",
    "        'https://tfhub.dev/google/experts/bert/pubmed/2',\n",
    "    'experts_wiki_books':\n",
    "        'https://tfhub.dev/google/experts/bert/wiki_books/2',\n",
    "    'talking-heads_base':\n",
    "        'https://tfhub.dev/tensorflow/talkheads_ggelu_bert_en_base/1',\n",
    "}\n",
    "\n",
    "map_model_to_preprocess = {\n",
    "    'bert_en_uncased_L-12_H-768_A-12':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'bert_en_cased_L-12_H-768_A-12':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_cased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-2_H-128_A-2':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-2_H-256_A-4':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-2_H-512_A-8':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-2_H-768_A-12':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-4_H-128_A-2':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-4_H-256_A-4':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-4_H-512_A-8':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-4_H-768_A-12':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-6_H-128_A-2':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-6_H-256_A-4':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-6_H-512_A-8':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-6_H-768_A-12':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-8_H-128_A-2':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-8_H-256_A-4':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-8_H-512_A-8':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-8_H-768_A-12':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-10_H-128_A-2':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-10_H-256_A-4':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-10_H-512_A-8':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-10_H-768_A-12':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-12_H-128_A-2':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-12_H-256_A-4':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-12_H-512_A-8':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-12_H-768_A-12':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'bert_multi_cased_L-12_H-768_A-12':\n",
    "        'https://tfhub.dev/tensorflow/bert_multi_cased_preprocess/3',\n",
    "    'albert_en_base':\n",
    "        'https://tfhub.dev/tensorflow/albert_en_preprocess/3',\n",
    "    'electra_small':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'electra_base':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'experts_pubmed':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'experts_wiki_books':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'talking-heads_base':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "}\n",
    "\n",
    "tfhub_handle_encoder = map_name_to_handle[bert_model_name]\n",
    "tfhub_handle_preprocess = map_model_to_preprocess[bert_model_name]\n",
    "\n",
    "print(f'BERT model selected           : {tfhub_handle_encoder}')\n",
    "print(f'Preprocess model auto-selected: {tfhub_handle_preprocess}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b51fbdb3-8670-4b21-924c-ebe16dc197e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "158684 79342\n"
     ]
    }
   ],
   "source": [
    "X = aapl_comments_1['body'].to_numpy()\n",
    "y = aapl_comments_1['sentiment'].to_numpy()\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.2,random_state=28)\n",
    "kf = KFold(n_splits=3)\n",
    "for i, (train_idx,val_idx) in enumerate(kf.split(X_train)):\n",
    "    if i == 0: \n",
    "        len_train, len_val = len(train_idx), len(val_idx)\n",
    "        print(len_train,len_val)\n",
    "    elif len(train_idx) != len_train or len(val_idx) != len_val:\n",
    "        print(i,len(train_idx),len(val_idx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a4dd262d-c231-46b2-bf32-5dbd5c54a180",
   "metadata": {},
   "outputs": [],
   "source": [
    "steps_per_epoch = 158684\n",
    "epochs = 5\n",
    "batch_size = 1\n",
    "num_train_steps = steps_per_epoch & epochs\n",
    "num_warmup_steps = int(0.1*num_train_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e4e23f1c-1db5-4ed3-b59d-8ac61a99c064",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BERT_classifier:\n",
    "    def __init__(self):\n",
    "        return None\n",
    "                 \n",
    "    def build_model(self,hp):\n",
    "        \n",
    "        hp_dropout = hp.Float('dropout_rate',min_value=1e-5,max_value=5e-5,step=1e-5)\n",
    "        hp_lr = hp.Float('lr',min_value=0.05,max_value=0.2,step=0.05)\n",
    "        \n",
    "        text_input = ke.layers.Input(shape=(),dtype=tf.string,name='text') #is shape supposed to be empty? why?\n",
    "        preprocessing_layer = hub.KerasLayer(tfhub_handle_preprocess,name='preprocessing')\n",
    "        encoder_inputs = preprocessing_layer(text_input)\n",
    "        encoder = hub.KerasLayer(tfhub_handle_encoder,trainable=True,name='BERT_encoder')\n",
    "        outputs = encoder(encoder_inputs)\n",
    "        net = outputs['pooled_output'] #pooled_output and sequence_output\n",
    "        net = ke.layers.Dropout(hp_dropout)(net)\n",
    "        net = ke.layers.Dense(1,activation=None,name='classifier')(net)\n",
    "        model = ke.Model(text_input,net)\n",
    "        \n",
    "        optimizer = optimization.create_optimizer(init_lr=hp_lr,\n",
    "                                              num_train_steps=num_train_steps,\n",
    "                                              num_warmup_steps=num_warmup_steps,\n",
    "                                              optimizer_type='adamw')\n",
    "        model.compile(optimizer=optimizer,loss='mse',metrics=['mae'])\n",
    "        return model\n",
    "\n",
    "    def fit(self,hp,model,*args,**kwargs):\n",
    "        return model.fit(\n",
    "            *args,\n",
    "            batch_size=batch_size,\n",
    "            **kwargs,\n",
    "        )\n",
    "        \n",
    "# still requires tf.sigmoid() if binary classifier\n",
    "# loss = ke.losses.BinaryCrossentropy(from_logits=True)\n",
    "# metrics = tf.metrics.BinaryAccuracy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "48f65c56-606a-473e-88f6-3bf1e6402986",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reloading Tuner from .\\untitled_project\\tuner0.json\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "bert = BERT_classifier() #critical. Without creating the object, hyperparameters object won't be passed\n",
    "stop_early = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5)\n",
    "tuner = kt.Hyperband(bert.build_model, objective='val_loss', max_epochs=10)\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c54df9b-63e2-4aae-b33d-bea6b2d9e17a",
   "metadata": {},
   "source": [
    "## 2.2 Train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "519d3261-9064-429a-ac18-8232e9a59012",
   "metadata": {},
   "source": [
    "### 2.2.1 Without Cross-Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59a3a1ad-c6be-4941-969f-37a5d9554d22",
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner.search(X_train,y_train,epochs=5,validation_split=0.2,callbacks=[stop_early])\n",
    "best_model = tuner.get_best_models()[0]\n",
    "best_model.fit(X_train,y_train,validation_split=0.2,epochs=epochs,batch_size=batch_size)\n",
    "best_hps = tuner.get_best_hyperparameters()[0]\n",
    "loss, mae = best_model.evaluate(X_test,y_test)\n",
    "print(best_hps)\n",
    "print(f'Loss:{loss}, MAE:{mae}')\n",
    "\n",
    "# Note on clearing temp directory: \n",
    "    # https://discuss.tensorflow.org/t/tensorflow-model-works-but-after-a-while-does-not-work/18400/3\n",
    "    # https://stackoverflow.com/questions/62358745/oserror-savedmodel-file-does-not-exist-at-c-users-munib-new-folder-saved-mod"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16ca4930-b65d-41eb-9d46-4ed74c0788bf",
   "metadata": {},
   "source": [
    "### 2.2.2 With Cross-Validation (WIP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb8357a9-ebc3-4b40-a865-1052f79505c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# With cross-validation\n",
    "results = {}\n",
    "for i, (train_idx,val_idx) in tqdm(enumerate(kf.split(X_train))):\n",
    "    x_tr = X_train[train_idx]\n",
    "    y_tr = y_train[train_idx]\n",
    "    x_va = X_train[val_idx]\n",
    "    y_va = y_train[val_idx]\n",
    "    tuner.search(x_tr,y_tr,epochs=5,validation_data=(x_va,y_va),callbacks=[stop_early])\n",
    "    best_model = tuner.get_best_models()[0]\n",
    "    best_model.fit(x_tr,y_tr,validation_data=(x_va,y_va),epochs=epochs)\n",
    "    loss, mae = best_model.evaluate(X_test,y_test)\n",
    "    results[i] = [best_model,loss,mae]\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7465970-6b4e-464a-922c-91e00f63d05e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf.keras.utils.plot_model(classifier_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec283114-f119-48ec-a4b6-e3d78ad61c11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Next action:\n",
    "# Callbacks and checkpoints\n",
    "# Rework cross-validation: scores should be averaged for the same hyperparameter set across cv sets"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf-env0",
   "language": "python",
   "name": "tf-env0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
