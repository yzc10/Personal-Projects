{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4f201b7e",
   "metadata": {},
   "source": [
    "# Document Retrieval using Wikipedia Dataset\n",
    "\n",
    "**General Approach:** Implemented 3 Bag-of-Words- and Embeddings-based models and picked the best for final retrieval. Drew reference from the framework provided here: https://medium.com/mlearning-ai/enhancing-information-retrieval-via-semantic-and-relevance-matching-64973ff81818"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d33b664",
   "metadata": {},
   "source": [
    "## 1. Pre-processing\n",
    "### 1.1 Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9ca2b81a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cc1555b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "ds = load_dataset('wikipedia','20220301.simple',trust_remote_code=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "7f8ba2a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from functools import partial\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import KFold, train_test_split\n",
    "from simpletransformers.retrieval import RetrievalModel, RetrievalArgs\n",
    "import torch\n",
    "import warnings\n",
    "\n",
    "path = r'C:\\Users\\yongz\\Personal Projects\\ahrefs_task'\n",
    "os.chdir(path)\n",
    "tqdm = partial(tqdm,position=0,leave=True)\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d49f08dd",
   "metadata": {},
   "source": [
    "### 1.2 Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bf328c8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>points</th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>how do living organisms in a natural environme...</td>\n",
       "      <td>57</td>\n",
       "      <td>Environment</td>\n",
       "      <td>Environment means anything that surrounds us. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>what is the name of the poem written by juan r...</td>\n",
       "      <td>72</td>\n",
       "      <td>Marcha Real</td>\n",
       "      <td>La Marcha Real (English translation: The Royal...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>what body parts can mri scans study?</td>\n",
       "      <td>45</td>\n",
       "      <td>Magnetic resonance imaging</td>\n",
       "      <td>Magnetic resonance imaging (MRI), or nuclear m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>what are the names of the 12 boroughs in berli...</td>\n",
       "      <td>46</td>\n",
       "      <td>Boroughs of Berlin</td>\n",
       "      <td>The German capital Berlin is subdivided into 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>what was the cause of charles dickens' death?</td>\n",
       "      <td>87</td>\n",
       "      <td>Heinrich Rudolf Hertz</td>\n",
       "      <td>Heinrich Rudolf Hertz (22 February 1857 – 1 Ja...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            question  points  \\\n",
       "0  how do living organisms in a natural environme...      57   \n",
       "1  what is the name of the poem written by juan r...      72   \n",
       "2               what body parts can mri scans study?      45   \n",
       "3  what are the names of the 12 boroughs in berli...      46   \n",
       "4      what was the cause of charles dickens' death?      87   \n",
       "\n",
       "                        title  \\\n",
       "0                 Environment   \n",
       "1                 Marcha Real   \n",
       "2  Magnetic resonance imaging   \n",
       "3          Boroughs of Berlin   \n",
       "4       Heinrich Rudolf Hertz   \n",
       "\n",
       "                                                text  \n",
       "0  Environment means anything that surrounds us. ...  \n",
       "1  La Marcha Real (English translation: The Royal...  \n",
       "2  Magnetic resonance imaging (MRI), or nuclear m...  \n",
       "3  The German capital Berlin is subdivided into 1...  \n",
       "4  Heinrich Rudolf Hertz (22 February 1857 – 1 Ja...  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_json('train.jsonl',lines=True)\n",
    "doc_base = pd.DataFrame(ds['train'][:10000])\n",
    "train = train.rename(columns={'article':'title'})\n",
    "df = train.merge(doc_base[['title','text']],how='left',on='title')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "57b86e6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>url</th>\n",
       "      <th>title</th>\n",
       "      <th>gold_passage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>https://simple.wikipedia.org/wiki/April</td>\n",
       "      <td>April</td>\n",
       "      <td>April is the fourth month of the year in the J...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>https://simple.wikipedia.org/wiki/August</td>\n",
       "      <td>August</td>\n",
       "      <td>August (Aug.) is the eighth month of the year ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6</td>\n",
       "      <td>https://simple.wikipedia.org/wiki/Art</td>\n",
       "      <td>Art</td>\n",
       "      <td>Art is a creative activity that expresses imag...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8</td>\n",
       "      <td>https://simple.wikipedia.org/wiki/A</td>\n",
       "      <td>A</td>\n",
       "      <td>A or a is the first letter of the English alph...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9</td>\n",
       "      <td>https://simple.wikipedia.org/wiki/Air</td>\n",
       "      <td>Air</td>\n",
       "      <td>Air refers to the Earth's atmosphere. Air is a...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  id                                       url   title  \\\n",
       "0  1   https://simple.wikipedia.org/wiki/April   April   \n",
       "1  2  https://simple.wikipedia.org/wiki/August  August   \n",
       "2  6     https://simple.wikipedia.org/wiki/Art     Art   \n",
       "3  8       https://simple.wikipedia.org/wiki/A       A   \n",
       "4  9     https://simple.wikipedia.org/wiki/Air     Air   \n",
       "\n",
       "                                        gold_passage  \n",
       "0  April is the fourth month of the year in the J...  \n",
       "1  August (Aug.) is the eighth month of the year ...  \n",
       "2  Art is a creative activity that expresses imag...  \n",
       "3  A or a is the first letter of the English alph...  \n",
       "4  Air refers to the Earth's atmosphere. Air is a...  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_base = doc_base.rename(columns={'text':'gold_passage'})\n",
    "doc_base.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "52d1177a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test done\n"
     ]
    }
   ],
   "source": [
    "# Test for NA values -> impute if necessary\n",
    "def NA_test(df):\n",
    "    for c in df.columns:\n",
    "        if df[c].isnull().values.any():\n",
    "            print('null',c)\n",
    "    print('test done')\n",
    "NA_test(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "22e4a10f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utils\n",
    "n_docs = 10\n",
    "\n",
    "def gen_splits(df):\n",
    "    X, X_test = train_test_split(df,test_size=0.2,random_state=27)\n",
    "    X_train, X_val = train_test_split(df,test_size=0.2,random_state=27)\n",
    "    return X_train, X_val, X_test\n",
    "\n",
    "'''\n",
    "For model evaluation functions, use EITHER ONE of the functions below\n",
    "'''\n",
    "\n",
    "def compute_simple_accuracy(query_df,predicted_passages):\n",
    "    '''\n",
    "    query_df: DataFrame['query_text','title','gold_passage']\n",
    "    predicted_passages: List[List[str]] (query x top k docs per query)\n",
    "    '''\n",
    "    query_df['retrieved_passage'] = [docs[0] for docs in predicted_passages]\n",
    "    query_df['correct'] = query_df.apply(lambda row: row.gold_passage == row.retrieved_passage,axis=1)\n",
    "    accuracy = len(query_df[query_df['correct']==True])/len(query_df)\n",
    "    return accuracy\n",
    "\n",
    "def compute_performance(query_df,predicted_passages,top_k=n_docs):\n",
    "    '''\n",
    "    n_docs should be >= 10\n",
    "    Metrics covered:\n",
    "    - accuracy: top 1, 3, 5, 10\n",
    "    - mrr: (1/N)Sum(1/rank_i)\n",
    "    '''\n",
    "    query_df['retrieved_passages'] = predicted_passages\n",
    "    def compute_rank(row):\n",
    "        if row.gold_passage in row.retrieved_passages:\n",
    "            return row.retrieved_passages.index(row.gold_passage) + 1\n",
    "        else: return 0\n",
    "    query_df['rank'] = query_df.apply(lambda row:compute_rank(row),axis=1)\n",
    "#     print(query_df['rank'].head(20))\n",
    "    for n in (1,3,5,10):\n",
    "        query_df[f'top_{n}'] = query_df.apply(lambda row:row['rank']>0 and row['rank']<=n,axis=1)\n",
    "#     print(query_df['top_3'].head(20),query_df['top_10'].head(20))\n",
    "    query_df['mrr_component'] = query_df.apply(lambda row:1/row['rank'] if row['rank']>0 else 0,axis=1)\n",
    "    top_1_accuracy = query_df['top_1'].sum()/len(query_df)\n",
    "    top_3_accuracy = query_df['top_3'].sum()/len(query_df)\n",
    "    top_5_accuracy = query_df['top_5'].sum()/len(query_df)\n",
    "    top_10_accuracy = query_df['top_10'].sum()/len(query_df)\n",
    "    mrr = query_df['mrr_component'].sum()/len(query_df)\n",
    "    results_dict = {\n",
    "        'top 1 accuracy': top_1_accuracy,\n",
    "        'top 3 accuracy': top_3_accuracy,\n",
    "        'top 5 accuracy': top_5_accuracy,\n",
    "        'top 10 accuracy': top_10_accuracy,\n",
    "        'mrr': mrr\n",
    "    }\n",
    "    return results_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "183a8511",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query_text</th>\n",
       "      <th>title</th>\n",
       "      <th>gold_passage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>what is the title of the french nobility that ...</td>\n",
       "      <td>Cardinal Richelieu</td>\n",
       "      <td>Armand Jean du Plessis, better known as Cardin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>what is the therapeutic index of warfarin?</td>\n",
       "      <td>Pharmacology</td>\n",
       "      <td>Pharmacology is the study of how medicine and ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>what is the top-selling 2010s automobile in th...</td>\n",
       "      <td>Fiat Ulysse</td>\n",
       "      <td>The Fiat Ulysse was a large car with seven sea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>when did pope innocent i succeed pope anastasi...</td>\n",
       "      <td>401</td>\n",
       "      <td>401 (CDI) was a common year starting on Tuesda...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>what is the name of euterpe's son according to...</td>\n",
       "      <td>Muse</td>\n",
       "      <td>For the British musical group of the same name...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          query_text               title  \\\n",
       "0  what is the title of the french nobility that ...  Cardinal Richelieu   \n",
       "1         what is the therapeutic index of warfarin?        Pharmacology   \n",
       "2  what is the top-selling 2010s automobile in th...         Fiat Ulysse   \n",
       "3  when did pope innocent i succeed pope anastasi...                 401   \n",
       "4  what is the name of euterpe's son according to...                Muse   \n",
       "\n",
       "                                        gold_passage  \n",
       "0  Armand Jean du Plessis, better known as Cardin...  \n",
       "1  Pharmacology is the study of how medicine and ...  \n",
       "2  The Fiat Ulysse was a large car with seven sea...  \n",
       "3  401 (CDI) was a common year starting on Tuesda...  \n",
       "4  For the British musical group of the same name...  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Final preparation of training, validation and test sets\n",
    "'''\n",
    "doc_base columns: id (not used), url, title, gold_passage\n",
    "data split columns: query_text, title, gold_passage\n",
    "'''\n",
    "df1 = df.rename(columns={'question':'query_text','text':'gold_passage'})\n",
    "data = df1[['query_text','title','gold_passage']]\n",
    "x_train, x_val, x_test = gen_splits(data)\n",
    "x_train = x_train.reset_index(drop=True)\n",
    "x_val = x_val.reset_index(drop=True)\n",
    "x_test = x_test.reset_index(drop=True)\n",
    "queries_train = x_train['query_text'].tolist()\n",
    "queries_test = x_test['query_text'].tolist()\n",
    "x_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a24507a",
   "metadata": {},
   "source": [
    "## 2. Model Training & Evaluation\n",
    "**NOTE:** All models to be evaluated using test set (i.e. x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc3ada6e",
   "metadata": {},
   "source": [
    "### 2.1 TF-IDF Retrieval (Baseline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "ee1bf511",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.schema import Document\n",
    "from langchain_core.retrievers import BaseRetriever\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from typing import Any, Dict, Iterable, List, Optional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "7ebb5a8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_docs_tfidf = n_docs\n",
    "\n",
    "class Custom_TFIDFRetriever(BaseRetriever):\n",
    "    vectorizer: Any\n",
    "    tfidf_array: Any\n",
    "    docs: Any\n",
    "    \n",
    "    class Config:\n",
    "        arbitary_types_allowed = True\n",
    "    \n",
    "    @classmethod\n",
    "    def from_documents(cls,\n",
    "        documents: Iterable[Document],\n",
    "        tfidf_params: Optional[Dict[str, Any]] = None,\n",
    "    ):\n",
    "        vectorizer = TfidfVectorizer()\n",
    "        docs = [doc.page_content for doc in documents]\n",
    "        tfidf_array = vectorizer.fit_transform(docs)\n",
    "        return cls(vectorizer=vectorizer,docs=docs,tfidf_array=tfidf_array)\n",
    "    \n",
    "    def get_relevant_documents(\n",
    "        self,\n",
    "        queries: Iterable[str],\n",
    "        n_docs = n_docs_tfidf\n",
    "    ):\n",
    "        return_docs = []\n",
    "        for i in tqdm(queries):\n",
    "            query_vec = self.vectorizer.transform([i])\n",
    "            results = cosine_similarity(self.tfidf_array,query_vec).reshape((-1,))\n",
    "            return_docs_i = [self.docs[i] for i in results.argsort()[-n_docs:][::-1]]\n",
    "            return_docs.append(return_docs_i)\n",
    "        return return_docs        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "4cd46577",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 4353/4353 [02:21<00:00, 30.82it/s]\n"
     ]
    }
   ],
   "source": [
    "queries_test = x_test['query_text'].tolist()\n",
    "doc_list = [Document(page_content=doc_base.at[i,'gold_passage']) for i in range(len(doc_base))]\n",
    "retriever = Custom_TFIDFRetriever().from_documents(doc_list)\n",
    "tfidf_passages = retriever.get_relevant_documents(queries_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "49574897",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'top 1 accuracy': 0.5171146335860326, 'top 3 accuracy': 0.5171146335860326, 'top 5 accuracy': 0.5171146335860326, 'top 10 accuracy': 0.5171146335860326, 'mrr': 0.5171146335860326}\n"
     ]
    }
   ],
   "source": [
    "# Evaluate model\n",
    "tfidf_df = x_test.copy()\n",
    "# tfidf_accuracy = compute_simple_accuracy(tfidf_df,tfidf_passages)\n",
    "# print(tfidf_accuracy) # 0.51\n",
    "tfidf_results = compute_performance(tfidf_df,tfidf_passages)\n",
    "print(tfidf_results)\n",
    "\n",
    "{'top 1 accuracy': 0.5171146335860326, 'top 3 accuracy': 0.6772340914311968, 'top 5 accuracy': 0.726165862623478, 'top 10 accuracy': 0.7783138065701815, 'mrr': 0.6071221635143069}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12a7099b",
   "metadata": {},
   "source": [
    "### 2.2 Deep Passage Retrieval\n",
    "**Notes on Implementation:** Requires edit(s) to SimpleTransformers repo, as non-training actions are not supported by the max_seq_length limit:\n",
    "- retrieval/retrieval_utils.py: add the following arguments to embed():\n",
    "    - padding ='max_length', max_length = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "09625fd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Init\n",
    "n_docs_dpr = n_docs\n",
    "Ep = \"facebook/dpr-ctx_encoder-single-nq-base\"\n",
    "Eq = \"facebook/dpr-question_encoder-single-nq-base\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "97a89b8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utils\n",
    "def parallelize_model(model,device_ids=None):\n",
    "    '''\n",
    "    device_ids: List[int]\n",
    "    '''\n",
    "    if torch.cuda.device_count() > 1:\n",
    "        model.args.train_batch_size *= torch.cuda.device_count()\n",
    "        model = torch.nn.DataParallel(model,device_ids=device_ids)\n",
    "    return model\n",
    "\n",
    "def build_dpr_model(mode='train',hard_negatives=False,model_path=None):\n",
    "    '''\n",
    "    mode = 'train' or 'load'\n",
    "    hard_negatives = True -> train with hard_negatives\n",
    "    The other arguments can be toggled directly within the function\n",
    "    '''\n",
    "    model_args = RetrievalArgs(\n",
    "        max_seq_length = 512,\n",
    "        overwrite_output_dir = True,\n",
    "        train_batch_size = 16\n",
    "    )\n",
    "    if mode == 'train':\n",
    "        model = RetrievalModel(\n",
    "            model_type='dpr',\n",
    "            context_encoder_name = Ep,\n",
    "            query_encoder_name = Eq,\n",
    "            args = model_args,\n",
    "            use_cuda = torch.cuda.is_available(),\n",
    "            hard_negatives = True\n",
    "        )\n",
    "    elif mode == 'load':\n",
    "        model = RetrievalModel(\n",
    "            model_type = 'dpr',\n",
    "            model_name = model_path\n",
    "        )\n",
    "    else: raise ValueError (\"Input a valid mode. Must be 'train' or 'load'.\")\n",
    "    model = parallelize_model(model)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2791fc5b",
   "metadata": {},
   "source": [
    "##### Training Round 1: Without Hard Negatives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e65215b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "dpr_model1 = build_dpr_model(mode='train')\n",
    "dpr_model1.train_model(x_train,eval_data=x_val,\n",
    "                 output_dir = 'DPR_model/',\n",
    "                 show_running_loss=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3bb6f11",
   "metadata": {},
   "source": [
    "**DPR Checkpoint 1** - After the first training run above, skip the above cell and proceed directly to the following cells:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d80b951b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load trained model, for convenience\n",
    "dpr_model1_path = 'DPR_model/checkpoint-2176-epoch-1'\n",
    "dpr_model1 = build_dpr_model(mode='load',model_path=dpr_model1_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "3d564824",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate model\n",
    "predicted_passages, _, _, _ = dpr_model1.predict(\n",
    "    to_predict = x_test['query_text'].tolist(),\n",
    "    prediction_passages = doc_base['gold_passage'].tolist(),\n",
    "    retrieve_n_docs = n_docs_dpr\n",
    ")\n",
    "dpr_df = x_test.copy()\n",
    "# dpr_accuracy1 = compute_simple_accuracy(dpr_df,predicted_passages)\n",
    "# print(dpr_accuracy1) # 0.42706179646221\n",
    "dpr_results1 = compute_performance(dpr_df,predicted_passages)\n",
    "print(dpr_results1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "397fa49f",
   "metadata": {},
   "source": [
    "##### Training Round 2: With Generated Hard Negatives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "079601fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def row_hard_negative(row,k):\n",
    "    if row.gold_passage != row.retrieved_passage[-k]:\n",
    "        return row.retrieved_passage[-k]\n",
    "    else:\n",
    "        return row_hard_negative(row,-k+1)\n",
    "\n",
    "def generate_hard_negatives(train_df,passage_base,train_predictions):\n",
    "    train_df['retrieved_passage'] = train_predictions # or first item per list in list\n",
    "    train_df['hard_negative'] = train_df.apply(lambda row:row_hard_negative(row,n_docs_dpr),axis=1)\n",
    "    return train_df.drop(columns=['retrieved_passage'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af15afe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate hard_negatives for subsequent training\n",
    "predicted_passages_hn, _, _, _ = dpr_model1.predict(\n",
    "    to_predict = x_train['query_text'].tolist(),\n",
    "    prediction_passages = doc_base['gold_passage'].tolist(),\n",
    "    retrieve_n_docs = n_docs_dpr\n",
    ")\n",
    "\n",
    "x_train_hn = generate_hard_negatives(x_train,doc_base,predicted_passages_hn)\n",
    "x_train_hn.to_json(r'SBERT/x_train_hn.jsonl',orient='records',lines=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48343cdd",
   "metadata": {},
   "source": [
    "**DPR Checkpoint 2** - For the 2nd training round (with hard negatives), start from this cell right after #Init and #Utils (if/when kernel is restarted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e6a94fa8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yongz\\miniforge3\\envs\\torch-env\\Lib\\site-packages\\torch\\_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\n",
      "Some weights of the model checkpoint at facebook/dpr-ctx_encoder-single-nq-base were not used when initializing DPRContextEncoder: ['ctx_encoder.bert_model.pooler.dense.bias', 'ctx_encoder.bert_model.pooler.dense.weight']\n",
      "- This IS expected if you are initializing DPRContextEncoder from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DPRContextEncoder from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'DPRQuestionEncoderTokenizer'. \n",
      "The class this function is called from is 'DPRContextEncoderTokenizerFast'.\n",
      "Some weights of the model checkpoint at facebook/dpr-question_encoder-single-nq-base were not used when initializing DPRQuestionEncoder: ['question_encoder.bert_model.pooler.dense.bias', 'question_encoder.bert_model.pooler.dense.weight']\n",
      "- This IS expected if you are initializing DPRQuestionEncoder from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DPRQuestionEncoder from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f5a4a734cd64c2c8c50d9b37f0d67ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/17408 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "39c26b9a152a4c72a53fe398b9f3de2b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/17408 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d38f83056deb4968ac8049eb259bdeb7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a2a5ab64e463476abf22249fa5a31467",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 0 of 1:   0%|          | 0/2176 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yongz\\miniforge3\\envs\\torch-env\\Lib\\site-packages\\simpletransformers\\retrieval\\retrieval_model.py:1660: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  softmax_score = torch.nn.functional.log_softmax(similarity_score, dim=-1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(2176, 0.6494938274765386)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_hn = pd.read_json('SBERT/x_train_hn.jsonl',lines=True)\n",
    "x_train_hn.head()\n",
    "\n",
    "dpr_model2 = build_dpr_model(mode='train',hard_negatives=True)\n",
    "dpr_model2.train_model(x_train_hn,eval_data=x_val,\n",
    "                       output_dir = 'DPR_model/',\n",
    "                       show_running_loss = True,\n",
    "                       hard_negatives = True\n",
    "                      )   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7edd4114",
   "metadata": {},
   "source": [
    "**DPR Checkpoint 3** - After the second training run with hard negatives, start all DPR activity from the following cell right after #Init and #Utils (if/when kernel is restarted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "672474a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load trained model, for convenience\n",
    "dpr_model2_path = 'DPR_model/checkpoint-2176-epoch-1'\n",
    "dpr_model2 = build_dpr_model(mode='load',model_path=dpr_model2_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "f4e71da6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'top 1 accuracy': 0.41557546519641625, 'top 3 accuracy': 0.5662761314036296, 'top 5 accuracy': 0.6250861474844934, 'top 10 accuracy': 0.6944635883298874, 'mrr': 0.5053413263613126}\n"
     ]
    }
   ],
   "source": [
    "# Evaluate model\n",
    "predicted_passages2, _, _, _ = dpr_model2.predict(\n",
    "    to_predict = x_test['query_text'].tolist(),\n",
    "    prediction_passages = doc_base['gold_passage'].tolist(),\n",
    "    retrieve_n_docs = n_docs_dpr\n",
    ")\n",
    "\n",
    "dpr_df = x_test.copy()\n",
    "# dpr_accuracy2 = compute_simple_accuracy(dpr_df,predicted_passages2)\n",
    "# print(dpr_accuracy2)\n",
    "dpr_results2 = compute_performance(dpr_df,predicted_passages2)\n",
    "print(dpr_results2)\n",
    "{'top 1 accuracy': 0.41557546519641625, 'top 3 accuracy': 0.5662761314036296, 'top 5 accuracy': 0.6250861474844934, 'top 10 accuracy': 0.6944635883298874, 'mrr': 0.5053413263613126}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4361fbbc",
   "metadata": {},
   "source": [
    "### 2.3 S-BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "515241c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from sentence_transformers import SentenceTransformer, InputExample\n",
    "from sentence_transformers.losses import MultipleNegativesRankingLoss as MNRL\n",
    "from torch.utils.data import DataLoader,Dataset,SequentialSampler\n",
    "from nltk import sent_tokenize\n",
    "import nltk\n",
    "import faiss\n",
    "from statistics import multimode\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "6b211989",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SBERT_Dataset(Dataset):\n",
    "    def __init__(self,df):\n",
    "        self.df = df\n",
    "    \n",
    "    def __len__(self):\n",
    "        return(len(self.df))\n",
    "    \n",
    "    def __getitem__(self,idx):\n",
    "        row = self.df.loc[idx,'gold_passage']\n",
    "        if not isinstance(row,str):\n",
    "            text = []\n",
    "            for i in row.tolist():\n",
    "                text.extend(sent_tokenize(i))\n",
    "        else: text = sent_tokenize(row)\n",
    "        return text\n",
    "\n",
    "def SBERT_tokenizer(batch):\n",
    "    return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "cfc36d6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions to generate embeddings\n",
    "def get_embeddings(model,dataloader):\n",
    "    data_array = torch.empty((len(dataloader.dataset),768))\n",
    "    batch_size = dataloader.batch_size\n",
    "    for batch_idx, data in enumerate(dataloader): #sentence batches\n",
    "        model_output = model.encode(data)\n",
    "        data_array[batch_idx*batch_size: (batch_idx*batch_size) + len(model_output)] = torch.from_numpy(model_output)\n",
    "    return data_array\n",
    "\n",
    "def save_embeddings(embeddings,directory,filename):\n",
    "    if os.path.isdir(directory) == False:\n",
    "        os.mkdir(directory)\n",
    "    filename = filename + '.pt'\n",
    "    torch.save(embeddings,os.path.join(directory,filename))\n",
    "\n",
    "def generate_embeddings(model,tokenizer,dataset,directory,filename):\n",
    "    embeddings = torch.Tensor()\n",
    "    if os.path.isfile(os.path.join(directory,'sent2doc_hash.csv')) == False:\n",
    "        '''\n",
    "        sent2doc_hash\n",
    "        index: doc idx\n",
    "        value: first sentence idx\n",
    "        '''\n",
    "        sent2doc_hash = pd.Series()\n",
    "        for i in tqdm(range(len(dataset))): #docs\n",
    "            sent2doc_hash = pd.concat([sent2doc_hash,pd.Series(embeddings.shape[0])],ignore_index=True)\n",
    "            dataloader = DataLoader(dataset[i], batch_size=4, shuffle=False, pin_memory=True,  \n",
    "                                    sampler = SequentialSampler(dataset[i]),\n",
    "                                    drop_last=False, collate_fn=tokenizer)\n",
    "            embeddings_1 = get_embeddings(model, dataloader)\n",
    "            embeddings = torch.cat((embeddings,embeddings_1),0)\n",
    "        save_embeddings(embeddings, directory, filename) \n",
    "        sent2doc_hash.to_csv(os.path.join(directory,'sent2doc_hash.csv'))\n",
    "    else: \n",
    "        for i in tqdm(range(len(dataset))): #docs\n",
    "            dataloader = DataLoader(dataset[i], batch_size=4, shuffle=False, pin_memory=True,  \n",
    "                                    sampler = SequentialSampler(dataset[i]),\n",
    "                                    drop_last=False, collate_fn=tokenizer)\n",
    "            embeddings_1 = get_embeddings(model, dataloader)\n",
    "            embeddings = torch.cat((embeddings,embeddings_1),0)\n",
    "        save_embeddings(embeddings, directory, filename) \n",
    "# Sentence to doc mapping\n",
    "def generate_sent2doc(sent_embeddings): # assumes that hash file has been saved\n",
    "    sent2doc_hash = pd.read_csv('SBERT/sent2doc_hash.csv')\n",
    "    sent2doc_hash = sent2doc_hash.set_index('Unnamed: 0',drop=True)\n",
    "    sent2doc_hash.index.names = ['']\n",
    "    sent2doc_hash = sent2doc_hash.squeeze()\n",
    "    sent2doc = pd.DataFrame(index=(range(sent_embeddings.shape[0]))) # index: sentence idx\n",
    "    sent2doc['doc_id'] = (pd.Series(sent2doc.index.map(dict(zip(sent2doc_hash,sent2doc_hash.index))),\n",
    "                               index=sent2doc.index).ffill())\n",
    "    sent2doc['doc_id'] = pd.to_numeric(sent2doc['doc_id'],downcast='integer')\n",
    "    '''\n",
    "    index: sentence idx\n",
    "    value: doc idx ('doc_id')\n",
    "    '''\n",
    "    return sent2doc "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "56e2b4f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Init\n",
    "SBERT_model = SentenceTransformer('stsb-distilbert-base')\n",
    "SBERT_model.to(device)\n",
    "SBERT_directory = 'SBERT'\n",
    "filename = 'SBERT_embeddings_v1'\n",
    "passages = SBERT_Dataset(doc_base)\n",
    "n_docs_sbert = n_docs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "848cb42e",
   "metadata": {},
   "source": [
    "##### Round 1: Out-of-the-box use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e62cf66f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate and load embeddings\n",
    "generate_embeddings(SBERT_model,SBERT_tokenizer,passages,SBERT_directory,filename)\n",
    "'''\n",
    "Comment out the above line after the running it once\n",
    "'''\n",
    "sent_embeddings = torch.load(os.path.join(SBERT_directory,filename+'.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "6d6d5e79",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FAISS_DocSearch:\n",
    "    def __init__(self,model,pretok_doc_dataset,sent_embeddings):\n",
    "        sent2doc_hash = pd.read_csv('SBERT/sent2doc_hash.csv')\n",
    "        sent2doc_hash = sent2doc_hash.set_index('Unnamed: 0',drop=True)\n",
    "        sent2doc_hash.index.names = ['']\n",
    "        self.sent2doc_hash = sent2doc_hash\n",
    "        self.sent2doc = generate_sent2doc(sent_embeddings)\n",
    "        index = faiss.IndexIDMap(faiss.IndexFlatIP(768))\n",
    "        sent_embeddings = sent_embeddings.numpy()\n",
    "        faiss.normalize_L2(sent_embeddings)\n",
    "        index.add_with_ids(sent_embeddings,np.array(range(0,sent_embeddings.shape[0])))\n",
    "        self.model = model\n",
    "        self.data = pretok_doc_dataset\n",
    "        self.index = index\n",
    "        self.sent_embeddings = sent_embeddings\n",
    "#         gpu = faiss.StandardGpuResources() # faiss-gpu not supported for Windows\n",
    "#         gpu_index = faiss.index_cpu_to_gpu(gpu,0,index)\n",
    "#         self.index = gpu_index\n",
    "\n",
    "    def search_doc(self,query,k=n_docs_sbert):\n",
    "        query_vector = self.model.encode([query])\n",
    "        faiss.normalize_L2(query_vector)\n",
    "        top_k = self.index.search(query_vector,k)\n",
    "        doc_ids = [self.sent2doc.at[idx,'doc_id'] for idx in top_k[1].tolist()[0]]\n",
    "        return self.data.loc[doc_ids,'gold_passage'].tolist()\n",
    "\n",
    "    def search_sentence(self,query,posttok_doc_dataset,full_train_dataset,k=5):\n",
    "        '''\n",
    "        For training. \n",
    "        sent_embeddings: torch.Tensor() -> Sentence embeddings from the corresponding gold_passage\n",
    "        '''\n",
    "        # Create faiss index of sentences for the corresponding document\n",
    "            # query -> doc-> doc_idx -> get sentence _ids from sent2doc_hash\n",
    "        doc_id = self.data.index[self.data['gold_passage']==full_train_dataset.loc[full_train_dataset['query_text']==query,'gold_passage'].to_numpy()[0]][0]\n",
    "        if doc_id < len(self.data)-1:\n",
    "            sent_emb_ids = list(range(self.sent2doc_hash.at[doc_id,'0'],self.sent2doc_hash.at[doc_id+1,'0']))\n",
    "        else: sent_emb_ids = list(range(self.sent2doc_hash.at[doc_id,'0'],len(self.data))) # list of sentence_ids for doc\n",
    "        index = faiss.IndexIDMap(faiss.IndexFlatIP(768))\n",
    "        index.add_with_ids(self.sent_embeddings[sent_emb_ids],np.array(range(0,len(sent_emb_ids))))\n",
    "        \n",
    "        # Generate top sentences from document based on query\n",
    "        query_vector = self.model.encode([query])\n",
    "        faiss.normalize_L2(query_vector)\n",
    "        top_k = index.search(query_vector,k)\n",
    "        sent_ids = top_k[1].tolist()[0]\n",
    "        sents = [posttok_doc_dataset[doc_id][sent_id] for sent_id in sent_ids]\n",
    "        return sents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "08ebc335",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 4353/4353 [04:57<00:00, 14.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'top 1 accuracy': 0.35377900298644616, 'top 3 accuracy': 0.4985067769354468, 'top 5 accuracy': 0.5580059728922582, 'top 10 accuracy': 0.6292212267401792, 'mrr': 0.44139746717279454}\n"
     ]
    }
   ],
   "source": [
    "SBERT_search1 = FAISS_DocSearch(SBERT_model,doc_base,sent_embeddings)\n",
    "sbert_predictions = []\n",
    "for i in tqdm(queries_test):\n",
    "    results = SBERT_search1.search_doc(i)\n",
    "    sbert_predictions.append(results)\n",
    "\n",
    "sbert_df = x_test.copy()\n",
    "# sbert_accuracy = compute_simple_accuracy(sbert_df,sbert_predictions)\n",
    "# print(sbert_accuracy)\n",
    "sbert_results = compute_performance(sbert_df,sbert_predictions)\n",
    "print(sbert_results)\n",
    "\n",
    "{'top 1 accuracy': 0.35377900298644616, 'top 3 accuracy': 0.4985067769354468, 'top 5 accuracy': 0.5580059728922582, 'top 10 accuracy': 0.6292212267401792, 'mrr': 0.44139746717279454}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e990f1fd",
   "metadata": {},
   "source": [
    "##### Round 2: Fine-tuning with Wikipedia Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "6d4945f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SBERT_New_Dataset(Dataset):\n",
    "    def __init__(self,df):\n",
    "        '''\n",
    "        df: List[List[InputExample]] -> List of sentence pairs, wh\n",
    "        InputExample is a class under sentence_transformers (1 per sentence)\n",
    "        '''\n",
    "        self.df = df\n",
    "    \n",
    "    def __len__(self):\n",
    "        return(len(self.df))\n",
    "    \n",
    "    def __getitem__(self,idx):\n",
    "        return self.df[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "b1bd000c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 17408/17408 [08:04<00:00, 35.89it/s]\n"
     ]
    }
   ],
   "source": [
    "# Generate dataset for fine-tuning\n",
    "SBERT_search = FAISS_DocSearch(SBERT_model,doc_base,sent_embeddings)\n",
    "eg_list = []\n",
    "for i in tqdm(queries_train):\n",
    "    sentences = SBERT_search.search_sentence(i,passages,x_train)\n",
    "    query_repeat = [i]*n_docs_sbert\n",
    "    eg_list_i = [InputExample(texts=list(x)) for x in zip(query_repeat,sentences)]\n",
    "    eg_list.extend(eg_list_i)\n",
    "eg_list = list(x for x,_ in itertools.groupby(eg_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "56779b27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "badc1bdb92a147c38c6f092630523217",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "68d1b9119d564760aae48819a82e3587",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/10880 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Train with new dataset\n",
    "sbert_train_data = SBERT_New_Dataset(eg_list)\n",
    "sbert_train_dataloader = DataLoader(sbert_train_data,shuffle=False,batch_size=8)    \n",
    "sbert_train_loss = MNRL(model=SBERT_model)\n",
    "SBERT_model.fit(train_objectives=[(sbert_train_dataloader,sbert_train_loss)],epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "b27296ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 10000/10000 [36:29<00:00,  4.57it/s]\n"
     ]
    }
   ],
   "source": [
    "# Generate and load embeddings\n",
    "filename2 = 'SBERT_embeddings_v2'\n",
    "generate_embeddings(SBERT_model,SBERT_tokenizer,passages,SBERT_directory,filename2)\n",
    "'''\n",
    "Comment out the above line after running it once\n",
    "'''\n",
    "sent_embeddings2 = torch.load(os.path.join(SBERT_directory,filename2+'.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "82aff1ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 4353/4353 [04:47<00:00, 15.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'top 1 accuracy': 0.3496439237307604, 'top 3 accuracy': 0.48334481966459913, 'top 5 accuracy': 0.5375603032391454, 'top 10 accuracy': 0.5910866069377441, 'mrr': 0.4284863750232461}\n"
     ]
    }
   ],
   "source": [
    "# Evaluate model\n",
    "SBERT_search = FAISS_DocSearch(SBERT_model,doc_base,sent_embeddings2)\n",
    "sbert_predictions2 = []\n",
    "for i in tqdm(queries_test):\n",
    "    results = SBERT_search.search_doc(i)\n",
    "    sbert_predictions2.append(results)\n",
    "\n",
    "sbert_df = x_test.copy()\n",
    "# sbert_accuracy2 = compute_simple_accuracy(sbert_df,sbert_predictions2)\n",
    "# print(sbert_accuracy2)\n",
    "sbert_results2 = compute_performance(sbert_df,sbert_predictions2)\n",
    "print(sbert_results2)\n",
    "{'top 1 accuracy': 0.3496439237307604, 'top 3 accuracy': 0.48334481966459913, 'top 5 accuracy': 0.5375603032391454, 'top 10 accuracy': 0.5910866069377441, 'mrr': 0.4284863750232461}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5365e549",
   "metadata": {},
   "source": [
    "## 3. Consolidation\n",
    "Generate final predictions and export results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "21c24e06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>top 1 accuracy</th>\n",
       "      <th>top 3 accuracy</th>\n",
       "      <th>top 5 accuracy</th>\n",
       "      <th>top 10 accuracy</th>\n",
       "      <th>mrr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tfidf</td>\n",
       "      <td>0.517115</td>\n",
       "      <td>0.677234</td>\n",
       "      <td>0.726166</td>\n",
       "      <td>0.778314</td>\n",
       "      <td>0.607122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>dpr</td>\n",
       "      <td>0.415575</td>\n",
       "      <td>0.566276</td>\n",
       "      <td>0.625086</td>\n",
       "      <td>0.694464</td>\n",
       "      <td>0.505341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sbert</td>\n",
       "      <td>0.349644</td>\n",
       "      <td>0.483345</td>\n",
       "      <td>0.537560</td>\n",
       "      <td>0.591087</td>\n",
       "      <td>0.428486</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   model  top 1 accuracy  top 3 accuracy  top 5 accuracy  top 10 accuracy  \\\n",
       "0  tfidf        0.517115        0.677234        0.726166         0.778314   \n",
       "1    dpr        0.415575        0.566276        0.625086         0.694464   \n",
       "2  sbert        0.349644        0.483345        0.537560         0.591087   \n",
       "\n",
       "        mrr  \n",
       "0  0.607122  \n",
       "1  0.505341  \n",
       "2  0.428486  "
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compare performance\n",
    "tfidf_results['model'] = 'tfidf'\n",
    "dpr_results2['model'] = 'dpr'\n",
    "sbert_results2['model'] = 'sbert'\n",
    "model_results = pd.DataFrame(tfidf_results,index=[0])\n",
    "model_results = pd.concat([model_results,pd.DataFrame(dpr_results2,index=[1])],ignore_index=True)\n",
    "model_results = pd.concat([model_results,pd.DataFrame(sbert_results2,index=[2])],ignore_index=True)\n",
    "cols = model_results.columns.tolist()\n",
    "cols = cols[-1:] + cols[:-1]\n",
    "model_results = model_results[cols]\n",
    "model_results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "70bd0a3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_test = pd.read_json('test.jsonl',lines=True)\n",
    "queries_final = final_test['question'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "081c6ffc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 5468/5468 [02:54<00:00, 31.29it/s]\n"
     ]
    }
   ],
   "source": [
    "# Build model and generate predictions: TFIDF\n",
    "doc_list = [Document(page_content=doc_base.at[i,'gold_passage']) for i in range(len(doc_base))]\n",
    "retriever = Custom_TFIDFRetriever().from_documents(doc_list)\n",
    "predictions_final = retriever.get_relevant_documents(queries_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "df3e34e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>points</th>\n",
       "      <th>article</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>what is the percentage of the population of gu...</td>\n",
       "      <td>53</td>\n",
       "      <td>Guernsey</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>what is the traditional method of making vineg...</td>\n",
       "      <td>50</td>\n",
       "      <td>Vinegar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>what were the primary ways that medieval towns...</td>\n",
       "      <td>54</td>\n",
       "      <td>Early Middle Ages</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>what are the names of the nine native american...</td>\n",
       "      <td>56</td>\n",
       "      <td>South Dakota</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>who was the young woman who was the inspiratio...</td>\n",
       "      <td>53</td>\n",
       "      <td>Leoš Janáček</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>what is the former capital of the duchy of lor...</td>\n",
       "      <td>66</td>\n",
       "      <td>Capital city</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>what is the process of pattern welding used to...</td>\n",
       "      <td>83</td>\n",
       "      <td>Welding</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>what is the total population of sydney includi...</td>\n",
       "      <td>56</td>\n",
       "      <td>Sydney</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>what is the name of the national recreation ar...</td>\n",
       "      <td>76</td>\n",
       "      <td>Lake Chaubunagungamaug</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>what is the best way we have of understanding ...</td>\n",
       "      <td>49</td>\n",
       "      <td>Bioinformatics</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            question  points  \\\n",
       "0  what is the percentage of the population of gu...      53   \n",
       "1  what is the traditional method of making vineg...      50   \n",
       "2  what were the primary ways that medieval towns...      54   \n",
       "3  what are the names of the nine native american...      56   \n",
       "4  who was the young woman who was the inspiratio...      53   \n",
       "5  what is the former capital of the duchy of lor...      66   \n",
       "6  what is the process of pattern welding used to...      83   \n",
       "7  what is the total population of sydney includi...      56   \n",
       "8  what is the name of the national recreation ar...      76   \n",
       "9  what is the best way we have of understanding ...      49   \n",
       "\n",
       "                  article  \n",
       "0                Guernsey  \n",
       "1                 Vinegar  \n",
       "2       Early Middle Ages  \n",
       "3            South Dakota  \n",
       "4            Leoš Janáček  \n",
       "5            Capital city  \n",
       "6                 Welding  \n",
       "7                  Sydney  \n",
       "8  Lake Chaubunagungamaug  \n",
       "9          Bioinformatics  "
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Organize results\n",
    "'''\n",
    "final_test: DataFrame(columns=['question','points'])\n",
    "predictions_final: List[List[str]]\n",
    "submission.jsonl\n",
    "'''\n",
    "final_test['gold_passage'] = [docs[0] for docs in predictions_final]\n",
    "final_test = final_test.merge(doc_base[['title','gold_passage']],how='left',on='gold_passage')\n",
    "if final_test['title'].isnull().values.any(): print('null exists')\n",
    "final_test = final_test.drop(columns=['gold_passage']).rename(columns={'title':'article'})\n",
    "final_test.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c109be7b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch-env",
   "language": "python",
   "name": "my-conda-env-kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
