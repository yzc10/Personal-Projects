{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6411c4d7-2162-4a76-b4cc-6113a14d87b1",
   "metadata": {},
   "source": [
    "# Predicting Stock Returns [PyTorch - LSTM]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2d0666a-8bca-453b-835f-0660ad724b70",
   "metadata": {},
   "source": [
    "## 0. One-Off Data Processing [Temp]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "90d02b4b-7eed-4f5f-8c33-5321575a5b20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime as dt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from functools import partial\n",
    "from tqdm import tqdm\n",
    "\n",
    "path = path = r'C:\\YZC\\NUS\\Semester 1\\DSA5105_Principles of Machine Learning\\Principles of ML_Project'\n",
    "os.chdir(path)\n",
    "tqdm = partial(tqdm,position=0,leave=True)\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d40f9444-b934-43db-b251-de33d2f7528c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sp500 = pd.read_csv('processed_df_v1.csv')\n",
    "sp500 = sp500.drop(['Year_x','Year_y','grouper1'],axis=1)\n",
    "sp500['Date'] = pd.to_datetime(sp500['Date'])\n",
    "sp500['Target'] = sp500.groupby('Stock')['Target'].shift(-1)\n",
    "sp500['Target_Return'] = sp500.groupby('Stock')['Return'].shift(-1)\n",
    "sp500['Target_Close'] = sp500.groupby('Stock')['Close'].shift(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9bd8e6fe-d4ca-4d3f-994e-8151ac285b28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test done\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "inf_cols = ['Stochastic_5','Stochastic_15','RS_5','RS_15']\n",
    "null_mean_cols = ['SMA_Volume_ratio','Stochastic_5','Stochastic_15','Stochastic_%D_5','Stochastic_%D_15','Stochastic_Ratio',\n",
    "'+DM_5','-DM_5','+DM_15','-DM_15','RS_5','RS_15','RSI_5','RSI_ratio']\n",
    "null_adjfill_cols = ['Return','Target','Target_Return','Target_Close']\n",
    "\n",
    "def impute(df,inf_cols,null_mean_cols,null_adjfill_cols,groupby_col):\n",
    "    for c in inf_cols:\n",
    "        df[c] = df[c].replace([-np.inf,np.inf],np.nan)\n",
    "    for c in null_mean_cols:\n",
    "        result = df.groupby(groupby_col)[c].apply(lambda x:x.fillna(x.mean()))\n",
    "        df[c] = result.droplevel(0)\n",
    "    for c in null_adjfill_cols:\n",
    "        df[c] = df.groupby(groupby_col)[c].ffill().bfill()\n",
    "    return df\n",
    "\n",
    "def NA_test(df,cols):\n",
    "    for c in cols:\n",
    "        if df[c].isnull().values.any():\n",
    "            print('null',c)\n",
    "        if np.isinf(df[c].values).any():\n",
    "            print('inf',c)\n",
    "    print('test done')\n",
    "\n",
    "sp500_1 = impute(sp500,inf_cols,null_mean_cols,null_adjfill_cols,'Stock')\n",
    "NA_test(sp500_1,[c for c in sp500_1.columns if c not in ['Date','Stock','Year']])\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2229a6c3-2d91-4223-9940-218eecc41563",
   "metadata": {},
   "outputs": [],
   "source": [
    "sp500_1.to_csv('processed_df_v2.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a928ba7-6d80-41a0-8419-e9545e3e89f0",
   "metadata": {},
   "source": [
    "## 1. Data Pre-Processing\n",
    "#### (Start from here)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "a4b3accc-477c-4b96-98b4-cf5b5a1148cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime as dt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "import time\n",
    "import os\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "from functools import partial\n",
    "\n",
    "path = path = r'C:\\YZC\\NUS\\Semester 1\\DSA5105_Principles of Machine Learning\\Principles of ML_Project'\n",
    "os.chdir(path)\n",
    "# tqdm = partial(tqdm,position=0,leave=True)\n",
    "# tqdm._instances.clear()\n",
    "# while len(tqdm._instances) > 0:\n",
    "#     tqdm._instances.pop().close()\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f99dd3ac-272b-4c90-af7b-116d2471a2cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Dividends</th>\n",
       "      <th>Stock Splits</th>\n",
       "      <th>Stock</th>\n",
       "      <th>Return</th>\n",
       "      <th>...</th>\n",
       "      <th>United States_CA</th>\n",
       "      <th>United States_CP_end</th>\n",
       "      <th>United States_CP_avg</th>\n",
       "      <th>United States_Gov_NetDebt</th>\n",
       "      <th>United States_GDP</th>\n",
       "      <th>United States_UR</th>\n",
       "      <th>Fed_Rate</th>\n",
       "      <th>Target</th>\n",
       "      <th>Target_Return</th>\n",
       "      <th>Target_Close</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2000-01-03</td>\n",
       "      <td>1.153400</td>\n",
       "      <td>1.206028</td>\n",
       "      <td>1.023149</td>\n",
       "      <td>1.201642</td>\n",
       "      <td>7226398</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>ATVI</td>\n",
       "      <td>-0.030293</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.921</td>\n",
       "      <td>3.427</td>\n",
       "      <td>3.367</td>\n",
       "      <td>-0.537</td>\n",
       "      <td>4.077</td>\n",
       "      <td>3.967</td>\n",
       "      <td>5.45</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.030293</td>\n",
       "      <td>1.165241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2000-01-04</td>\n",
       "      <td>1.175329</td>\n",
       "      <td>1.187609</td>\n",
       "      <td>1.041570</td>\n",
       "      <td>1.165241</td>\n",
       "      <td>4262390</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>ATVI</td>\n",
       "      <td>-0.030293</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.921</td>\n",
       "      <td>3.427</td>\n",
       "      <td>3.367</td>\n",
       "      <td>-0.537</td>\n",
       "      <td>4.077</td>\n",
       "      <td>3.967</td>\n",
       "      <td>5.45</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.003765</td>\n",
       "      <td>1.169628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2000-01-05</td>\n",
       "      <td>1.153401</td>\n",
       "      <td>1.196818</td>\n",
       "      <td>1.151208</td>\n",
       "      <td>1.169628</td>\n",
       "      <td>3389998</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>ATVI</td>\n",
       "      <td>0.003765</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.921</td>\n",
       "      <td>3.427</td>\n",
       "      <td>3.367</td>\n",
       "      <td>-0.537</td>\n",
       "      <td>4.077</td>\n",
       "      <td>3.967</td>\n",
       "      <td>5.45</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.019498</td>\n",
       "      <td>1.146823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2000-01-06</td>\n",
       "      <td>1.162173</td>\n",
       "      <td>1.169628</td>\n",
       "      <td>1.137612</td>\n",
       "      <td>1.146823</td>\n",
       "      <td>2429998</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>ATVI</td>\n",
       "      <td>-0.019498</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.921</td>\n",
       "      <td>3.427</td>\n",
       "      <td>3.367</td>\n",
       "      <td>-0.537</td>\n",
       "      <td>4.077</td>\n",
       "      <td>3.967</td>\n",
       "      <td>5.45</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.027915</td>\n",
       "      <td>1.178837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2000-01-07</td>\n",
       "      <td>1.162172</td>\n",
       "      <td>1.187609</td>\n",
       "      <td>1.133228</td>\n",
       "      <td>1.178837</td>\n",
       "      <td>15549590</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>ATVI</td>\n",
       "      <td>0.027915</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.921</td>\n",
       "      <td>3.427</td>\n",
       "      <td>3.367</td>\n",
       "      <td>-0.537</td>\n",
       "      <td>4.077</td>\n",
       "      <td>3.967</td>\n",
       "      <td>5.45</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.050223</td>\n",
       "      <td>1.238042</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 93 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date      Open      High       Low     Close    Volume  Dividends  \\\n",
       "0  2000-01-03  1.153400  1.206028  1.023149  1.201642   7226398        0.0   \n",
       "1  2000-01-04  1.175329  1.187609  1.041570  1.165241   4262390        0.0   \n",
       "2  2000-01-05  1.153401  1.196818  1.151208  1.169628   3389998        0.0   \n",
       "3  2000-01-06  1.162173  1.169628  1.137612  1.146823   2429998        0.0   \n",
       "4  2000-01-07  1.162172  1.187609  1.133228  1.178837  15549590        0.0   \n",
       "\n",
       "   Stock Splits Stock    Return  ...  United States_CA  United States_CP_end  \\\n",
       "0           0.0  ATVI -0.030293  ...            -3.921                 3.427   \n",
       "1           0.0  ATVI -0.030293  ...            -3.921                 3.427   \n",
       "2           0.0  ATVI  0.003765  ...            -3.921                 3.427   \n",
       "3           0.0  ATVI -0.019498  ...            -3.921                 3.427   \n",
       "4           0.0  ATVI  0.027915  ...            -3.921                 3.427   \n",
       "\n",
       "   United States_CP_avg  United States_Gov_NetDebt  United States_GDP  \\\n",
       "0                 3.367                     -0.537              4.077   \n",
       "1                 3.367                     -0.537              4.077   \n",
       "2                 3.367                     -0.537              4.077   \n",
       "3                 3.367                     -0.537              4.077   \n",
       "4                 3.367                     -0.537              4.077   \n",
       "\n",
       "   United States_UR  Fed_Rate  Target  Target_Return  Target_Close  \n",
       "0             3.967      5.45     0.0      -0.030293      1.165241  \n",
       "1             3.967      5.45     1.0       0.003765      1.169628  \n",
       "2             3.967      5.45     0.0      -0.019498      1.146823  \n",
       "3             3.967      5.45     1.0       0.027915      1.178837  \n",
       "4             3.967      5.45     1.0       0.050223      1.238042  \n",
       "\n",
       "[5 rows x 93 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Essentials\n",
    "sp500 = pd.read_csv('processed_df_v2.csv')\n",
    "sp500_var = sp500.copy().drop(['Date','Return','Stock','Target','Target_Return','Target_Close'],axis=1)\n",
    "sp500.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3f3297f0-c129-4a55-93a0-8872d7975c59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sampling\n",
    "sampled_stocks = ['AAPL','CCI', 'USB', 'ADI', 'PNW', 'QCOM']\n",
    "sp500_sampled = sp500.loc[sp500['Stock'].isin(sampled_stocks)].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e0a8371d-dc48-4e5f-91b7-bb1088d84f4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataFrameSelector(BaseEstimator,TransformerMixin):\n",
    "    def __init__(self,attribute_names):\n",
    "        self.attribute_names = attribute_names\n",
    "    def fit(self,X):\n",
    "        return self\n",
    "    def transform(self,X):\n",
    "        return X[self.attribute_names].to_numpy()\n",
    "\n",
    "class ArrayTransformer(BaseEstimator,TransformerMixin): \n",
    "    # Restructure into: samples x timesteps x features\n",
    "    def __init__(self):\n",
    "        return None\n",
    "    def fit(self,X):\n",
    "        return self\n",
    "    def transform(self,X):\n",
    "        X = X.toarray()\n",
    "        X1_cols = list(range(30))\n",
    "        X1_cols.extend(sampled_stocks)    \n",
    "        X1_df = pd.DataFrame(X,columns=X1_cols)\n",
    "        X1 = []\n",
    "        for s in sampled_stocks:\n",
    "            X1.append(X1_df.loc[X1_df[s]==1].to_numpy())\n",
    "        X1 = np.asarray(X1)\n",
    "        return X1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "29fb14cf-550c-4e19-a458-ad6fb6232e43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "# Pipeline for X\n",
    "cat_vars = ['Stock']\n",
    "num_vars = list(set(sp500_var.columns) - set(cat_vars))\n",
    "\n",
    "num_pipeline = Pipeline([\n",
    "    ('selector',DataFrameSelector(num_vars)),\n",
    "    ('scaler',StandardScaler()),\n",
    "    ('pca',PCA(n_components=30)),\n",
    "])\n",
    "cat_pipeline = Pipeline([\n",
    "    ('selector',DataFrameSelector(cat_vars)),\n",
    "    ('ohe',OneHotEncoder(categories=[sampled_stocks])), #Note: categories should be a list of list(s)\n",
    "])\n",
    "concat_pipeline = FeatureUnion(transformer_list=[\n",
    "    ('num_pipeline',num_pipeline),\n",
    "    ('cat_pipeline',cat_pipeline),\n",
    "])\n",
    "final_pipeline = Pipeline([\n",
    "    ('combined_pipeline',concat_pipeline),\n",
    "    ('to_array',ArrayTransformer()),\n",
    "])\n",
    "X1 = final_pipeline.fit_transform(sp500_sampled)\n",
    "\n",
    "# Transform Y:\n",
    "y1 = []\n",
    "for s in sampled_stocks:\n",
    "    y1.append(sp500_sampled.loc[sp500_sampled['Stock']==s,'Target'].to_numpy())\n",
    "y1 = np.asarray(y1)\n",
    "y1 = y1.astype(int)\n",
    "\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f93d3e05-ab47-49b9-83e7-47d5d2f1fe39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Verifying order of labels: ['AAPL','CCI', 'USB', 'ADI', 'PNW', 'QCOM']\n",
    "# idx = {}\n",
    "# for s in sampled_stocks:\n",
    "#     idx[s] = sp500_sampled.index[sp500_sampled['Stock']==s].tolist()[0]\n",
    "# print(idx)\n",
    "# for i in idx:\n",
    "#     print(i,X1[idx[i],30:]) # Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0f729957-6a65-4e36-a929-db2968d2a2c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n",
      "(6, 5995) (6, 5995, 36)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as data\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(device)\n",
    "print(y1.shape,X1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "94b410f8-8f8d-49aa-9729-9b28747466e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM_Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.lstm = nn.LSTM(input_size=36, hidden_size=50,num_layers=1,batch_first=True)\n",
    "        self.linear = nn.Linear(50,1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "    def forward(self,x):\n",
    "        x, _ = self.lstm(x)\n",
    "        x = self.linear(x)\n",
    "        x = self.sigmoid(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "90d51d2a-de30-4744-904c-082823adeaa0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([6, 4796, 36]) torch.Size([6, 4796, 1]) torch.Size([6, 1199, 36]) torch.Size([6, 1199, 1])\n"
     ]
    }
   ],
   "source": [
    "def time_series_split(X,split_pct):\n",
    "    time_series = X.shape[1]\n",
    "    train_size = int(time_series*split_pct)\n",
    "    test_size = time_series - train_size\n",
    "    X_train, X_test = X[:,:train_size],X[:,train_size:time_series]\n",
    "    return X_train, X_test\n",
    "\n",
    "def convert_tensor(X,unsqueeze=False):\n",
    "    X = torch.from_numpy(X)\n",
    "    X = X.type(torch.FloatTensor)\n",
    "    if unsqueeze==True:\n",
    "        X = torch.unsqueeze(X,dim=-1)\n",
    "    return X\n",
    "\n",
    "split_pct = 0.8\n",
    "X_train, X_test = time_series_split(X1,split_pct)\n",
    "y_train, y_test = time_series_split(y1,split_pct)\n",
    "X_train, X_test = convert_tensor(X_train), convert_tensor(X_test)\n",
    "y_train, y_test = convert_tensor(y_train,unsqueeze=True), convert_tensor(y_test,unsqueeze=True)\n",
    "print(X_train.shape,y_train.shape,X_test.shape,y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "97848e63-df1a-4fcb-a85d-ce87844ae475",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LSTM_Model()\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "loader = data.DataLoader(data.TensorDataset(X_train,y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "4fd9fa99-b0e9-462a-97ed-1a65b26e0098",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▊                                                                                 | 1/100 [00:00<00:27,  3.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch0: accuracy=0.5005560189046427, precision=0.5185704274702172,recall=0.591684434968017\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|█▋                                                                                | 2/100 [00:00<00:29,  3.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch1: accuracy=0.5001390047261607, precision=0.5181648812296227,recall=0.5930170575692963\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|██▍                                                                               | 3/100 [00:00<00:26,  3.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch2: accuracy=0.5016680567139282, precision=0.5195504565675486,recall=0.5914179104477612\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|███▎                                                                              | 4/100 [00:01<00:28,  3.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch3: accuracy=0.5005560189046427, precision=0.5184840734712858,recall=0.5943496801705757\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|████                                                                              | 5/100 [00:01<00:27,  3.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch4: accuracy=0.5006950236308034, precision=0.518796992481203,recall=0.5884861407249466\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|████▉                                                                             | 6/100 [00:01<00:29,  3.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch5: accuracy=0.5020850708924104, precision=0.5198227611940298,recall=0.5940831556503199\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|█████▋                                                                            | 7/100 [00:02<00:30,  3.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch6: accuracy=0.5018070614400889, precision=0.519895783988631,recall=0.5850213219616205\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[48], line 6\u001b[0m\n\u001b[0;32m      4\u001b[0m model\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m X_batch, y_batch \u001b[38;5;129;01min\u001b[39;00m loader:\n\u001b[1;32m----> 6\u001b[0m     y_pred \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_batch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      7\u001b[0m     loss \u001b[38;5;241m=\u001b[39m loss_fn(y_pred,y_batch)\n\u001b[0;32m      8\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n",
      "File \u001b[1;32m~\\miniforge3\\envs\\torch-env\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\miniforge3\\envs\\torch-env\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[9], line 8\u001b[0m, in \u001b[0;36mLSTM_Model.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m,x):\n\u001b[1;32m----> 8\u001b[0m     x, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlstm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      9\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlinear(x)\n\u001b[0;32m     10\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msigmoid(x)\n",
      "File \u001b[1;32m~\\miniforge3\\envs\\torch-env\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\miniforge3\\envs\\torch-env\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\miniforge3\\envs\\torch-env\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:879\u001b[0m, in \u001b[0;36mLSTM.forward\u001b[1;34m(self, input, hx)\u001b[0m\n\u001b[0;32m    876\u001b[0m         hx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpermute_hidden(hx, sorted_indices)\n\u001b[0;32m    878\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m batch_sizes \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 879\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43m_VF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlstm\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_flat_weights\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnum_layers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    880\u001b[0m \u001b[43m                      \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdropout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbidirectional\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch_first\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    881\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    882\u001b[0m     result \u001b[38;5;241m=\u001b[39m _VF\u001b[38;5;241m.\u001b[39mlstm(\u001b[38;5;28minput\u001b[39m, batch_sizes, hx, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_flat_weights, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias,\n\u001b[0;32m    883\u001b[0m                       \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_layers, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbidirectional)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "n_epochs = 100\n",
    "results = pd.DataFrame(columns=['epoch','accuracy','precision','recall'])\n",
    "for epoch in tqdm(range(n_epochs)):\n",
    "    model.train()\n",
    "    for X_batch, y_batch in loader:\n",
    "        y_pred = model(X_batch)\n",
    "        loss = loss_fn(y_pred,y_batch)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        model.eval()\n",
    "    with torch.no_grad():\n",
    "        y_pred = model(X_test)\n",
    "        y_pred = torch.squeeze(y_pred,dim=-1)\n",
    "        y_test1 = torch.squeeze(y_test,dim=-1)\n",
    "        y_pred, y_test1 = y_pred.numpy(), y_test1.numpy()\n",
    "        y_pred = (y_pred>0.5).astype(float).flatten()\n",
    "        y_test1 = y_test1.flatten()\n",
    "        # print(y_pred,y_test1)\n",
    "        accuracy = metrics.accuracy_score(y_test1,y_pred)\n",
    "        precision = metrics.precision_score(y_test1,y_pred)\n",
    "        recall = metrics.recall_score(y_test1,y_pred)\n",
    "        tqdm.write(f\"Epoch{epoch}: accuracy={accuracy}, precision={precision},recall={recall}\") \n",
    "        results.loc[len(results)] = [epoch,accuracy,precision,recall]\n",
    "results.to_csv('pytorch_lstm_results_v0.csv',index=False)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "91494be0-4009-4480-b481-5679069ce805",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross validation\n",
    "# Hyperparam Tuning"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch-env",
   "language": "python",
   "name": "my-conda-env-kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
